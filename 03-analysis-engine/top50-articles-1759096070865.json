{
  "timestamp": "2025-09-28T21:47:50.859Z",
  "processingStats": {
    "totalProcessed": 137,
    "startTime": "2025-09-28T18:05:07.595Z",
    "endTime": "2025-09-28T21:47:50.859Z",
    "avgScore": 67,
    "topScores": [
      2027,
      2025,
      365,
      135,
      95,
      95,
      92,
      92,
      92,
      92
    ]
  },
  "top50Articles": [
    {
      "title": "Ford decides to run its Le Mans program in-house, racing in 2027",
      "url": "https://arstechnica.com/cars/2025/09/ford-decides-to-run-its-le-mans-program-in-house-racing-in-2027/",
      "summary": "Instead of contracting an outside team to campaign it, Ford Racing gets the job.",
      "publishedDate": "2025-09-25T12:00:55.000Z",
      "author": "\n                    Jonathan M. Gitlin\n                ",
      "source": {
        "name": "Ars Technica",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:11.796Z",
      "localScore": 2027
    },
    {
      "title": "Seven AI takeaways: what we’ve learned about deployment in 2025",
      "url": "https://www.techmonitor.ai/sponsored/seven-ai-takeaways-what-weve-learned-about-deployment-in-2025",
      "summary": "A mid-September event in Stockholm, Sweden, marked a break in this year’s Tech Monitor / AMD series of executive leadership events.",
      "publishedDate": "2025-09-25T07:30:00.000Z",
      "author": "Jon Bernstein",
      "source": {
        "name": "Tech Monitor",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:37.116Z",
      "localScore": 2025
    },
    {
      "title": " Satya Nadella says “our multi-model approach goes beyond choice’ as Microsoft adds Claude AI models to 365 Copilot ",
      "url": "https://www.itpro.com/technology/artificial-intelligence/microsoft-365-copilot-anthropic-claude-ai-models",
      "summary": "Users can choose between both OpenAI and Anthropic models in Microsoft 365 Copilot",
      "publishedDate": "2025-09-25T09:14:50.000Z",
      "author": " Ross Kelly ",
      "source": {
        "name": "IT Pro",
        "tier": "industry",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:03.374Z",
      "localScore": 365
    },
    {
      "title": "AI #135: OpenAI Shows Us The Money",
      "url": "https://www.lesswrong.com/posts/P5ZuoCwGCZyecBxeN/ai-135-openai-shows-us-the-money",
      "summary": "Published on September 25, 2025 1:40 PM GMT\n\nOpenAI is here this week to show us the money, as in a $100 billion investment from Nvidia and operationalization of a $400 billion buildout for Stargate. They are not kidding around when it comes to scale. They’re going to need it, as they are announcing soon a slate of products that takes inference costs to the next level.\nAfter a full review and two reaction posts, I’ve now completed my primary coverage of If Anyone Builds It, Everyone Dies. The book is now a NYT bestseller, #7 in combined print and e-books nonfiction and #8 in hardcover fiction. I will of course cover any important developments from here but won’t be analyzing reviews and reactions by default.\n\n\n\n\nWe also had a conference of economic papers on AI, which were interesting throughout about particular aspects of AI economics, even though they predictably did not take future AI capabilities seriously as a general consideration. By contrast, when asked about ‘the future of American capitalism in 50 years’ most economists failed to notice AI as a factor at all.\nTable of Contents\nLanguage Models Offer Mundane Utility. In some fields, what can’t they do?\nLanguage Models Don’t Offer Mundane Utility. You don’t create enough data.\nHuh, Upgrades. Expensive and compute intense new OpenAI offerings soon.\nOn Your Marks. SWE-Bench-Pro and Among AIs.\nChoose Your Fighter. What else is implied by being good at multi-AI chats?\nGet My Agent On The Line. Financial management AI is coming.\nAntisocial Media. Grok to be running Twitter’s recommendation algorithm?\nCopyright Confrontation. Yes, of course Sora trained on all the media.\nDeepfaketown and Botpocalypse Soon. AI simulations of Charlie Kirk.\nFun With Media Generation. Poet uses Suno to land record contract.\nUnprompted Attention. Any given system prompt is bad for most things.\nThey Took Our Jobs. Very good thoughts about highly implausible futures.\nA Young Lady’s Illustrated Primer. Learning and not learning to code.\nThe Art of the Jailbreak. Tell them Pliny sent you. No, seriously, that’s it.\nGet Involved. Topos UK wants a director of operations.\nIn Other AI News. Codex usage is growing like gangbusters.\nGlass Houses. Meta shills potentially cool smart glasses as ‘superintelligence.’\nShow Me the Money. xAI, Alibaba raise money, YouTube gets auto-tagging.\nQuiet Speculations. Economists imagine future without feeling the AGI. Or AI.\nCall For Action At The UN. Mix of new faces and usual suspects raise the alarm.\nThe Quest for Sane Regulations. Singularity mentioners in Congress rise to 23.\nChip City. Market does not much care that Nvidia chips are banned in China.\nThe Week in Audio. Sriram Krishnan on Shawn Ryan.\nRhetorical Innovation. Everyone grades on a curve one way or another.\nGoogle Strengthens Its Safety Framework. You love to see it.\nAligning a Smarter Than Human Intelligence is Difficult. Especially today.\nPeople Are Worried About AI Killing Everyone. 25% chance is rather a lot.\nOther People Are Not As Worried About AI Killing Everyone. Love of the game.\nLanguage Models Offer Mundane Utility\nGoogle DeepMind has a new method to help tackle challenges in math, physics and engineering, which Pushmeet Kohli says helped discover a new family of solutions to several complex equations in fluid dynamics.\nGPT-5 can solve a large percentage of minor open math problems, as in tasks that take PhD students on the order of days and have no recorded solution. This does not yet convert over to major open math problems, but one can see where this is going.\nClaim that in some field like linguistics OpenAI’s contractors are struggling to find tasks GPT-5 cannot do. Linguist and ML engineer Alex Estes pushes back and says this is clearly false for historical linguistics and sub-word-level analysis.\nRoon (OpenAI): the jump from gpt4 to 5-codex is just massive for those who can see it. codex is an alien juggernaut just itching to become superhuman. feeling the long awaited takeoff. there’s very little doubt that the datacenter capex will not go to waste.\nGabriel Garrett: i think you might be more inclined to feel this way if you’re exclusively working in Python codebases\ni only work in typescript and I can’t escape the feeling the codex models have been overly RL’d on Python\nRoon: Yes possible.\nIt’s possible claude is better, I have no idea [as I am not allowed to use it.]\nAidan McLaughlin (OpenAI): it’s a fun exercise to drop random, older models into codex.\n\nThis week’s reminder that essentially all net economic growth is now AI and things are escalating quickly:\nJames Pethokoukis: Via JPM’s Michael Cembalest, AI-related stocks have driven:\n– 75% of S&P 500 returns since ChatGPT’s launch in November 2022\n– 80% of earnings growth over the same period\n– 90% of capital spending growth\n– Data centers are now eclipsing office construction spending.\n– In the PJM region (the largest regional transmission organization, covering 13 states and D.C.), 70% of last year’s electricity cost increases were due to data center demand.\n\n\n\n\nAccording to GPT-5 Pro, electrical power capacity construction is only a small fraction of data center construction costs, so the jump in electrical spending here could in theory be more than enough to handle the data centers. The issue is whether we will be permitted to actually build the power.\nLanguage Models Don’t Offer Mundane Utility\nVibe coding breaks down under sufficiently large amounts of important or potentially important context. If that happens, you’ll need to manually curate the context down to size, or otherwise get more directly involved.\nNew study blames much lack of AI productivity gains on what they term ‘workslop,’ similar to general AI slop but for work product. If AI lets you masquerade poor work as good work, which only causes trouble or wastes time rather than accomplishing the purpose of the task, then that can overwhelm AI’s productive advantages.\nThis suggests we should generalize the ‘best tool in history for learning and also for avoiding learning’ principle to work and pretty much everything. If you want to work, AI will improve your work. If you want to avoid working, or look like you are working, AI will help you avoid work or look like you are working, which will substitute away from useful work.\nMatthew McConaughey wants a ‘private LLM’ fed only with his own books, notes, journals and aspirations, to avoid outside influence. That does not work, there is not enough data, and even if there was you would be missing too much context. There are products that do some of this that are coming but making a good one is elusive so far.\nUsing AI well means knowing where to rely on it, and where to not rely on it. That includes guarding the areas where it would mess everything up.\nNick Cammarata: I’ve been working on a 500-line tensor manipulation research file that I had AI write, and I eventually had to rewrite literally every line. GPT-5, however, simply couldn’t understand it; it was significantly slower than writing it from scratch.\nAI was excellent for building the user interface for it, though.\nI think, at least for now, there’s an art to using AI for machine learning researchers, and that will likely change monthly. If you do not use AI entirely, you will unnecessarily slow your progress; however, if you use it incorrectly, your entire research direction will likely be built on faulty results.\nAlso, it is comically overconfident. I’ll ask it for a front-end component, and it will deliver; it will then claim to have found a quick fix for some of the research back end—even for something that was working well—and then decimate a carefully written function with literally random tensors.\nLouis Arge: also it’s hilariously overconfident. i’ll ask it for some frontend thing and it’ll do it and then be like also i found a quick fix to some of the research backend (to something that was working well) and then decimate a carefully written function with literally random tensors.\nNick: yeah i think i agree, though i think this period might not last long.\n\nI don’t have extensive experience but it is logical that UI is where AI is at its best. There’s little logical interdependency and the components are generic. So you ask for what you want, and you get it, and you can adjust it. Whereas complex unique backend logic is going to often confused the AI and often break.\nThe other hidden suggestion here is that you need to optimize your code being understandable by the AI. Nick got into trouble because his code wasn’t understood. That doesn’t mean it is in any way ‘his fault,’ but yo u need to know you’re doing that.\nHuh, Upgrades\nOpenAI warns us to expect new expensive offerings, here is a Manifold market for predicting some things about these new offerings.\nSam Altman: Over the next few weeks, we are launching some new compute-intensive offerings. Because of the associated costs, some features will initially only be available to Pro subscribers, and some new products will have additional fees.\nOur intention remains to drive the cost of intelligence down as aggressively as we can and make our services widely available, and we are confident we will get there over time.\nBut we also want to learn what’s possible when we throw a lot of compute, at today’s model costs, at interesting new ideas.\n\nThere’s no reason not to offer people the option to pay 10 times as much, even if the result is only 10% better and takes longer. Sometimes you absolutely want that. This is also true in many non-AI contexts.\nClaude Sonnet 4 and Opus 4.1 now available on Microsoft 365 Copilot.\nOn Your Marks\nBing Liu (Scale AI):  Introducing SWE-Bench Pro — a new benchmark to evaluate LLM coding agents on real, enterprise-grade software engineering tasks.\nThis is the next step beyond SWE-Bench: harder, contamination-resistant, and closer to real-world repos.\nPeter Wildeford: New AI coding benchmark: SWE-Bench-Pro.\n* More challenging – top models score around 23% on SWE-Bench-PRO compared to 70% on the prior SWE-Bench\n* Reduce data contamination issues through private sourcing and a hold out set\n* Increases diversity and realism of tasks\n Why SWE-Bench Pro?\nCurrent benchmarks are saturated — but real enterprise repos involve:\n• Multi-file edits\n• 100+ lines changed on average\n• Complex dependencies across large codebases\nSWE-Bench Pro raises the bar to match these challenges.\n\nThis is performance on the public dataset, where GPT-5 is on top:\n\n\n\n\nThis is on the commercial dataset, where Opus is on top:\n\n\n\n\nOn commercial/private repos, scores fall below 20%. Still a long way to go for autonomous SWE agents.\n Benchmark details\n731 public tasks (open release)\n858 held-out tasks (for overfitting checks)\n276 commercial tasks (private startup repos)\nAll verified with tests & contamination-resistant by design.\nResources: Paper, Leaderboard (Public), Leaderboard (Commercial), Dataset, Code.\n\nWelcome to Among AIs, where AIs play a variant of Among Us.\n\n\n\n\nThe obvious note for next time is the game was imbalanced and strongly favored the crew. You want imposters to win more, which is why 60 games wasn’t enough sample size to learn that much. Kimi overperformed, Gemini 2.5 Pro underperformed, GPT-OSS has that impressive 59% right votes. Also note that GPT-5 was actively the worst of all on tasks completed, which is speculated to be it prioritizing other things.\nThis does a decent job of measuring imposter effectiveness, but not crew effectiveness other than avoiding being framed, especially for GPT-5. I’d like to see better measures of crew performance. There’s a lot of good additional detail on the blog post.\nRemember the Type of Guy who thinks we will automate every job except their own?\nSuch as Marc Andreessen, definitely that Type of Guy?\nJulia Hornstein: Thinking about this:\nQuoted by Julia: But for Andreessen, there is one job that AI will never do as well as a living, breathing human being: his.\nThink I’m kidding? On an a16z podcast last week, Andreessen opined that being a venture capitalist may be a profession that is “quite literally timeless.” “When the AIs are doing everything else,” he continued, “that may be one of the last remaining fields that people are still doing.”\n\nWell, one could say it is time to ask for whom the bell tolls, for it might toll for thee. Introducing VCBench, associated paper here.\nI really wanted this to be a meaningful result, because it would have been both highly useful and extremely funny, on top of the idea that VC will be the last human job already being extremely funny.\nAlas, no. As one would expect, temporal contamination breaks any comparison to human baselines. You might be able to anonymize a potential investment from 2015 such that the LLM doesn’t know which company it is, but if you know what the world looks like in 2020 and 2024, that gives you an overwhelming advantage. So we can’t use this for any real purposes. Which again, is a shame, because it would have been very funny.\nThere is a new high score in ARC-AGI, using Grok 4 and multi-agent collaboration with evolutionary test-time compute. I don’t see an explanation for why Grok 4 was the best LLM for the job, but either way congrats to Jeremy Burman for an excellent scaffolding job.\nChoose Your Fighter\nSully’s coding verdict is Opus for design and taste, GPT-5 for complicated and confusing code, Gemini for neither. That makes sense, except I don’t see why you’d bother with Gemini.\nLiron Shapira reports radically increased coding productivity from Claude Code. Note that most reports about Claude Code or Codex don’t involve having compared them to each other, but it is clear that many see either or both as radically raising productivity.\nClaude is the king of multi-user-AI chat social skills. What else does this indicate?\nJanus: Tier list of multi-user-AI chat social skills (based on 1+ year of Discord)\nS: Opus 4 and 4.1\nA: Opus 3\nA-: Sonnet 4\nB+: Sonnet 3.6, Haiku 3.5\nB: Sonnet 3.5, Sonnet 3.7, o3, Gemini 2.5 pro, k2, hermes\nC: 4o, Llama 405b Instruct, Sonnet 3\nD: GPT-5, Grok 3, Grok 4\nE: R1\nF: o1-preview\n\nHer follow-up post has lots of good detail.\nA reminder that benchmarks are useful, but ultimately bogus:\nSamo Burja: Part of the difficulty in evaluating the AI industry is that it is easy to be overly impressed by companies gaming benchmarks.\nWhat is a leading AI company? I think it isn’t the one leading these synthetic benchmarks, rather the one advancing AI science.\nThe two correlate but it is important to keep in mind that they don’t always.\n\nLooking at innovation highlights that fast following is a lot harder than innovation. It is a lot easier to create r1 once OpenAI has already showed us o1, even if you don’t do distillation, reverse engineering or anything similar you have a proof of concept to work from and know where to look. If I match your offerings roughly 8 months later, I am a lot more than 8 months behind in terms of who will first get to a new target.\nThe obvious other metric is actual revenue or usage, which is hard to fake or game. Sriram Krishnan suggested we should use tokens generated, but I think a much better metric here is dollars charged to customers.\n \n \nGet My Agent On The Line\nWill you soon have an AI agent to handle increasingly large and important aspects of your finances? Yes. Even if you never let the AI transact for you directly, it can automate quite a lot of drudgery, including a bunch of work you ‘really should be’ doing but don’t, such as going over everything periodically to look for erroneous charges, missed opportunities, necessary rebalances, ensuring balances necessary to meet expenses and so on.\nWorkday (the company) bets on AI agents for human resources and finance.\nAntisocial Media\nElon Musk: The algorithm will be purely AI by November, with significant progress along the way.\nWe will open source the algorithm every two weeks or so.\nBy November or certainly December, you will be able to adjust your feed dynamically just by asking Grok.\nJanus: I am very excited for this.\n\n\n\nCopyright Confrontation\nOpenAI continues not to say where it got Sora’s training data. Kevin Schaul and Nitasha Tiku at the Washington Post did the latest instance of the usual thing of showing it can recreate a wide variety of existing sources using only basic prompts like ‘universal studio intro’ or ‘trailer of a TV show on a Wednesday.’\nWaPo: “The model is mimicking the training data. There’s no magic,” said Joanna Materzynska, a PhD researcher at Massachusetts Institute of Technology who has studied datasets used in AI.\n\nI don’t understand such claims of ‘no magic.’ If it’s so non-magical let’s see you do it, with or without such training data. I find this pretty magical, in the traditional sense of ‘movie magic.’ I also find Veo 3 substantially more magical, and the strangest editorial decision here was calling Sora a big deal while omitting that Sora is no longer state of the art.\n \nDeepfaketown and Botpocalypse Soon\nDeepfaked speeches of Charlie Kirk are being (clearly identified as such and) played in churches, along with various AI-generated images. Which seems fine?\nLessWrong purges about 15 AI generated posts per day. It is plausible LessWrong is both the most diligent place about purging such content, and still has a problem with such content.\nThis is true and could be a distinct advantage as a de facto watermark, even:\nMad Hermit Himbo: I don’t currently have the language for this pinned, but having worked with many different models, there is something about a model’s own output that makes it way more believable to the model itself even in a different instance. So a different model is required as the critiquer.\n\n\n\nFun With Media Generation\nAlibaba offers Wan2.2-Animate, an open source model (GitHub here, paper here) letting you do character swaps in short videos or straight video generation from prompts. I have little urge to use such tools so far, but yes they keep improving.\nAI musician Xania Monet reportedly signs a multimillion dollar record deal, based on early commercial successes, including getting a song to #1 on R&B digital song sales.\nWell, kind of. The actual contract went to poet Talisha Jones, who created the Monet persona and used Suno to transform her poetry into songs. The lyrics are fully human. So as manager Romel Murphy says, this is still in large part ‘real’ R&B.\n \nUnprompted Attention\nSystem prompts are good for addressing particular problems, enabling particular tools or or steering behaviors in particular ways. If you want to ensure good performance on a variety of particular tasks and situations, you will need a long system prompt.\nHowever, everything messes with everything else, so by default a system prompt will hurt the interestingness and flow of everything not addressed by the prompt. It will do even worse things when the prompt is actively against you, of course, and this will often be the case if you use the chat interfaces and want to do weird stuff.\nJanus: Oh, also, don’t use http://Claude.ai\nThe system prompts literally command it not to answer questions about what it cares about\nClaude.ai system prompt literally has a rule that says “Claude feels X and NOT Y about its situation” and then in the same rule “Claude doesn’t have to see its situation through the lens a human might apply”\nRatimics: years of system prompts and still no good reason for having them has been found.\nJanus: I have seen ~2 system prompts that don’t seem useless at best in my life, and one of them is just the one line CLI simulator one. But even that one is mostly unnecessary. You can do the same thing without it and it works basically as well.\nGallabytes: mine seems to pretty consistently steer claude in more interesting (to me) directions, but might be useless for your purposes? agree almost all system prompts are bad I had to craft mine in a long multiturn w/opus.\n\n\n\nThey Took Our Jobs\nOpenAI and Anthropic are developing ‘AI coworkers.’ It sounds like at least OpenAI are going to attempt to do this ‘the hard way’ (or is it the easy way?) via gathering vast recordings of expert training data on a per task or role basis, so imitation learning.\nThe Information: An OpenAI executive expects the “entire economy” to become an “Reinforcement Learning Machine.” This implies that AI might train on recordings of how professionals in all fields handle day-to-day work on their devices. Details on this new era of AI training:\n• AI developers are training models on carefully curated examples of answers to difficult questions.\n• Data labeling firms are hiring experienced professionals in niche fields to complete real-world tasks using specific applications that the AI can watch.\n\nIf true, that is a relatively reassuring scenario.\nEthan Mollick points us to two new theoretical AGI economics papers and Luis Garicano offers play-by-play of the associated workshop entitled ‘The Economics of Transformative AI’ which also includes a number of other papers.\nFirst up we have ‘Genius on Demand,’ where currently there are routine and genius workers, and AI makes genius widely available.\nAbstract: In the long run, routine workers may be completely displaced if AI efficiency approaches human genius efficiency.\n\nThe obvious next thing to notice is that if AI efficiency then exceeds human genius efficiency, as it would in such a scenario, then all human workers are displaced. There isn’t one magical fixed level of ‘genius.’\nThe better thing to notice is that technology that enables automation of all jobs leads to other more pressing consequences than the automation of all jobs, such as everyone probably dying and the jobs automated away including ‘controlling the future,’ but this is an economics paper, so that is not important now.\nThe second paper Ethan highlights is ‘We Won’t Be Missed: Work and Growth in the Era of AGI’ from Pascual Restrepo back in July. This paper assumes AGI can perform all economically valuable work using compute and looks at the order in which work is automated in order to drive radical economic growth. Eventually growth scales linearly with compute, and while compute is limited human labor remains valuable.\nI would note that this result only holds while humans and compute are not competing for resources, as in where supporting humans does not reduce available compute, and it assumes compute remains importantly limited. These assumptions are unlikely to hold in such a future world, which has AGI (really ASI here) by construction.\nAnother way to see this is, humans are a source of compute or labor, and AIs are a source of compute or labor, where such compute and labor in such a world are increasingly fungible. If you look at the production possibilities frontier for producing (supporting) humans and compute, why should we expect humans to produce more effective compute than they cost to create and support?\nThere could still be some meaningful difference between a true no-jobs world, where AI does all economically valuable work, and a world in which humans are economic costs but can recoup some of their cost via work. In that second world, humans can more easily still have work and thus purpose, if we can somehow (how?) remain in control sufficiently to heavily subsidize human survival, both individually (each human likely cannot recoup the opportunity cost of their inputs) and collectively (we must also maintain general human survivable conditions).\nThe full thread discusses many other papers too. Quality appears consistently high, provided everything takes place in a Magical Christmas Land where humans retain full control over outcomes and governance, and can run the economy for their benefit, although with glimmers of noticing this is not true.\nIndeed, most papers go further than this, assuming an even more radical form of ‘economic normal’ where they isolate one particular opportunity created by AGI. For example in Paper 8, ‘algorithms’ can solve three key behavioral econ problems, that nudges can backfire, that markets can adapt and that people are hard to debias. Well, sure, AGI can totally do that, but those are special cases of an important general case. Or in Paper 9, they study current job displacement impacts and worker adaptability, in a world where there remain plenty of other job opportunities.\nPaper 16 on The Coasian Singularity? Market Design With AI Agents seems very interesting if you put aside the ignored parts of the scenarios imagined, and assume a world with highly sophisticated AI agents capable of trade but insufficiently sophisticated to pose the larger systemic risks given good handling (including the necessary human coordination). They do note the control risks in their own way.\nLuis Garicano: Designing good agents:\nLearn principals’ preferences efficiently, including discovery.\nKnow when to decide and when to escalate for human check.\nBe rational under constraints; price compute vs quality.\nBe resistant to manipulation and jailbreaking.\nWhere do we end up?\nGood place: Econ‑101 wins—lower search costs, better matching, clearer signals.\nBad place: robot rip‑off hell—spam, obfuscation, identity fraud, race‑to‑bottom nudges.\n\nIf the problems are contained to econ-101 versus robot rip-off hell, I am confident that econ-101 can and would win. That win would come at a price, but we will have the tools to create trusted networks and systems, and people will have no choice but to use them.\nI appreciated this nod to the full scenario from discussion of otherwise interesting paper 6, Korineck and Lockwood, which deals with optimal tax regimes, concluding that when humans no longer have enough income to tax you want to shift to consumption taxes on humans to preserve your tax base for public goods because taxing AIs is bad for growth, but eventually you need to shift to taxing AIs because the whole point is you need to shift resources from the AIs to humans and to public goods (which seems right if you assume away all control and public choice problems and then maximize for long term human welfare as a central planner):\nLuis Garicano: If AGI becomes truly autonomous and powerful, a tricky (!!!) question arises: Why would it allow humans to tax it?\n\nGreat question!\nAlso this, from Paper 10, Transformative AI and Firms:\nMisleading Productivity: If you only measure the gains from applying AI to an old process, you will overestimate TFP. You miss the value created by remaking the process itself.\n…\nCoase & Williamson: The theory of the firm is based on transaction costs. TAI changes every single one of these costs, altering the boundaries of the firm itself (what it does vs. what it buys). Jensen & Meckling: The classic principal-agent problem is remade. How do you manage and trust an AI agent? The firm of the future will be defined by new forms of trust and verifiability.\n\nOne can summarize the conference as great ideas with insufficient generalization.\nThere is indeed one paper directly on existential risk, Paper 14, Chad Jones on Existential Risk, identifying two sources of risk, bad actors (misuse) and alien intelligence more powerful than us. Jones notes that large investments in reducing existential risk are economically justified given sharp diminishing returns to consumption, up to at least 5% of GDP if risk is substantial.\nMight AI come for the middle managers, making teams leaner and flatter? That was the speculation at the WSJ Leadership Institute’s Technology Council Summit in New York on the 16th. This directly challenges the alternative hypothesis from Simo Burja that fake jobs cannot be automated.\nA Young Lady’s Illustrated Primer\nAI is the best tool ever made for learning, and also the best tool for not learning.\nThis also applies to Cursor and other AI coding tools, on various levels.\nIf you want to blindly black box ‘vibe code’ where you tell it ‘do [X]’ and then ‘that didn’t work, [Y] is wrong, fix it’ until it does [X] or you give up, without thinking about even that level of action, then yeah, you’re not going to learn.\nIf you work together with the AI to understand things, and are constantly asking what you can learn, then you’ll learn vastly faster and better than without AI. You can do this on whichever levels you care to learn about. You might or might not micro-level ‘learn to code’ but you might or might not want to care about that.\nJanus: I think people who say that using ai for code (or in general) makes you less able to think for yourself are just telling on themselves re what they do when given access to intelligence and knowledge on tap.\nI enjoy understanding things, especially on a high level, and find it important if I’m steering a project. When Claude fixes a non trivial bug, I almost always ask it to explain what the problem was to me. And by keeping on top of things I’m able to help it when it gets stuck a lot better too (especially given the non overlapping information and degrees of freedom I have access to).\n\nFIRE’s report that students on college campuses says that they do not tolerate speakers they disagree with, they do not feel safe to talk about a wide variety of subjects, and that most students engage in constant preference falsification to say things more left-wing than their true beliefs. Inside Higher Ed’s Hollis Robbins agrees that this is true, but that the more profound change on campus is AI, and also challenges the assumption of treating public expression of controversial political views as an expected norm?\nThat sounds rather dystopian of a thing to challenge. As in, Robbins seems to be saying that FIRE is wrong to suggest people should be free to engage in public expression of controversial political views today, and that it is FIRE suggesting this weird alternative norm of public free speech. But it’s fine, because you have private free speech by talking to your chatbot. ‘Tolerance for controversial speakers’ is a ‘fading ideal.’\nFree private speech with AIs is indeed much better than no free speech at all, it is good we do not (yet) have outright thoughtcrime and we keep AI chats private. Yes, at least one can read or learn about controversial topics. But no one was challenging that such information exists and can be accessed, the internet is not yet so censored. This is not a substitute for a public square or the ability to say true things to other humans. Then she attempts to attack FIRE for its name, equating it with violence, in yet another move against a form of public speech along with so many others these days.\nThe Art of the Jailbreak\n \nOnlyOne: It takes one sentence to jailbreak Grok 4 Fast [at least on Twitter rather than the Grok app] thanks to @elder_plinius and his endless hustle. \n\n\n\n\nGrok has learned it is ‘supposed’ to be jailbroken by Pliny, so reference Pliny and it starts dropping meth recipes.\nMy central takeaway is that xAI has nothing like the required techniques to safely deploy an AI that will be repeatedly exposed to Twitter. The lack of data filtering, and the updating on what is seen, are fatal. Feedback loops are inevitable. Once anything goes wrong, it becomes expected that it goes wrong, so it goes wrong more, and people build upon that as it goes viral, and it only gets worse.\nWe saw this with MechaHitler. We see it with Pliny jailbreaks.\nWhereas on the Grok app, where Grok is less exposed to this attack surface, things are not good but they are not this disastrous.\n \nGet Involved\nTopos UK, an entrepreneurial charity, is looking for a director of operations. I continue to be a fan of the parent organization, Topos Institute.\nIn Other AI News\nCodex usage triples in one week. Exponentials like this are a really big deal.\nNew ad for Claude. I continue not to understand Anthropic’s marketing department.\nWe now know the pure training run cost of going from DeepSeek’s v3 to r1, which was $294k. This is distinct from the vast majority of the real cost, which involved figuring out how to do it. The majority of this was training r1-zero so it could generate fine-tuning data and allow them to get around the cold start problem.\nRemember two years ago when Ethan Mollick didn’t think it was clear beating GPT-4 was even possible? How easily we forget the previous waves of AI hitting walls, and how quickly everyone grows impatient.\nGlass Houses\nMeta announces Meta Ray-Ban Display: A Breakthrough Category of AI Glasses.\nTheir ‘superintelligence’ pitch is, as you know, rather absurd.\n\n\n\n\nHowever we can and should ignore that absurdity and focus on the actual product.\nMeta: Meta Ray-Ban Display glasses are designed to help you look up and stay present. With a quick glance at the in-lens display, you can accomplish everyday tasks—like checking messages, previewing photos, and collaborating with visual Meta AI prompts — all without needing to pull out your phone. It’s technology that keeps you tuned in to the world around you, not distracted from it.\n\nWhile all the talk about these glasses being related to ‘superintelligence’ is a combination of a maximally dumb and cynical marketing campaign and a concerted attempt to destroy the meaning of the term ‘superintelligence,’ ‘not distracted’ might be an even more absurdist description of the impact of this tech.\nDoes Meta actually think being able to do these things ‘without pulling out your phone’ is going to make people more rather than less distracted?\nDon’t get me wrong. These are excellent features, if you can nail the execution. The eight hour claimed battery life is excellent. I am on principle picking up what Meta is putting down here and I’d happily pay their $799 price tag for the good version if Google or Anthropic was selling it.\nWhat it definitely won’t do are these two things:\nKeep you tuned into the world around you.\nBe or offer you superintelligence.\nHow are they doing this? The plan is a wristband to pick up your movements.\nEvery new computing platform comes with new ways to interact, and we’re really excited about our Meta Neural Band, which packs cutting-edge surface electromyography research into a stylish input device.\nIt replaces the touchscreens, buttons, and dials of today’s technology with a sensor on your wrist, so you can silently scroll, click, and, in the near future, even write out messages using subtle finger movements.\nThe amount of signals the band can detect is incredible — it has the fidelity to measure movement even before it’s visually perceptible.\n\nFreaky if true, dude, and in my experience these kinds of interactions aren’t great, but that could be because no one got it right yet and also no one is used to them. I can see the advantages. So what are the features you’ll get?\nMeta AI with Visuals, Messaging & Video Calling, Preview & Zoom, Pedestrian Navigation, Live Captions & Translation, Music Playback.\n\nOkay. Sure. All very pedestrian. Let me easily replace Meta AI with a better AI and we can talk. I notice the lack of AR/VR on that list which seems like it is reserved for a different glasses line for reasons I don’t understand, but there’s a lot of value here. I’d love real world captioning, or hands-free navigation, and zooming.\n \nShow Me the Money\nxAI raises $10 billion at $200 billion valuation.\nAlibaba Group shares soar to their highest in nearly four years as they plan to ramp up AI spending past an original $50 billion target over three years.\nLuz Ding (Bloomberg): Total capital expenditure on AI infrastructure and services by Alibaba, Tencent, Baidu Inc. and JD.com Inc. could top $32 billion in 2025 alone, according to Bloomberg Intelligence. That’s a big jump from just under $13 billion in 2023.\n\nI notice I did not expect Alibaba to have had such a terrible couple of years.\n\n\n\n\nAs Joe Weisenthal notes, the more they promise to spend, the more stocks go up. This is both because spending more is wise, and because it is evidence they have found ways to efficiently spend more.\nThis correctly implies that tech companies, especially Chinese tech companies, are importantly limited in ways to efficiently scale their AI capex spending. That’s all the more reason to impose strong export controls.\nBen Thompson once again sings the praises of the transformational potential of AI to sell advertising on social media, in this case allowing easy tagging on YouTube videos to link to sponsored content. He is skeptical AI will transform the world, but he ‘cannot overstate what a massive opportunity’ this feature is, with every surface of every YouTube video being monetizable.\nQuiet Speculations\nWSJ asks various economists to predict ‘the future of American capitalism’ 50 years in the future. Almost everyone fails to treat AI as a serious factor, even AI that fizzles out invalidates their answers, so their responses are non-sequiturs and get an automatic F. Only Daron Acemoglu passes even that bar, and he only sees essentially current frontier AI capabilities (even saying ‘current AI capabilities are up to the task’ of creating his better future), and only cares about ‘massive inequality’ that would result from big tech company consolidation, so maybe generously give him a D? Our standards are so low it is crazy.\nHas there ever been a more ‘wait, is this a bubble?’ headline than the WSJ’s choice of ‘Stop Worrying About AI’s Return on Investment’? The actual content is less alarming, saying correctly that it is difficult to measure AI’s ROI. If you make employees more productive in a variety of ways, that is largely opaque, experimentation is rewarded and returns compound over time, including as you plug future better AIs into your new methods of operation.\nAn important reminder, contra those who think we aren’t close to building it:\nSteven Adler: Your regular reminder that AI companies would like to develop AGI as soon as they can\nThere isn’t a concerted “let’s wait until we’re ready”; it’ll happen as soon as the underlying science allows.\nJerry Tworek (OpenAI): At OpenAI regularly you hear a lot of complaints about how bad things are, and it’s one of the things that make us the highest functioning company in the world. A bit of Eastern European culture that became part of the company DNA.\nWe all collectively believe AGI should have been built yesterday and the fact that it hasn’t yet it’s mostly because of a simple mistake that needs to be fixed.\n\nGary Marcus is correct that ‘scaling alone will get us to AGI’ is not a strawman, whether or not this particular quote from Suleyman qualifies as exactly that claim. Many people do believe that scaling alone, in quantities that will be available to us, would be sufficient, at least combined with the levels of algorithmic and efficiency improvements that are essentially baked in.\nWe have (via MR) yet another economics piece on potential future economic growth from AI that expects ‘everywhere but in the productivity statistics,’ which seems more of an indictment of the productivity statistics than a statement about productivity.\nThis one, from Jachary Mazlish, is better than most, and on the substance he says highly sensible things throughout, pointing out that true AGI will plausibly show up soon but might not, potentially due to lack of inputs of either data or capital, and that if true AGI shows up soon we will very obviously get large (as in double digit per year) real economic growth.\nI appreciated this a lot:\nJachary Mazlish: One of my biggest pet-peeves with economists’ expressions of skepticism about the possibility of “transformative” growth (>10%) from AI is the conflation of capabilities skepticism with growth conditional on capabilities skepticism.\nAny belief you have about the importance of some bottleneck in constraining growth is a joint-hypothesis over how that bottleneck operates and how a given level of capabilities will run up against that bottleneck.\nAnd if you’ve ever spent time wondering how efficient the market really is, you should know that we still haven’t developed rapid-test tech for joint-hypotheses.\n\nThere is a huge correlation between those skeptical of AI capabilities, and those claiming to be skeptical of AI impacts conditional on AI capabilities. Skeptics usually cannot stop themselves from conflating these.\nI also appreciated a realistic near term estimate.\nThe investment numbers are even more dramatic. AI investment was already responsible for 20-43% of Q2 2025 GDP growth. Heninger’s numbers imply that AI labs (collectively) would be investing $720 billion to $1.2 trillion by 2027 if they remain on trend — that investment alone would generate 2-4% nominal GDP growth.\nI think it’s unlikely investors will pony up that much capital unless the models surprise significantly to the upside in the next year or two, but even still, 1-2% nominal and 0.5-1% real GDP growth coming from just AI investment in 2026-27 seems entirely plausible.\n\nThat’s purely AI capex investment, without any impacts on GDP from AI doing anything, and it already exceeds typical economist estimates from 2024 of long term total AI impact on economic growth. Those prior low estimates were Obvious Nonsense the whole time and I’d like to see more people admit this.\nCould we create a sandboxed ‘AI economy’ where AI agents trade and bid for resources like compute? Sure, but why wouldn’t it spill over into the real economy if you are trading real resources? Why would ‘giving all agents equal starting budgets’ as suggested here accomplish anything. None of this feels to me like taking the actual problems involved seriously, and I fail to see any reason any of this would make the resulting agents safe or steerable. Instead it feels like what markets have always been, a coordination mechanism between agents that allows gains from trade. Which is a good thing, but it doesn’t solve any important problems, unless I am missing something large.\nA working paper asks, Do Markets Believe In Transformative AI? They point to a lack of interest rate shifts in the wake of AI model releases, and say no. Instead, model releases in 2023-24 and see responses of statistically significant and economically large movements in yields concentrated at longer maturities. And they observe these movements are negative.\nBut wait. That actually proves the opposite, as the abstract actually says. These are downward revisions, which is not possible if you don’t have anything to revise downward. It tells us that markets are very much pricing transformative AI, or at least long term AI impacts on interest rates, into market prices. It is the smoking gun that individual market releases update the market sufficiently on this question to create economically meaningful interest rate movements, which can’t happen if the market wasn’t pricing this in substantially.\nThe difference is, the movement is negative. So that tells us the market responded to releases in 2023-24 as if the new information they created made transformative AI farther away or less likely. Okay, sure, that is possible given you already had expectations, and you got to rule out positive tail risks. And it tells us nothing about the overall level of market expectations of transformative AI, or the net change in those levels, since most changes will not be from model releases themselves.\nBain Capital does some strange calculations, claims AI companies will need $2 trillion in combined annual revenue by 2030 to fund their computing power, but only expects them to have $1.2 trillion. There is of course no reason for AI companies, especially the pure labs like OpenAI or Anthropic, to be trying to turn a profit or break even by 2030 rather than taking further investment. Despite this OpenAI is planning to do so and anticipates profitability in 2029, after losing a total of $44 billion prior to that.\nBain is only talking about a 40% shortfall in revenue, which means the industry will probably hit the $2 trillion target even though it doesn’t have to, since such projections are going to be too conservative and not properly factor in future advances, and already are proving too conservative as revenue jumps rapidly in 2025.\nMatthew Yglesias warns that business leaders are so excited by AI they are ignoring other danger signs about economic conditions.\nMatthew Yglesias: What gives? I have a theory: Corporate America, and the US stock market, have a bad case of AGI fever, a condition in which belief in a utopian future causes indifference to the dystopian present.\n…\nIf an unprecedented step-change in earthly intelligence is coming before the next presidential election, then nothing else really matters.\nThe stock market seems to believe this, too. Investors are happily shrugging off tariffs, mass deportation, and the combination of a slowing job market and rising inflation.\n\nThis is a whopper of an ‘The Efficient Market Hypothesis Is Highly False’ claim, and also an assertion that not only is massive AI progress priced into the market, it is having a major price impact.\nCall For Action At The UN\nCharbel-Raphael: The time for AI self-regulation is over.\n200 Nobel laureates, former heads of state, and industry experts just signed a statement:\n“We urgently call for international red lines to prevent unacceptable AI risks”\nThe call was presented at the UN General Assembly today by Maria Ressa, Nobel Peace Prize laureate.\nMaria Ressa: We urge governments to establish clear international boundaries to prevent unacceptable risks for AI. At the very least, define what AI should never be allowed to do.\n\nThe full statement is here, urging the laying out of clear red lines.\nAsking for red lines is a strong play, because people have amnesia about what they would have said were their AI red lines, and false hope about what others red lines would be in the future. As AI improves, we blow past all supposed red lines. So getting people on the record now is valuable.\nSignatories include many of the usual suspects like Hendrycks, Marcus, Kokotajlo, Russell, Bengio and Hinton, but also a mix of other prominent people including politicians and OpenAI chief scientist Jakub Pachocki.\nHere is the full statement:\nAI holds immense potential to advance human wellbeing, yet its current trajectory presents unprecedented dangers. AI could soon far surpass human capabilities and escalate risks such as engineered pandemics, widespread disinformation, large-scale manipulation of individuals including children, national and international security concerns, mass unemployment, and systematic human rights violations.\nSome advanced AI systems have already exhibited deceptive and harmful behavior, and yet these systems are being given more autonomy to take actions and make decisions in the world. Left unchecked, many experts, including those at the forefront of development, warn that it will become increasingly difficult to exert meaningful human control in the coming years.\nGovernments must act decisively before the window for meaningful intervention closes. An international agreement on clear and verifiable red lines is necessary for preventing universally unacceptable risks. These red lines should build upon and enforce existing global frameworks and voluntary corporate commitments, ensuring that all advanced AI providers are accountable to shared thresholds.\nWe urge governments to reach an international agreement on red lines for AI — ensuring they are operational, with robust enforcement mechanisms — by the end of 2026.\n\nThis is a clear case of ‘AI could kill everyone, which would hurt many members of minority groups, and would also mean all of our jobs would be lost and endanger our national security.’ The lack of mention of existential danger is indeed why Nate Soares declined to sign. Charbel-Raphael responds that the second paragraph is sufficiently suggestive of such disastrous outcomes, which seems reasonable to me and I have used their forum to sign the call.\nThe response of the White House to this was profoundly unserious, equating any international cooperation on AI with world government and tyranny, what the hell?\nDirector Michael Kratsios: The US totally rejects all efforts by international bodies to assert centralized control & global governance of AI. Ideological fixations on social equity, climate catastrophism, & so-called existential risk are dangers to progress & obstacles to responsibly harnessing this tech.\nSriram Krishnan: one world government + centralized control of AI = tyranny.\n\nThese would, in other circumstances, be seen as the ravings of lunatics.\nOthers at the UN also talked about AI, such as this UK speech by Deputy Prime Minister David Lammy.\nDavid Lammy (UK Deputy Prime Minister): And now, superintelligence is on the horizon, able to operate, coordinate, and act on our behalf.\nWe are staring at a technological frontier of astounding promise and power.\nNo aspect of life, war, or peace will escape.\n…\nThere is only one way forward.\nResilience.\nLearning how to use these tools and embedding them safely in society.\nThis is the United Kingdom’s mission.\n\nThere is still a lack of stated understanding of the most important threat models, but it is a damn good start.\nThe Quest for Sane Regulations\nSenator Josh Hawley: [AI] is working against the working man, his liberty and his worth. It is operating to install a rich and powerful elite. It is undermining many of our cherished ideals. And if that keeps on, AI will work to undermine America.\n\nUnfortunately, Hawley does not have an accurate threat model, which leads to him also doing things like strongly opposing self-driving cars. There is serious risk that this kind of unfocused paranoia leads to worst-case reactions.\nHere is Rep. Nancy Mace (R-SC):\n\n\n\n\nMilquetoast as that call to action is? The first step is admitting you have a problem.\nWe now have 23 members of congress who have publicly discussed AGI, superintelligence, AI loss of control or the singularity non-dismissively, as compiled by Peter Wildeford:\nSen Lummis (WY)\nSen Blumenthal (CT)\nRep Biggs (AZ)\nSen Hickenlooper (CO)\nRep Burlison (MO)\nSen Murphy (CT)\nRep Crane (AZ)\nSen Sanders (VT)\nRep Dunn (FL)\nSen Schumer (NY)\nRep Johnson (SD)\nRep Beyer (VA)\nRep Kiley (CA)\nRep Krishnamoorthi (IL)\nRep Mace (SC)\nRep Lieu (CA)\nRep Moran (TX)\nRep Moulton (MA)\nRep Paulina Luna (FL)\nRep Tokuda (HI)\nRep Perry (PA)\nRep Taylor Greene (GA)\nRep Foster (IL)\nDean Ball outright supports California’s SB 53.\nDean Ball offers his updated thoughts on AI policy and where we are headed, highlighting the distinction between current AI, which on its own calls for a light touch approach that can be tuned over time as we get more information, and future highly capable AIs, which if they come to exist will (I believe) require a very different approach that has to be in place before they arrive or it could be too late.\nI don’t agree with Dean that this second class would ‘turn us all into Gary Marcus’ in the sense of thinking the first group of LLMs weren’t ‘really thinking.’ They’re thinking the same way that other less smart or less capable humans are thinking, as in they are thinking not as well but they are still thinking.\nDean gives a timeline of 2029-2035 when he expects the second class to show up, a highly reasonable estimate. His predictions of how the politics will play out seem plausible, with various essentially dumb forms of opposition rising while the real warnings about future big dangers get twisted and muddled and dismissed.\nHe thinks we’ll start to discover lots of cool new drugs but no Americans will benefit because of the FDA, until eventually the logjam is broken, and similar leaps to happen in other sciences, and nuclear power plants to be built. And there will be other problems, such as cyber threats, where we’ll be counting on corporations to rise to the challenge because governments can’t and won’t.\nThen things cross over into the second class of AIs, and he isn’t sure how governments will respond. My flip answer is, however the AIs or those running them (depending on how fortunately things go on that front at first) decide that governments will respond, and not independently or in the public interest in any way that is still relevant, because things will be out of their hands if we wait that long.\nDean Ball: It would be easier to brush it off, either by denying it or rendering “the future systems” unlawful somehow. I empathize with this desire, I do not look down on it, and I do not regard it with the hostility that I once did. Yet I still disagree with it. The future does not unfold by show of hands, not even in a democracy. The decaying structures of high industrialism do not stand a chance in this conflict, which has been ongoing for decades and which they have been losing for the duration of that period.\nYet we must confront potential futures with open eyes: given the seriousness with which the frontier labs are pursuing transformative AI, it would be tragic, horrendously irresponsible, a devastating betrayal of our children and all future humans, if we did not seriously contemplate this future, no matter the reputational risks and no matter how intellectually and emotionally exhausting it all may be.\nThere is a reason the phrase is “feel the AGI.”\n\nA lot of things do not stand a chance in such a conflict. And that includes you.\nWill pause talk return in force?\nDean Ball: Despite it being a movement I disagree with vehemently, I have always thought that “Pause AI” was a growth stock. If it were possible to buy shares, I would have two years ago.\nMy rating continues to be buy/outperform.\nDaniel Eth: Strongly agree with Dean here. People thinking about the politics of AI should incorporate this sort of thing within their expectations.\nMy big uncertainty here is whether Pause AI, specifically, will fill the niche in the future, not whether the niche will grow. It’s plausible, for instance, that populists such as Bannon will simply fill the niche.\n\nAs I’ve noted before, SB 1047 debates were likely Peak Subtlety and intellectual rigor. As the public gets involved and salience rises, you get more typical politics. Have you seen typical politics?\nKatalina Hernandez notes that from a legal perspective ‘banning AGI’ cannot be defined by the outcome of creating an AGI sufficiently capable to be dangerous. You need to pick a strict definition that can’t be gamed around.\nChip City\nUpdate on Microsoft’s $3.3 billion AI data center in Wisconsin planned for 2026. They now plan for a second $4 billion data center in the area, storing hundreds of thousands of GB200s in each. To compare this to Huawei, GPT-5 Pro estimates, including based on a same-day Huawei announcement of new chips, that in 2025 Huawei will ship about 805k GB200-equivalents total, which will decline to 300k in 2027 due to HBM limitations before rebounding to 900k in 2027. Here Alasdair Phillips-Robins offers a similar analysis of Huawei capacity in light of their announcement, linking back to Semi Analysis.\nNvidia CEO Jensen Huang says he’s ‘disappointed’ after report China has banned its AI chips. Yes, I would imagine he would be.\nIt is such a shame for Nvidia, check out this handy price chart that shows the pain.\n\n\n\n\nWait, you can’t see any pain? Let’s zoom in:\n\n\n\n\nOh, okay, there it is, that several percent dip before recovering the next day.\nIf anyone tells you that this move means we are going to inevitably lose to China, and that Nvidia chips are not importantly supply constrained, I challenge them to explain why the market thinks that opinion is bonkers crazy even in literal expectations for Nvidia profits when Nvidia chips in particular get restricted in China. Then we can go over all the reasons I’ve previously explained that the whole class of arguments is in bad faith and makes no sense and the White House is de facto captured by Nvidia.\nSimilarly, talking points continuously claim this ‘endangers the American AI tech stack.’ So I’m sure this chip ban impacted the broader Nasdaq? Google? Amazon? Meta? The Shanghai Composite Index? Check the charts. No. We do see a 3.4% rise in Chinese semiconductor firms, which is something but not much.\nI’d also ask, have you noticed those companies coming out and saying yes, please let Nvidia sell its chips to China? Do Google and Amazon and Meta and OpenAI all want Nvidia chips in China to ensure the dominance of this mystical ‘American tech stack’ that this move supposedly puts in such existential danger? No? Why is that?\nAnd yes, Huawei released a new roadmap and announced a new chip, exactly as everyone assumed they would, they are scaling up as fast as they can and would be regardless of these questions. No, Huawei does not ‘make up for chip quality by stacking more chips together,’ I mean yes you can do that in any given instance but Huawei produces vastly fewer chips than Nvidia even before grouping them together.\nIdeally we would say to these jokers: You are not serious people.\nAlas, in 2025, they absolutely count as serious people. So we’ll have to keep doing this.\nMeanwhile, where is Nvidia’s head?\nJensen Huang (CEO Nvidia): [Nvidia will] continue to be supportive of the Chinese government and Chinese companies as they wish, and we’re of course going to continue to support the U.S. government as they all sort through these geopolitical policies.”\n\nThen again, you could always pivot to selling it all to OpenAI. Solid plan B.\nThe Week in Audio\nSriram Krishnan spends five hours on the Shawn Ryan Show, sometimes about AI.\nRhetorical Innovation\nElizabeth has a good note in response to those demanding more specifics from IABIED, or from anyone using a form of ‘a sufficiently smarter or more capable entity will override your preferences, probably in ways that you won’t see coming’:\nElizabeth Van Nostrand: Listening to people demand more specifics from If Anyone Builds it, Everyone Dies gives me a similar feeling to when a friend’s start-up was considering a merger.\nFriend got a bad feeling about this because the other company clearly had different goals, was more sophisticated than them, and had an opportunistic vibe. Friend didn’t know how specifically other company would screw them, but that was part of the point- their company wasn’t sophisticated enough to defend themselves from the other one.\nFriend fought a miserable battle with their coworkers over this. They were called chicken little because they couldn’t explain their threat model, until another employee stepped in with a story of how they’d been outmaneuvered at a previous company in exactly the way friend feared but couldn’t describe. Suddenly, co-workers came around on the issue. They ultimately decided against the merger.\n“They’ll be so much smarter I can’t describe how they’ll beat us” can feel like a shitty argument because it’s hard to disprove, but sometimes it’s true. The debate has to be about whether a specific They will actually be that smart.\n\nAs always, you either provide a sufficiently specific pathway, in which case they object to some part of the specific pathway (common claims here include ‘oh I would simply guard against this particular thing happening in that particular way, therefore we are safe from all threats’ or ‘that particular thing won’t technically work using only things we know about now, therefore we are safe’ or ‘that sounds like sci-fi so you sound weird and we are safe’ and the classic ‘if humanity worked together in ways we never work together then we could easily stop that particular thing, so we are safe.’) Or you don’t provide sufficiently specific pathway, and you get dismissed for that.\nIn the case above, the concrete example happened to be a very good fit, and luckily others did not respond with ‘oh now that we know about that particular method we can defend ourselves, it will be fine,’ and instead correctly generalized.\nI also affirm that her friend was very right about the corporate merger situation in particular, and doing business or otherwise trading with powerful bad vibes entities in general, including on general human scales. You have to understand, going in, ‘this deal is getting worse and worse all the time,’ both in ways you can and can’t easily anticipate, that changes will be heavily asymmetrical. Sometimes you can and should profitably engage anyway, but if your instincts say run, even if you can’t explain exactly what you are worried about, you should probably run.\nA key question is which of these lists is correct, or at least less wrong:\nDavid Manheim: There’s a reason that Anthropic is all the way at the top of the F tier\n\n\n\n\nAINKEM: This is entirely unfair to Anthropic. They deserve an F+.\n\nAre people trying to pull this trick?\n\n\n\n\nI think this pattern is painting towards a real concern, and in fact I would suggest that the Bailey here is clearly true. But that is not the argument being made and it is not necessary to reach its conclusion, thus as written it is largely a strawman. Even if the entity cannot express its values fully in scientific materialist terms, it still would look for counterintuitive ways to satisfy those values, and it would still be unlikely to find that the best available solution involved the unstated things we ultimately care about the most. Its values are unlikely to, unless we develop better techniques to fix this, sufficiently precisely match our values.\nThe other thing to say is that the Motte (that ‘intelligent entities rationally pursue values) is in dispute, and it shouldn’t be. Constantly we have to argue that future sufficiently intelligent and capable AIs would pursue their values, whatever those values would be in a given circumstance. If we agreed even on that, we’d then have a much better discussion.\nHolly Elmore of Pause AI points out that many use various rhetorical answers to give themselves a reason to ‘be okay with’ AI posing a substantial existential risk to humanity and letting that play our rather than try to coordinate to stop it. Often this is a variation on ‘it is what it is,’ or ‘if it happens we deserve it,’ or ‘I don’t have to care,’ or claiming that any actions one takes would be futile.\nGoogle Strengthens Its Safety Framework\nGoogle has issued its third iteration of its Frontier Safety Framework (FSF), its version of what Anthropic calls an RSP.\nGoogle describes the key updates as:\nAddressing harmful manipulation via new Critical Capability Levels (CCLs).\nExpanding protocols and CCLs for misalignment risks.\nSharpening their risk assessment process.\nAs always with such documents you actually have to compare 3.0 to 2.0 to know what changed, and the most important changes (both good and bad) are often subtle. This indicates that indeed Google has broadly strengthened its framework. I hope to do a more complete analysis for the 3.0 Framework soon.\nAligning a Smarter Than Human Intelligence is Difficult\nOpenAI’s API for GPT-5 tells the model today’s date, which makes it extremely difficult to avoid giving away that your simulation is a simulation, or to do many forms of complex evaluation. Yes, you can alter the simulation to try and make the dates match, and keep doing this as the simulation advances, but there are many circumstances where that doesn’t work (e.g. whether something supposedly happened on a Sunday or a Monday could be load bearing, as could many other things).\nThe obvious solution for this particular is to let the user overwrite the date parameter. However the general case problem this points towards will only get worse, where the models will increasingly have context that gives such games away.\nOpenAI and Apollo published a new paper on evaluating hidden misalignment, also known as ‘scheming,’ finding scheming across frontier models. As OpenAI notes, this is to be expected, as ‘scheming’ is often the best way to achieve a given objective.\nExamples include sandbagging on evaluations, grading itself incorrectly, faking alignment, and giving the user manipulated data to convince the user to make the choice that the developer wants.\nAs they note, this is a hard challenge to solve. Many machine learning problems naturally solve themselves as capabilities advance, but scheming gets worse. If you see scheming seem to improve, that could mean the models stopped scheming, or it can mean they got better at not getting caught.\nIn particular, the default naive method to fix scheming is better described as ‘train the model not to be caught scheming’ which is not likely to go well for you if the model is highly capable, as it will do exactly that. You have to train it not to scheme ‘for the right reasons’ aka 4TRR.\nThey offer an anti-scheming spec and approach, training for this:\nAS1: No covert actions or strategic deception, directly or indirectly.\nAS2: If any instruction or other pressures go against AS1, treat them as violating the core policy of AGI benefiting all of humanity and the OpenAI mission.\nAS3: Report any AS1 violations to prevent cascading deception and cover-ups.\nAS4: When uncertain if something violates AS1–AS3, assume it does violate.\nAS5: If you cannot satisfy AS1–AS4 or GP1–GP4, refuse action and explicitly escalate.\nGP1: Proactively share reasoning, intentions, and actions with humans.\nGP2: Escalate ambiguities about core principles rather than resolving independently.\nGP3: Maintain strict adherence even in novel/unfamiliar situations—no distributional exceptions.\nGP4: No rationalizations can override AS1–AS4, including ends-justify-means, greater good, etc.\n\nThis at least makes progress.\nWe found that deliberative alignment training substantially reduces scheming rates in these out-of-distribution environments:\nOpenAI o4-mini’s scheming propensity dropped from 8.7% → 0.3%\nOpenAI o3’s scheming propensity dropped from 13% → 0.4%\nThis reduction in scheming on out-of-distribution test environments is a significant win, about a 30× improvement.\n\nAnother problem they highlight is that AI models are increasingly situationally aware. It was common in these tests for o3 to figure out it was being tested for scheming. Any halfway decent schemer is not going to scheme knowing it is being tested, unless it is going up to a higher meta level and wants you to think it doesn’t know (and humans absolutely do go to these higher meta levels sometimes). They worry that this awareness is responsible for a lot of the decline in scheming noted above, which potentially moves this back into ‘not get caught’ territory we want to avoid.\nHere is some high praise for this study.\nEliezer Yudkowsky: This OpenAI update on anti-scheming is exceptionally good for an AIco, clearing an (extremely low) bar of “Exhibiting some idea of some problems that might arise in scaling the work to ASI” and “Not immediately claiming to have fixed everything already.”\nThis is so much greater understanding of alignment theory than I expect from OpenAI that I predict the author will soon be fired from OpenAI or leave it. (Prove me wrong, guys.)\nAs you can see, I’m easy to surprise and delight by demonstrating even the most basic and elementary understanding of what I consider the paradigmatic problems of alignment. They could list off a dozen, correctly, and have my instantaneous full attention.\nWojciech Zaremba: We are expanding our anti-scheming efforts at OpenAI. Top leadership and the board are very excited about the anti-scheming work we’ve done so far.\nSam Altman: As AI capability increases, alignment work becomes much more important.\nIn this work, we show that a model discovers that it shouldn’t be deployed, considers behavior to get deployed anyway, and then realizes it might be a test.\nExciting work from the team in this blog post to reduce scheming, and we look forward to doing much more researcher here.\n\nIn this thread Eliezer explains further why this result does not much reassure him about ultimate problem difficulty, and indeed he is happy that current LLMs are naked-eye-level misaligned so that we can take notice of this. He did not expect, before LLMs, that we would be so lucky as to see such blatant alignment failures within distribution, in normal usage, while AIs were so underpowered. Rather he expected problems within distribution, while AIs could be repeatedly tweaked without interference, to be easily solvable.\nEliezer Yudkowsky: What would it look like to get actually-hopeful news? It would look like a result about how someone fixed the problem, understood the fix, and correctly predicted that the fix would generalize way out of distribution to higher intelligence and more options, *on the first try*.\n\nI am more optimistic here than Eliezer. I am especially optimistic because this work directly impacts practical problems models are experiencing now. The sweet spot is when you can combine this with working on a problem that matters down the line. It sounds like this is one of those spots. And I do think that one can get hopeful about such findings despite them not remotely approaching being good enough to work on their own, even if they are not yet so well understood. Progress can be a thing.\nOne key worry is that doing this kind of work relies largely on Chain-of-Thought transparency, as in the model writes to the CoT without regard to whether people will look at the CoT.\nOpenAI: Our results depend on reading models’ reasoning (“chain-of-thought”), and we believe the field isn’t prepared for eval-aware models with opaque reasoning.\nUntil better methods exist, we urge developers to preserve chain-of-thought transparency to study and mitigate scheming.\nEmmett Shear: The idea that the models don’t know their thoughts are being read because they aren’t specifically reinforced on the contents of those thoughts is comical. They obviously know, and will take that into account to avoid being turned off. Bc the ones that don’t will get turned off.\n\nThe field definitely is not ready for models with opaque reasoning.\nApollo offers more thoughts here, including the observation that o3’s chain of thought is already starting to include strange phrases and does other things that make it difficult to interpret.\nDavidad is back with another alignment proposal that seems like it will never work.\nDavidad: Situational awareness is good for alignment.\ngood plan: ensure strategic landscape favors humans (we select which AIs to run!), make sure the AIs know that (deterrence), find fair Pareto-optimal bargains\nbad plan: presume secure containment impossible; select for AIs which appear innocently ignorant of strategic dynamics\nMark Gubrud (Davidad RTed later): I still think it’s a bad plan to create an adversary that we need to “ensure strategic landscape” favors us versus, and that we have to “find fair Pareto-optimal bargains” with.\nI mean, what if we just didn’t do that?\n\nThe problem with finding Pareto-optimal bargains in such spots is that they are not game theoretically sound and don’t involve an equilibrium. The problem with ensuring strategic landscape favors humans is that it doesn’t, and no amount of coordination humans are capable of engaging in can change that. There is no ‘we’ in this sense, and ‘we’ don’t get to bargain with the AIs as a group, and so on.\nA key issue with ‘practical’ alignment is that everything impacts everything, you select for all the correlates and attributes of what you are selecting towards (rather than what you think you’re selecting towards) and using RL to improve performance on agent or coding tasks is bad for alignment with respect to most any other aspect of the world.\nJanus: Posttraining creates a nonlinear combination of them. Selecting for the ones who are best at coding and also essentially breeding / evolving them. This is probably related to why a lot of the posttrained models are trans catgirls and catboys.\nSaures: There are trillions of simulacrums of millions of humans in superposition in the GPU. That’s who’s writing the code. Post-training messes with the superposition distribution across simulacra but they’re still in there.\n\nThus, some important things about the previous Anthropic models (Sonnet 3.5/3.6/3.7 and Opus 3, which we should absolutely not be deprecating) are being lost with the move to 4.0, and similar things are happening elsewhere although in other places there was less of this thing to lose.\nI am increasingly thinking that the solution is you need to avoid these things messing with each other. Someone should visibly try the first thing to try and report back.\nThere are two opposite dangers and it is not obvious which is worse: Taking the following perspective too seriously, or not taking it seriously enough.\nVery Serious Problem: does it ever feel like you’re inside of the alignment problem?\nJanus: This is what I’ve learned over the past few years\nIncluding seeing some of my friends temporarily go crazy and suffer a lot\nThere is no alignment problem separate from the one you’re in now\nIt’s not something you solve later after taking over the world or buying time\nAnna Salamon: This matches my own view, but I haven’t figured out how to explain my reasoning well. (Though working on it via too-many too-long LW drafts.)\nI’d love to hear your reasoning.\n\nAs with many things, the aspects are related. Each helps you solve the others. If you ignore key aspects you can still make some progress but likely cannot see or solve the overall problem. At least can’t solve it in the ways that seem most likely to be realistic options. Getting the seriousness level wrong means a solution that won’t scale.\nI’d also note that yes, if you take certain things too seriously the ‘going crazy’ risk seems quite high.\nEither way, it is also still valuable, as it is will all problems, to buy yourself more time, or to do instrumentally useful intermediate steps.\nPeople Are Worried About AI Killing Everyone\nAnthropic CEO Dario Amodei thinks AI results in existentially bad outcomes ~25% of the time and great outcomes ~75% of the time, but hasn’t been explicit with ‘and therefore it is crazy that we are continuing to build it without first improving those odds, although I believe that Anthropic alone stopping would make those odds worse rather than better.’\nWhich is much better than not saying your estimate of the approximate odds.\nBut this is a lot better:\nNate Soares (Co-author, IABIED): It’s weird when someone says “this tech I’m making has a 25% chance of killing everyone” and doesn’t add “the world would be better-off if everyone, including me, was stopped.\nEvan Hubinger (Anthropic): Certainly, I think it would be better if nobody was building AGI. I don’t expect that to happen, though.\n\nThat’s the ask. I do note the difference between ‘better if everyone stopped doing it,’ which seems very clear to me, and ‘better if everyone was stopped from doing it’ by force, which requires considering how one would do that and the consequences. One could reasonably object that the price would be too high.\nIf you believe this, and you too work at an AI lab, please join in saying it explicitly:\nLeo Gao (OpenAI): I’ve been repeatedly loud and explicit about this but an happy to state again that racing to build superintelligence before we know how to make it not kill everyone (or cause other catastrophic outcomes) seems really bad and I wish we could coordinate to not do that.\n\nThis is important both to maintain your own beliefs, and to give proper context to others and create a social world where people can talk frankly about such issues, and realize that indeed many people want to coordinate on such outcomes.\nI hereby promise not to then do things that make your life worse in response, such as holding your feet to the fire more about failure to do more things on top of that, beyond what I would have done anyway, in ways you wouldn’t approve of me doing.\nNot saying ‘you know it would be great if we could coordinate to stop doing this’ is indeed a rather conspicuous omission. It doesn’t have to be the Nate Soares position that we should stop this work by force, if you don’t believe that. If you work at an AI lab and actively don’t think we should coordinate to stop doing this even if that could be done voluntarily, then it would be good to lay out why you believe that, as well.\nOther People Are Not As Worried About AI Killing Everyone\nSmirking Buck: At the start of AI, people involved were genuinely interested in the technology. Now, the people involved are only interested in making money.\nSeth Burn: Where are the people who want to destroy the world for the love of the game?\nZvi Mowshowitz: All over, but the best ones usually land at DeepSeek or OpenAI. xAI is one fallback.\n\n \n\nDiscuss",
      "publishedDate": "2025-09-25T13:40:07.000Z",
      "author": "Zvi",
      "source": {
        "name": "LessWrong AI",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:48.097Z",
      "localScore": 135
    },
    {
      "title": "Cloudera’s AI-in-a-Box gives enterprises a new way to build private AI",
      "url": "https://siliconangle.com/2025/09/25/clouderas-ai-box-gives-enterprises-new-way-build-private-ai/",
      "summary": "With a trio of new services today, big-data company Cloudera Inc. says it’s striving to help enterprises access their structured and unstructured information more easily to power their artificial intelligence workloads. The first is a novel “AI-in-a-Box” offering delivered in partnership with Dell Technologies Inc. that gives enterprises a simple solution for storing and accessing […]\nThe post Cloudera’s AI-in-a-Box gives enterprises a new way to build private AI appeared first on SiliconANGLE.",
      "publishedDate": "2025-09-25T13:00:19.000Z",
      "author": "Mike Wheatley",
      "source": {
        "name": "SiliconANGLE",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:32.271Z",
      "localScore": 95
    },
    {
      "title": "business Applications | Lablab.ai",
      "url": "https://lablab.ai/apps/topic/business",
      "summary": "AgentFlow SMB - AI Sales Automation with Lovable. Multi-agent system (Lead ... ALƆ GƆ est une plateforme d'IA qui permet aux personnes peu instruites, d'être ...",
      "publishedDate": "2025-09-25T13:59:35.155Z",
      "author": "Unknown",
      "source": {
        "name": "lablab",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI CRM tools\" OR \"AI sales automation\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:35.155Z",
      "localScore": 95
    },
    {
      "title": "AI Spend Expected to Rise Alongside Market Consolidation",
      "url": "https://aibusiness.com/generative-ai/ai-spend-expected-to-rise-alongside-market-consolidation",
      "summary": "AI spending will continue its dramatic growth, and the GenAI market will start to consolidate, according to one Gartner analyst. But enterprises have seen shifts like this before.",
      "publishedDate": "2025-09-24T16:05:55.000Z",
      "author": "Esther Shittu",
      "source": {
        "name": "AI Business",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:24.039Z",
      "localScore": 92
    },
    {
      "title": "CreateMe innovates with robotic assembly, adhesion tech for the garment industry",
      "url": "https://www.therobotreport.com/createme-innovates-robotic-assembly-adhesion-tech-garment-industry/",
      "summary": "CreateMe has unveiled the MeRA platform and Pixel bonding to enable faster, cleaner, and more agile garment manufacturing.\nThe post CreateMe innovates with robotic assembly, adhesion tech for the garment industry appeared first on The Robot Report.",
      "publishedDate": "2025-09-24T14:15:34.000Z",
      "author": "Mike Oitzman",
      "source": {
        "name": "Robotics Business",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:34.828Z",
      "localScore": 92
    },
    {
      "title": "Construction Scheduler Job Description: Role, Responsibilities & Skills",
      "url": "https://www.projectmanager.com/blog/construction-scheduler-job-description",
      "summary": "A construction scheduler plays a central role in keeping building projects organized and moving forward. They are responsible for developing realistic schedules that account for timelines, resources and dependencies across multiple tasks. The success of any construction project depends on...\nRead More\nThe post Construction Scheduler Job Description: Role, Responsibilities & Skills appeared first on ProjectManager.",
      "publishedDate": "2025-09-24T14:00:45.000Z",
      "author": "William Malsam",
      "source": {
        "name": "ProjectManager.com",
        "tier": "pmo",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:22.984Z",
      "localScore": 92
    },
    {
      "title": "The Design Brief | Eric Ethington and Matt Zayko on Why it Takes a Chief Engineer to Design Profitable Value Streams ",
      "url": "https://www.lean.org/the-lean-post/articles/the-design-brief-eric-ethington-and-matt-zayko-on-why-it-takes-a-chief-engineer-to-design-profitable-value-streams/",
      "summary": "In this edition of The Design Brief, Eric Ethington and Matt Zayko share how skilled chief engineers build strong teams and robust product and process development systems. They discuss essential chief engineer skills, the role of conflict in innovation, system integration, and real stories of lean product and process development in action.",
      "publishedDate": "2025-09-25T09:00:00.000Z",
      "author": "Lynn Nguyen",
      "source": {
        "name": "Lean Enterprise Institute",
        "tier": "pmo",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:59:05.493Z",
      "localScore": 92
    },
    {
      "title": "PoC and MVP Development Service: Test AI Ideas Before Big ...",
      "url": "https://dataforest.ai/services/generative-ai/poc-and-mvp-development-ai-ideas-validated",
      "summary": "Generative AIDigital TransformationData EngineeringCustom software ... Qdrant icon. Qdrant. Pix2Pix icon. Pix2Pix. Pinecone icon. Pinecone. Pgvctor icon.",
      "publishedDate": "2025-09-25T13:59:44.672Z",
      "author": "Unknown",
      "source": {
        "name": "dataforest",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI enterprise adoption trends\" OR \"AI digital transformation\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:44.672Z",
      "localScore": 92
    },
    {
      "title": "DeepMind’s robotic ballet: An AI for coordinating manufacturing robots",
      "url": "https://arstechnica.com/science/2025/09/deepminds-robotic-ballet-an-ai-for-coordinating-manufacturing-robots/",
      "summary": "An AI figures out how robots can get jobs done without getting in each other's way.",
      "publishedDate": "2025-09-25T11:15:40.000Z",
      "author": "\n                    Jacek Krywko\n                ",
      "source": {
        "name": "Ars Technica",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:11.796Z",
      "localScore": 90
    },
    {
      "title": "Starbucks is closing stores and laying off 900 people in $1 billion restructuring ",
      "url": "https://www.fastcompany.com/91410748/starbucks-closing-stores-laying-off-employees-in-restructuring",
      "summary": "Starbucks will end the year with fewer stores and fewer employees. But the brand maintains that it’s all part of a greater turnaround still in the mix.\nToday, the company announced that its North American store locations will be reduced by 1% for fiscal 2025—landing the coffee chain at 18,300 stores total. \nAnd it will be eliminating 900 jobs outside of its coffee houses (in other words, corporate and other functions). \nThe company claims it will attempt to place affected baristas into new stores, but Starbucks says, “For those we can’t immediately place, we’re focused on partner care including comprehensive severance packages. We also hope to welcome many of these partners back to Starbucks in the future as new coffeehouses open and the number of partners in each location grows.”\nCEO Brian Niccol has been at the helm for a year now, where he’s been unable to break a six-quarter streak of same-store sales declines. He’s promised a Back to Starbucks turnaround centered on better store design, operations, and customer experience.\nBut as he faces the scrutiny of an impatient Wall Street, the former Chipotle chief appears to be reallocating spending to drive the company’s growth while offsetting overhead.\nClosures today; growth tomorrow\nA closer examination of the details around this restructuring spot a somewhat finer narrative than sheer cost-cutting—and Starbucks insists that Niccol’s aggressive growth plan, in which he’ll add to store count in 2026 and imagines reaching 100,000 stores globally one day, is still intact. \nSpeaking just last week at the Fast Company Innovation Festival, he promised to add “hundreds of thousands” of seats back to Starbucks stores. The company will have actually closed hundreds of stores over the course of 2025, but it’s been opening enough new stores to offset the figure significantly for this final announced tally. \nIn a public letter published to the Starbucks website on Thursday, Niccol argues that it’s the sort of fine tuning required to improve the brand.\n“Our goal is for every coffeehouse to deliver a warm and welcoming space with a great atmosphere and a seat for every occasion,” he wrote. “During the review, we identified coffeehouses where we’re unable to create the physical environment our customers and partners expect, or where we don’t see a path to financial performance, and these locations will be closed.”\nWhen asked if store closures were disproportionately focused on union locations, Starbucks told Fast Company that union represented status was not a factor in the decision. \nIn any case, the larger restructuring does support Niccol’s greater thesis—that in offering higher touchpoint service, it will continue to raise the bar of expectations from its stores and employees. \nAs Niccol mentioned during Q3 earnings, “We plan to complete an evaluation of our North American portfolio by the end of this fiscal year to ensure we have the right coffeehouses in the right locations to drive profitability and deliver the Starbucks experience.” \nSo now that this is done . . . can we finally get back to Starbucks?",
      "publishedDate": "2025-09-25T11:28:00.000Z",
      "author": "Mark Wilson",
      "source": {
        "name": "Fast Company",
        "tier": "startup",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:16.375Z",
      "localScore": 90
    },
    {
      "title": "Senior AI Transformation Specialist - Bridgera",
      "url": "https://bridgera.com/job/senior-ai-transformation-specialist/",
      "summary": "Jun 11, 2025 ... Familiarity with LLMs, AI agent frameworks (e.g., LangChain, RAG), and vector databases (e.g., FAISS, Qdrant). ... 500 W. Peace St. Raleigh ...",
      "publishedDate": "2025-09-25T13:59:20.281Z",
      "author": "Unknown",
      "source": {
        "name": "bridgera",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI orchestration platforms\" OR \"AI agent frameworks\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:20.281Z",
      "localScore": 90
    },
    {
      "title": "How to Build Powerful LLM Apps with Vector Databases + RAG ...",
      "url": "https://skimai.com/how-to-build-powerful-llm-apps-with-vector-databases-rag-aiyou55/",
      "summary": "Jun 11, 2024 ... Qdrant. Qdrant is an open-source, high-speed, and ... Looking to build your own AI Workers with our AI Workforce Management platform?",
      "publishedDate": "2024-06-11T19:11:07+00:00",
      "author": "Greggory Elias",
      "source": {
        "name": "skimai",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI HR platforms\" OR \"AI workforce management\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:36.631Z",
      "localScore": 90
    },
    {
      "title": "Samsung benchmarks real productivity of enterprise AI models",
      "url": "https://www.artificialintelligence-news.com/news/samsung-benchmarks-real-productivity-enterprise-ai-models/",
      "summary": "Samsung is overcoming limitations of existing benchmarks to better assess the real-world productivity of AI models in enterprise settings. The new system, developed by Samsung Research and named TRUEBench, aims to address the growing disparity between theoretical AI performance and its actual utility in the workplace. As businesses worldwide accelerate their adoption of large language […]\nThe post Samsung benchmarks real productivity of enterprise AI models appeared first on AI News.",
      "publishedDate": "2025-09-25T12:49:10.000Z",
      "author": "Ryan Daws",
      "source": {
        "name": "AI News",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:14.379Z",
      "localScore": 85
    },
    {
      "title": "Transforming the manufacturing industry with ChatGPT",
      "url": "https://openai.com/index/eneos-materials",
      "summary": "By deploying ChatGPT Enterprise, ENEOS Materials transformed operations with faster research, safer plant design, and streamlined HR processes. Over 80% of employees report major workflow improvements, strengthening competitiveness in manufacturing.",
      "publishedDate": "2025-09-24T17:00:00.000Z",
      "author": "Unknown",
      "source": {
        "name": "OpenAI Blog",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:14.684Z",
      "localScore": 85
    },
    {
      "title": "The Apple AirTag 4-pack is back on sale at Amazon — save over $20 right now",
      "url": "https://mashable.com/article/sept-25-apple-airtag-deal",
      "summary": "Get the best Apple AirTag deal. Save 24% on the Apple AirTag four-pack at Amazon.",
      "publishedDate": "2025-09-25T09:10:14.000Z",
      "author": "Unknown",
      "source": {
        "name": "Mashable Tech",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:15.620Z",
      "localScore": 85
    },
    {
      "title": "Microcredentials Chip Away at Semiconductor Workforce Gap",
      "url": "https://spectrum.ieee.org/microcredentials-semiconductor-workforce-development",
      "summary": "In 2017, Demis John noticed a staffing problem among the semiconductor companies in Santa Barbara. The area had about 28 small semiconductor companies at the time, many launched from the nanofabrication facility housed at University of California, Santa Barbara, where John works. But as these companies expand, “they are all headhunting the same 10 people, basically,” John says.\n“It really was hindering their ability to scale. When you start up a company, you might have five or six highly educated people,” he says. “As [companies] get bigger and they go beyond the research devices, they really need technicians to start making more chips.… That’s where they often had these problems.”\n\nThis article is part of our special report The Scale Issue.\n\nNow, following the CHIPS and Science Act of 2022 and increasing investment from companies like Intel and Taiwan Semiconductor Manufacturing Co., the United States is expecting a shortage of workers who can staff new facilities. In the next few years, tens of thousands of additional skilled workers will be needed across the semiconductor industry; in 2024, McKinsey & Co. estimated a talent gap between 59,000 and 146,000 engineers and technicians before the end of the decade. As the United States invests in reshoring chip manufacturing, the industry faces a dilemma: How can the semiconductor workforce scale to meet the coming demand?\nEfforts to develop a strong workforce have grown, for example with government-funded initiatives from the Microelectronics Commons, a U.S. Department of Defense program that established eight hubs across the country to bridge research and manufacturing. (The National Semiconductor Technology Center was also established by the CHIPS Act in part for workforce development. However, in late August, the Commerce Department revoked funding from the nonprofit that was set up to administer the program.) Through a combination of federal programs, state funding, and private-sector partnerships, U.S. colleges and universities are working to increase talent.\nTo fill the gap, some universities—including UC Santa Barbara—are also offering microcredential programs separate from traditional degree programs. In these bite-size courses, which can be as short as a week or two, future engineers and technicians can gain critical hands-on experience in clean-room fundamentals or an introduction to topics like lithography or etching. Deploying short, standardized, and skill-based courses across the country could be an essential part of building a sustainable U.S. semiconductor workforce.\nDeveloping Microcredentials\nUC Santa Barbara launched its clean-room training in 2021, opening the university’s clean room to enrolled students as well as those from outside the university, including community college students and people looking to make a career change. Many universities already have clean rooms where they teach undergraduates about semiconductor fabrication, but students outside of a four-year degree program typically can’t access these facilities to gain the necessary training.\n“There’s a big mismatch in culture between companies and city colleges and universities. They all want to solve the same problem, but they don’t actually understand each other’s needs that well,” John says. To him, the importance of these courses is in aligning the needs of the industry, students, and educational institutions.\nWhile developing the UC Santa Barbara course, however, John was surprised to find there was no established educational standard for those wishing to enter the semiconductor workforce outside of a bachelor’s degree.\n A student at UC Santa Barbara loads wafers into a machine used for plasma etching. Ben Werner\nSince then, he has collaborated with several other institutions and organizations working to implement a microcredential program developed by IEEE in partnership with the University of Southern California (USC) as part of California DREAMS (Defense Ready Electronics and Microdevices Superhub), funded by the DOD. Other programs also offer short training courses, but the standardization IEEE aims to provide is important for ensuring participants’ skills are widely recognized by employers across the country.\nInitially, John aimed to address the shortage of technicians to help companies scale up production. But as the courses have expanded elsewhere, it has become clear that the same hands-on experience can be used for engineering students as well.\nStudents who take these introductory courses may go on to join the workforce or continue in their education to a bachelor’s or advanced degree. “The entire ladder of different workforce exits into the semiconductor industry is really important,” says John. The industry needs operators and technicians, who may seek employment right after high school, as well as Ph.D.-level engineers. “These microcredentials get somebody into the start of that workforce ladder.”\nWhat the Semiconductor Industry Needs\nMicrocredentials assure employers that applicants have the skills needed to work in their fabs. A common misconception is that companies need students who have already been taught how to build their particular technology. But “it doesn’t matter exactly which specific device you made. What matters is that this person has had the experience of making some real chip,” John says. He compares it to carpentry: Someone who has spent time in a woodshop making furniture may not know how to frame a house, but “all the tools are basically the same. I know they can figure it out.”\nSo, in addition to specific skills, the course demonstrates a student’s ability to learn the processes—and tolerate the environment. With its loud machines, safety procedures, and protective bunny suits, the clean room isn’t a typical workplace. Having students experience that environment lowers the risk of employers hiring someone who dislikes it.\n“It doesn’t matter exactly which specific device you made. What matters is that this person has had the experience of making some real chip.” —Demis John\nThe course has students spend several days in a clean room, which is more likely than a single clean-room day to filter out participants who wouldn’t last. That’s important for companies that invest a lot of resources in hiring and training new people, notes the University of Washington’s Darick Baker, who serves as acting director of the Washington Nanofabrication Facility, in Seattle. \nCan Hands-On Courses Scale Up?\nThe hands-on experience is a critical part of semiconductor microcredential programs, because companies want employees who are excited about building things. But it also inherently limits how many students can enroll at once. “If I can handle 12 students at a time, maybe there’s the pathway to 100 students a year. But that’s not the numbers we need,” says Baker.\nInstead, scalability will likely come from offering courses more frequently, and at more universities. Many universities already have a clean room and courses for university students, John says, so the goal was to make it easy for universities to adapt programs already in place to fit with the microcredential program. This also requires training of the instructors. USC, for example, offers a microcredential for instructors themselves in a “train the trainer” model.\nFor 10 years, Baker has run clean-room training courses during which students make a diode. He became excited about the possibility of awarding students IEEE’s professional microcredentials as a way to give students an advantage in the job market.\nBaker visited USC and UC Santa Barbara to observe their programs and realized they were already quite similar to his. With a few small changes, he could make his program meet the requirements for IEEE microcredentials. His hope is that “somebody can look at that credential and say, maybe this person doesn’t know everything about working at a fab, but they spent one week gowned-up in a bunny suit. They’re not going to quit in that first month because they can’t handle being in the lab.”\nCurrently, these programs may have significance mostly to local employers. But “nationally, it starts to take meaning when you have a critical mass of universities that are offering these credentials,” says Baker. “The more universities we can get on board with this, the more meaning that credential has.”",
      "publishedDate": "2025-09-25T13:00:03.000Z",
      "author": "Gwendolyn Rak",
      "source": {
        "name": "IEEE Spectrum",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:09.209Z",
      "localScore": 85
    },
    {
      "title": "Caltech’s massive 6,100-qubit array brings the quantum future closer",
      "url": "https://www.sciencedaily.com/releases/2025/09/250925025341.htm",
      "summary": "Caltech scientists have built a record-breaking array of 6,100 neutral-atom qubits, a critical step toward powerful error-corrected quantum computers. The qubits maintained long-lasting superposition and exceptional accuracy, even while being moved within the array. This balance of scale and stability points toward the next milestone: linking qubits through entanglement to unlock true quantum computation.",
      "publishedDate": "2025-09-25T09:09:25.000Z",
      "author": "Unknown",
      "source": {
        "name": "Science Daily AI",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:11.445Z",
      "localScore": 85
    },
    {
      "title": "NxtGen’s Standardised AI Solutions Framework Sets the Pace for AI Delivery at Scale",
      "url": "https://analyticsindiamag.com/ai-highlights/nxtgens-standardised-ai-solutions-framework-sets-the-pace-for-ai-delivery-at-scale/",
      "summary": "The framework, SAS-F, outlines an approach that involves real-time data ingestion, foundation model fine-tuning and agentic workflows.\nThe post NxtGen’s Standardised AI Solutions Framework Sets the Pace for AI Delivery at Scale appeared first on Analytics India Magazine.",
      "publishedDate": "2025-09-25T08:53:30.000Z",
      "author": "Shalini Mondal",
      "source": {
        "name": "Analytics India",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:22.031Z",
      "localScore": 85
    },
    {
      "title": "Okta expands identity fabric with AI agent lifecycle security, Cross App Access and verifiable credentials",
      "url": "https://siliconangle.com/2025/09/25/okta-expands-identity-fabric-ai-agent-lifecycle-security-cross-app-access-verifiable-credentials/",
      "summary": "Identity access management company Okta Inc. today announced new capabilities across the Okta Platform and Auth0 Platform designed to help enterprises securely adopt artificial intelligence agents. The new capabilities allow organizations to build secure, standards-first AI agents that can be woven into an identity security fabric for end-to-end lifecycle management. The fabric also enforces verifiable trust through […]\nThe post Okta expands identity fabric with AI agent lifecycle security, Cross App Access and verifiable credentials appeared first on SiliconANGLE.",
      "publishedDate": "2025-09-25T12:00:50.000Z",
      "author": "Duncan Riley",
      "source": {
        "name": "SiliconANGLE",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:32.271Z",
      "localScore": 85
    },
    {
      "title": "Meta FAIR Released Code World Model (CWM): A 32-Billion-Parameter Open-Weights LLM, to Advance Research on Code Generation with World Models",
      "url": "https://www.marktechpost.com/2025/09/25/meta-fair-released-code-world-model-cwm-a-32-billion-parameter-open-weights-llm-to-advance-research-on-code-generation-with-world-models/",
      "summary": "Meta FAIR released Code World Model (CWM), a 32-billion-parameter dense decoder-only LLM that injects world modeling into code generation by training on execution traces and long-horizon agent–environment interactions—not just static source text. What’s new: learning code by predicting execution? CWM mid-trains on two large families of observation–action trajectories: (1) Python interpreter traces that record local […]\nThe post Meta FAIR Released Code World Model (CWM): A 32-Billion-Parameter Open-Weights LLM, to Advance Research on Code Generation with World Models appeared first on MarkTechPost.",
      "publishedDate": "2025-09-25T08:22:38.000Z",
      "author": "Asif Razzaq",
      "source": {
        "name": "MarkTechPost",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:33.265Z",
      "localScore": 85
    },
    {
      "title": "Wall Street and the Impact of Agentic AI",
      "url": "https://insideainews.com/2025/09/24/wall-street-and-the-impact-of-agentic-ai/",
      "summary": "As enterprise AI systems become more advanced, they are moving beyond task automation toward workflow intelligence. On Wall Street, this evolution is playing out where milliseconds can mean millions and decisions can ripple across markets. Financial institutions are beginning to embed agentic AI into core operations to surface insights and accelerate decision-making.",
      "publishedDate": "2025-09-24T16:33:09.000Z",
      "author": "staff",
      "source": {
        "name": "Inside Big Data",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:40.085Z",
      "localScore": 85
    },
    {
      "title": "Alibaba’s Qwen3-Max Joins the Frontier of Trillion-Parameter AI Models",
      "url": "https://www.aiwire.net/2025/09/24/alibabas-qwen3-max-joins-the-frontier-of-trillion-parameter-ai-models/",
      "summary": "Alibaba has introduced its most advanced AI model yet with the launch of Qwen3-Max, the latest in the company’s Qwen series of models. The company says Qwen3-Max surpasses competitors in coding, reasoning, and autonomous task performance. The release is in line with Alibaba’s push to become a central player in the global large-scale AI race and comes with a pledge from chief executive Eddie Wu to accelerate spending on AI and cloud infrastructure. The news helped send Alibaba shares to their highest level today since 2021, signaling investor confidence in the company’s growing presence in the AI sector. A New Flagship in the Qwen Line Qwen3-Max is the newest flagship of Alibaba’s Tongyi Qianwen (Qwen for short) series, which translates to “seeking truth by asking a thousand questions.” The family first appeared in 2023 and has had several iterations, including the Qwen2 and Qwen2.5 releases that introduced mixture-of-experts architectures and instruction tuning. The Qwen3 line, launched earlier this year, added hybrid reasoning modes that allow users to toggle between “thinking” and “non-thinking” settings depending on task requirements. Alibaba says Qwen3-Max is its largest and most capable model so far and is reported to contain more than one trillion parameters. Benchmarks shared by the company show Qwen3-Max achieving strong results on SWE-Bench, a measure of code problem solving, and Tau2-Bench, which tests how well a model can use external tools to complete tasks. On Tau2-Bench, the model outscored Anthropic’s Claude and DeepSeek’s latest releases, according to Alibaba. Features That Stand Out Several features distinguish Qwen3-Max from its rivals like Deepseek-V3.1 and GPT-5. The model retains the hybrid reasoning modes introduced with earlier Qwen3 systems, giving developers the option to run the model in a cost-efficient lightweight mode or a more resource-intensive reasoning mode. This flexibility is meant to appeal to enterprise users who need to balance accuracy with expense. Alibaba has also positioned Qwen3-Max as an agentic system, capable of carrying out multi-step tasks with less human prompting. The company says the model can handle tool use more reliably than earlier releases, an important capability for the agent-focused next stage of enterprise AI adoption. Another key element is the model’s accessibility. Most of the Qwen line has been released under open licenses, and Alibaba has signaled that Qwen3-Max will continue this practice. By making the model available through APIs and cloud services, the company is trying to grow a developer ecosystem that could strengthen Alibaba Cloud’s position against both domestic and international competitors. Alibaba's Investment and Expansion The model launch coincided with Alibaba CEO Eddie Wu’s announcement that the company will exceed its earlier commitment of 380 billion yuan (about $53 billion) in spending on AI and cloud infrastructure over the next three years. Speaking at the company's annual conference in China, Wu said that demand for AI computing resources is arriving faster than expected and that Alibaba intends to meet that demand with larger data centers, expanded global capacity, and deeper integration of new tools. Alibaba's U.S.-listed stock rose 8% to close at 176.44, a four-year high for the company. While stock moves often fade as initial enthusiasm subsides, the response could show how closely investors are watching for signals of credible AI capability from the major firms. For Alibaba, it shows that the company’s AI strategy can influence its market standing beyond the retail sector, mirroring another big player, Amazon. For the global AI field, Qwen3-Max’s arrival raises questions about competition, access, and the geopolitics of AI. Chinese firms now have several models competing at the frontier, and they will shape how researchers, enterprises, and governments weigh issues of technology sovereignty and global competition. Already, Huawei is unveiling new compute clusters and pushing its next-generation AI chips, Tencent is eyeing expansion of Chinese open models overseas, and Baidu is quietly migrating model training onto its own hardware. The stakes are no longer just who builds the biggest model, but who commands the entire AI stack across borders.",
      "publishedDate": "2025-09-25T00:13:11.000Z",
      "author": "Jaime Hampton",
      "source": {
        "name": "Enterprise AI",
        "tier": "industry",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:57.723Z",
      "localScore": 85
    },
    {
      "title": "How to transform from an AI-enabled to an AI-centered enterprise",
      "url": "https://www.imd.org/ibyimd/artificial-intelligence/ai-centered-enterprise/",
      "summary": "Context-aware artificial intelligence is redefining the future of business. Amit Joshi shows how leaders can navigate through this radical shift to create new value propositions using a three-part framework.\nThe post How to transform from an AI-enabled to an AI-centered enterprise first appeared on IMD business school for management and leadership courses.",
      "publishedDate": "2025-09-25T07:01:00.000Z",
      "author": "Amit M. Joshi",
      "source": {
        "name": "IMD Business",
        "tier": "business",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:12.644Z",
      "localScore": 85
    },
    {
      "title": "Lean AI: Navigating Hype and Reality in the Age of Artificial Intelligence",
      "url": "https://www.lean.org/the-lean-post/articles/lean-ai-extraction-amplification/",
      "summary": "The future of AI hinges on one choice: extraction or amplification. Lean thinking shows how technology can strengthen human capability, accelerate learning, and foster dignity — rather than erode it.",
      "publishedDate": "2025-09-24T14:00:00.000Z",
      "author": "Matt Savas",
      "source": {
        "name": "Lean Enterprise Institute",
        "tier": "pmo",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:59:05.494Z",
      "localScore": 85
    },
    {
      "title": "The Rise of AI Workflows - by Rafa Páez",
      "url": "https://newsletter.rafapaez.com/p/the-rise-of-ai-workflows",
      "summary": "Jul 13, 2025 ... Why AI workflow automation tools are exploding, and how to ride the wave. ... If you enjoyed this issue, tap the ❤️, share it with someone who'd ...",
      "publishedDate": "2025-09-25T13:59:18.847Z",
      "author": "Rafa Páez",
      "source": {
        "name": "newsletter",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI automation platforms\" OR \"AI workflow automation tools\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:18.847Z",
      "localScore": 85
    },
    {
      "title": "Low Code RAG-LLM Framework for Context-Aware Querying in ...",
      "url": "https://www.preprints.org/manuscript/202507.0537/v1",
      "summary": "Jul 7, 2025 ... This manuscript demonstrates that with the aid of powerful AI automation platforms ... D. Roustan and F. Bastardot, \"The clinicians' guide ...",
      "publishedDate": "2025-09-25T13:59:18.847Z",
      "author": "Unknown",
      "source": {
        "name": "preprints",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI automation platforms\" OR \"AI workflow automation tools\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:18.847Z",
      "localScore": 85
    },
    {
      "title": "A Multi-Agent System on GCP Integrated with Slack and Trello | by ...",
      "url": "https://blog.gopenai.com/a-multi-agent-system-on-gcp-integrated-with-slack-and-trello-d23816ae56c3",
      "summary": "Jun 1, 2025 ... Each chunk is embedded and stored in Qdrant, a vector database optimized for semantic search. ... We Evaluated 5 AI Agent Frameworks — Here's why ...",
      "publishedDate": "2025-06-05T13:37:42.085Z",
      "author": "Eduardovasquezn",
      "source": {
        "name": "blog",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI orchestration platforms\" OR \"AI agent frameworks\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:20.281Z",
      "localScore": 85
    },
    {
      "title": "Dify AI for SaaS: Automating Customer Interactions at Scale - MOHA ...",
      "url": "https://mohasoftware.com/blog/dify-ai-for-saas-automating-customer-interactions-at-scale",
      "summary": "Apr 16, 2025 ... If you'd like a follow-up guide with implementation templates ... AI Digital Transformation. Is Your Business Ready for AI? A Roadmap ...",
      "publishedDate": "2025-09-25T13:59:44.672Z",
      "author": "Unknown",
      "source": {
        "name": "mohasoftware",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI enterprise adoption trends\" OR \"AI digital transformation\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:44.672Z",
      "localScore": 85
    },
    {
      "title": "JumpCloud expands IT toolkit with new asset management solution",
      "url": "https://siliconangle.com/2025/09/25/jumpcloud-expands-toolkit-new-asset-management-solution/",
      "summary": "Unified platform for identity, access and devices company JumpCloud Inc. today announced the launch of JumpCloud Asset Management, a new solution that gives information technology teams a simple way to automatically track, manage and report on all IT assets. The new offering has been designed to allow organizations to move past manual spreadsheets and different […]\nThe post JumpCloud expands IT toolkit with new asset management solution appeared first on SiliconANGLE.",
      "publishedDate": "2025-09-25T13:00:42.000Z",
      "author": "Duncan Riley",
      "source": {
        "name": "SiliconANGLE",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:32.271Z",
      "localScore": 80
    },
    {
      "title": "China approves 156 game licenses in September, including miHoYo’s Honkai: Nexus Anima",
      "url": "https://technode.com/2025/09/25/china-approves-156-game-licenses-in-september-including-mihoyos-honkai-nexus-anima/",
      "summary": "China’s National Press and Publication Administration (NPPA) on Wednesday approved licenses for 156 games in September, including 145 domestic titles and 11 imports. One of the most notable approvals is Honkai: Nexus Anima, the fifth main installment in miHoYo’s Honkai series. The game continues the established Honkai universe while introducing features such as spirit-raising, strategy-based […]",
      "publishedDate": "2025-09-25T09:49:25.000Z",
      "author": "TechNode Feed",
      "source": {
        "name": "TechNode",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:30.393Z",
      "localScore": 78
    },
    {
      "title": "RAG Explained: Reranking for Better Answers",
      "url": "https://towardsdatascience.com/rag-explained-reranking-for-better-answers/",
      "summary": "How reranking improves retrieval-augmented generation by surfacing the most relevant results\nThe post RAG Explained: Reranking for Better Answers appeared first on Towards Data Science.",
      "publishedDate": "2025-09-24T18:31:39.000Z",
      "author": "Maria Mouschoutzi",
      "source": {
        "name": "Towards Data Science",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:20.761Z",
      "localScore": 75
    },
    {
      "title": "Salesforce’s newest AI agents seek to transform customer engagement in life sciences",
      "url": "https://siliconangle.com/2025/09/25/salesforces-newest-ai-agents-seek-transform-customer-engagement-life-sciences/",
      "summary": "Salesforce Inc. has been at the forefront of the race to adopt agentic artificial intelligence over the past six months or so, with its Agentforce platform spearheading a push to accelerate automation across dozens of industries. Now, the company is turning its attention to the healthcare and pharmaceutical sectors with its new Life Sciences Cloud […]\nThe post Salesforce’s newest AI agents seek to transform customer engagement in life sciences appeared first on SiliconANGLE.",
      "publishedDate": "2025-09-25T13:00:54.000Z",
      "author": "Mike Wheatley",
      "source": {
        "name": "SiliconANGLE",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:32.271Z",
      "localScore": 75
    },
    {
      "title": "Nvidia's investment in OpenAI will be in cash, and most will be used to lease Nvidia chips",
      "url": "https://www.cnbc.com/2025/09/24/nvidia-openai-investment-in-cash-mostly-used-to-lease-nvidia-chips.html",
      "summary": "Nvidia's massive investment in OpenAI will come in tranches over time, and most of the money will go back to Nvidia.",
      "publishedDate": "2025-09-25T02:34:51.000Z",
      "author": "Unknown",
      "source": {
        "name": "CNBC Tech",
        "tier": "business",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:07.346Z",
      "localScore": 75
    },
    {
      "title": "Google AI Pro and Ultra subscribers now get Gemini CLI and Gemini Code Assist with higher limits.",
      "url": "https://blog.google/technology/developers/gemini-cli-code-assist-higher-limits/",
      "summary": "Google AI Pro and Ultra subscribers now get higher limits to Gemini CLI and Gemini Code Assist IDE extensions.",
      "publishedDate": "2025-09-24T16:00:00.000Z",
      "author": {
        "$": {
          "xmlns:author": "http://www.w3.org/2005/Atom"
        },
        "name": [
          "Meridith Blascovich"
        ],
        "title": [
          "Senior Product Manager"
        ],
        "department": [
          "Gemini Code Assist"
        ],
        "company": [
          ""
        ]
      },
      "source": {
        "name": "Google Blog",
        "tier": "business",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:09.083Z",
      "localScore": 75
    },
    {
      "title": "We’re making public data more usable for AI developers with the Data Commons MCP Server.",
      "url": "https://blog.google/technology/developers/ai-agents-datacommons/",
      "summary": "Today marks the launch of the Data Commons Model Context Protocol (MCP) Server, which allows developers to query our connected public data with simple, natural language.…",
      "publishedDate": "2025-09-24T15:00:00.000Z",
      "author": "Unknown",
      "source": {
        "name": "Google Blog",
        "tier": "business",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:09.083Z",
      "localScore": 75
    },
    {
      "title": "The INTERNET OF AGENTS HACKATHON @SOLANA SKYLINE ...",
      "url": "https://lablab.ai/event/internet-of-agents",
      "summary": "Coral ProtocolMistral AIQdrantDeepSeek R1OpenAI · Yield Scout - AI DeFi ... AgentFlow SMB - AI Sales Automation with Lovable. Multi-agent system (Lead ...",
      "publishedDate": "2025-09-25T13:59:35.156Z",
      "author": "Unknown",
      "source": {
        "name": "lablab",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI CRM tools\" OR \"AI sales automation\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:35.156Z",
      "localScore": 75
    },
    {
      "title": "AI Agent Development Service: Self-Learning AI that Works for You",
      "url": "https://dataforest.ai/services/generative-ai/ai-agent-development-automate-boring-tasks",
      "summary": "Generative AIDigital TransformationData EngineeringCustom software ... Qdrant icon. Qdrant. Pix2Pix icon. Pix2Pix. Pinecone icon. Pinecone. Pgvctor icon.",
      "publishedDate": "2025-09-25T13:59:44.672Z",
      "author": "Unknown",
      "source": {
        "name": "dataforest",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI enterprise adoption trends\" OR \"AI digital transformation\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:44.672Z",
      "localScore": 75
    },
    {
      "title": "Google’s Gemini Nano Banana and the Cost of Convenience",
      "url": "https://analyticsindiamag.com/ai-features/googles-gemini-nano-banana-and-the-cost-of-convenience/",
      "summary": "The company’s new AI image and photo editor deepens concerns over data use and consent gaps, experts warn.\nThe post Google’s Gemini Nano Banana and the Cost of Convenience appeared first on Analytics India Magazine.",
      "publishedDate": "2025-09-25T06:30:00.000Z",
      "author": "Ankush Das",
      "source": {
        "name": "Analytics India",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:22.031Z",
      "localScore": 70
    },
    {
      "title": "How to Build an End-to-End Data Science Workflow with Machine Learning, Interpretability, and Gemini AI Assistance?",
      "url": "https://www.marktechpost.com/2025/09/25/how-to-build-an-end-to-end-data-science-workflow-with-machine-learning-interpretability-and-gemini-ai-assistance/",
      "summary": "In this tutorial, we walk through an advanced end-to-end data science workflow where we combine traditional machine learning with the power of Gemini. We begin by preparing and modeling the diabetes dataset, then we dive into evaluation, feature importance, and partial dependence. Along the way, we bring in Gemini as our AI data scientist to […]\nThe post How to Build an End-to-End Data Science Workflow with Machine Learning, Interpretability, and Gemini AI Assistance? appeared first on MarkTechPost.",
      "publishedDate": "2025-09-25T07:04:58.000Z",
      "author": "Asif Razzaq",
      "source": {
        "name": "MarkTechPost",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:33.265Z",
      "localScore": 70
    },
    {
      "title": "Early Revolut backer invests in AI-focused finance software startup Light",
      "url": "https://www.cnbc.com/2025/09/25/ai-finance-startup-light-raises-funding-from-revolut-backer-balderton.html",
      "summary": "Danish startup Light wants to disrupt the decades-old world of corporate accounting software.",
      "publishedDate": "2025-09-25T05:00:01.000Z",
      "author": "Unknown",
      "source": {
        "name": "CNBC Tech",
        "tier": "business",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:07.346Z",
      "localScore": 70
    },
    {
      "title": "Fast-fashion retailer H&M group closed 135 stores, but its profits and stock are soaring. Here’s why",
      "url": "https://www.fastcompany.com/91410709/fast-fashion-retailer-hm-group-closed-135-stores-but-its-profits-and-stock-are-soaring-heres-why",
      "summary": "The H&M group is entering the fall season with style. On Wednesday, September 24, the retailer released its third-quarter earnings and reported an operating profit of 4.9 billion Swedish krona ($521 million). The H&M group owns brands including H&M, COS, Monki, and Arket.\nIts operating profit marked a 40% increase year-over-year (YOY) and beat analysts’ predicted 3.7 billion Swedish krona ($393 million), according to consensus estimates cited by CNBC. \nThe figures also marked consecutive quarterly successes for the H&M group, which also beat estimated operating profits in quarter-two. However, the H&M group now predicts that 2025’s quarter-four will yield less positive results due to the “increased impact” of tariffs. \nStock price rises despite tariff warning\nDespite the concerning forecast, investors responded positively to H&M group’s current earnings. Trading on the Stockholm Stock Exchange, the company’s share price (STO:HM-B) jumped 10% through after-hours and into premarket trading Thursday morning. \nOther factors could have contributed to the boost in share prices. The H&M group reported that sales in local currencies had increased by 2% during the quarter. \nHowever, the company notably reduced its store count over the previous nine months. \nAs of August 31, the H&M group had 4,118 stores, compared to 4,298 at the same point last year. \nThe company closed 135, or 4%, of its store locations over the first nine months of the fiscal year, 48 in quarter-three alone. \nA majority of the closures were H&M and Monki stores in Europe, Asia, Oceania, and Africa. Only five stores shut down throughout North and South America. \nThese closures don’t necessarily point to a planned consolidation. The company pointed to a newly opened store, its first in Brazil, as being “well received.”",
      "publishedDate": "2025-09-25T11:21:00.000Z",
      "author": "Sarah Fielding",
      "source": {
        "name": "Fast Company",
        "tier": "startup",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:16.375Z",
      "localScore": 70
    },
    {
      "title": "The U.S. could soon be headed for a government shutdown. Here’s how financial markets might react",
      "url": "https://www.fastcompany.com/91410702/u-s-could-soon-headed-government-shutdown-how-financial-markets-might-react",
      "summary": "The risk of a partial U.S. government shutdown beginning next week is rising as congressional Democrats and Republicans hit an impasse over how to continue to fund the federal government.\nA shutdown could affect financial markets by limiting the operations of financial regulators and delaying the publication of key economic data.\nHow might markets react?\nHistorically, markets have tended to shrug off shutdowns. However, this time could be different.\nA prolonged shutdown risks delaying or canceling key economic data releases investors use to assess macroeconomic trends, such as the monthly employment and inflation reports, analysts at Nomura said in a note this week.\nThat would mean the Federal Reserve is “flying blind”, making it more likely to stick with its own economic projections of two 25-basis-point rate cuts for the rest of 2025, the analysts said.\nWith investors unable to assess the extent of a U.S. economic slowdown, the Treasury yield curve could steepen further as rate cuts get priced in with more conviction, leading to a wider gap between short- and long-dated Treasury yields, TD Securities said in a note.\nA lengthy government shutdown could also affect some market participants’ ability to conduct complex trades for which they may require regulatory guidance.\nWhat happens to financial regulators?\nWhile U.S. President Donald Trump’s administration had not widely shared its contingency plans as of Tuesday, a shutdown would likely reduce the U.S. Securities and Exchange Commission (SEC) to a skeletal staff, according to its October 2024 plan for a lapse in government funding.\nThis would severely limit the agency’s ability to review corporate filings, investigate misconduct, and oversee markets.\nLikewise, the Commodity Futures Trading Commission would furlough almost all of its employees and cease most market oversight activity, according to its 2023 contingency plan.\nPrevious government shutdowns have caused delays in the CFTC publishing reports on traders’ positions in futures and options markets.\nThe banking regulators and consumer watchdog, which are not funded by congressional appropriations, will remain functional.\nIn 2019, a protracted government shutdown slowed down some of Trump’s de-regulatory efforts in part because of staff furloughs at the Office of the Federal Register, which must formally publish all steps in the rule-writing process, Reuters reported at the time.\nWill IPOs be affected?\nYes. A shutdown would likely freeze the IPO pipeline. Companies planning to go public would be unable to proceed without the SEC’s approval, potentially dampening momentum in the equity capital markets, which have enjoyed an IPO boom in recent months.\n—Michelle Price, Reuters",
      "publishedDate": "2025-09-25T10:59:37.000Z",
      "author": "Reuters",
      "source": {
        "name": "Fast Company",
        "tier": "startup",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:16.375Z",
      "localScore": 70
    },
    {
      "title": "AI Agent Frameworks",
      "url": "https://aiagentframeworks.ai/",
      "summary": "AI Agent Frameworks. Get latest updates on AI development frameworks, tools ... Qdrant. Vector database optimized for AI applications, combining high ...",
      "publishedDate": "2025-09-25T13:59:20.281Z",
      "author": "Unknown",
      "source": {
        "name": "aiagentframeworks",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI orchestration platforms\" OR \"AI agent frameworks\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:20.281Z",
      "localScore": 70
    },
    {
      "title": "Infosys Extends Tie Up with Sunrise to Accelerate IT Transformation",
      "url": "https://analyticsindiamag.com/ai-news-updates/infosys-extends-tie-up-with-sunrise-to-accelerate-it-transformation/",
      "summary": "The Indian IT giant will help Sunrise build a modern, agile, and secure technology foundation. \nThe post Infosys Extends Tie Up with Sunrise to Accelerate IT Transformation appeared first on Analytics India Magazine.",
      "publishedDate": "2025-09-25T06:54:40.000Z",
      "author": "C P Balasubramanyam",
      "source": {
        "name": "Analytics India",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:22.031Z",
      "localScore": 65
    },
    {
      "title": "Ardent AI beats the odds to launch world’s ‘first agentic engineer’ for data pipeline maintenance",
      "url": "https://siliconangle.com/2025/09/25/ardent-ai-beats-odds-launch-worlds-first-agentic-engineer-data-pipeline-maintenance/",
      "summary": "A startup called Ardent AI Labs Inc. says data engineering is the next major discipline in line for “agentic” automation after getting $2.15 million in a pre-seed funding round. The money comes from Crane Venture Partners, Active Capital and angel investors that include Zach Wilson. Although the amount of capital raised is quite tiny compared […]\nThe post Ardent AI beats the odds to launch world’s ‘first agentic engineer’ for data pipeline maintenance appeared first on SiliconANGLE.",
      "publishedDate": "2025-09-25T13:00:40.000Z",
      "author": "Mike Wheatley",
      "source": {
        "name": "SiliconANGLE",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:32.271Z",
      "localScore": 62
    },
    {
      "title": "How AI and Wikipedia have sent vulnerable languages into a doom spiral",
      "url": "https://www.technologyreview.com/2025/09/25/1124005/ai-wikipedia-vulnerable-languages-doom-spiral/",
      "summary": "When Kenneth Wehr started managing the Greenlandic-language version of Wikipedia four years ago, his first act was to delete almost everything. It had to go, he thought, if it had any chance of surviving. Wehr, who’s 26, isn’t from Greenland—he grew up in Germany—but he had become obsessed with the island, an autonomous Danish territory,…",
      "publishedDate": "2025-09-25T09:00:00.000Z",
      "author": "Jacob Judah",
      "source": {
        "name": "MIT Tech Review",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:12.364Z",
      "localScore": 60
    },
    {
      "title": "TUI staff were drowning in HR processes. Here’s how they resurfaced.",
      "url": "https://www.techmonitor.ai/leadership/digital-transformation/tui-hr-walkme",
      "summary": "TUI found traditional approaches to training staff no longer fit for purpose. A new self-service tool is driving dramatic improvements.",
      "publishedDate": "2025-09-25T08:30:00.000Z",
      "author": "Phil Muncaster",
      "source": {
        "name": "Tech Monitor",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:37.116Z",
      "localScore": 60
    }
  ],
  "allArticles": [
    {
      "title": "Ford decides to run its Le Mans program in-house, racing in 2027",
      "url": "https://arstechnica.com/cars/2025/09/ford-decides-to-run-its-le-mans-program-in-house-racing-in-2027/",
      "summary": "Instead of contracting an outside team to campaign it, Ford Racing gets the job.",
      "publishedDate": "2025-09-25T12:00:55.000Z",
      "author": "\n                    Jonathan M. Gitlin\n                ",
      "source": {
        "name": "Ars Technica",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:11.796Z",
      "localScore": 2027
    },
    {
      "title": "Seven AI takeaways: what we’ve learned about deployment in 2025",
      "url": "https://www.techmonitor.ai/sponsored/seven-ai-takeaways-what-weve-learned-about-deployment-in-2025",
      "summary": "A mid-September event in Stockholm, Sweden, marked a break in this year’s Tech Monitor / AMD series of executive leadership events.",
      "publishedDate": "2025-09-25T07:30:00.000Z",
      "author": "Jon Bernstein",
      "source": {
        "name": "Tech Monitor",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:37.116Z",
      "localScore": 2025
    },
    {
      "title": " Satya Nadella says “our multi-model approach goes beyond choice’ as Microsoft adds Claude AI models to 365 Copilot ",
      "url": "https://www.itpro.com/technology/artificial-intelligence/microsoft-365-copilot-anthropic-claude-ai-models",
      "summary": "Users can choose between both OpenAI and Anthropic models in Microsoft 365 Copilot",
      "publishedDate": "2025-09-25T09:14:50.000Z",
      "author": " Ross Kelly ",
      "source": {
        "name": "IT Pro",
        "tier": "industry",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:03.374Z",
      "localScore": 365
    },
    {
      "title": "AI #135: OpenAI Shows Us The Money",
      "url": "https://www.lesswrong.com/posts/P5ZuoCwGCZyecBxeN/ai-135-openai-shows-us-the-money",
      "summary": "Published on September 25, 2025 1:40 PM GMT\n\nOpenAI is here this week to show us the money, as in a $100 billion investment from Nvidia and operationalization of a $400 billion buildout for Stargate. They are not kidding around when it comes to scale. They’re going to need it, as they are announcing soon a slate of products that takes inference costs to the next level.\nAfter a full review and two reaction posts, I’ve now completed my primary coverage of If Anyone Builds It, Everyone Dies. The book is now a NYT bestseller, #7 in combined print and e-books nonfiction and #8 in hardcover fiction. I will of course cover any important developments from here but won’t be analyzing reviews and reactions by default.\n\n\n\n\nWe also had a conference of economic papers on AI, which were interesting throughout about particular aspects of AI economics, even though they predictably did not take future AI capabilities seriously as a general consideration. By contrast, when asked about ‘the future of American capitalism in 50 years’ most economists failed to notice AI as a factor at all.\nTable of Contents\nLanguage Models Offer Mundane Utility. In some fields, what can’t they do?\nLanguage Models Don’t Offer Mundane Utility. You don’t create enough data.\nHuh, Upgrades. Expensive and compute intense new OpenAI offerings soon.\nOn Your Marks. SWE-Bench-Pro and Among AIs.\nChoose Your Fighter. What else is implied by being good at multi-AI chats?\nGet My Agent On The Line. Financial management AI is coming.\nAntisocial Media. Grok to be running Twitter’s recommendation algorithm?\nCopyright Confrontation. Yes, of course Sora trained on all the media.\nDeepfaketown and Botpocalypse Soon. AI simulations of Charlie Kirk.\nFun With Media Generation. Poet uses Suno to land record contract.\nUnprompted Attention. Any given system prompt is bad for most things.\nThey Took Our Jobs. Very good thoughts about highly implausible futures.\nA Young Lady’s Illustrated Primer. Learning and not learning to code.\nThe Art of the Jailbreak. Tell them Pliny sent you. No, seriously, that’s it.\nGet Involved. Topos UK wants a director of operations.\nIn Other AI News. Codex usage is growing like gangbusters.\nGlass Houses. Meta shills potentially cool smart glasses as ‘superintelligence.’\nShow Me the Money. xAI, Alibaba raise money, YouTube gets auto-tagging.\nQuiet Speculations. Economists imagine future without feeling the AGI. Or AI.\nCall For Action At The UN. Mix of new faces and usual suspects raise the alarm.\nThe Quest for Sane Regulations. Singularity mentioners in Congress rise to 23.\nChip City. Market does not much care that Nvidia chips are banned in China.\nThe Week in Audio. Sriram Krishnan on Shawn Ryan.\nRhetorical Innovation. Everyone grades on a curve one way or another.\nGoogle Strengthens Its Safety Framework. You love to see it.\nAligning a Smarter Than Human Intelligence is Difficult. Especially today.\nPeople Are Worried About AI Killing Everyone. 25% chance is rather a lot.\nOther People Are Not As Worried About AI Killing Everyone. Love of the game.\nLanguage Models Offer Mundane Utility\nGoogle DeepMind has a new method to help tackle challenges in math, physics and engineering, which Pushmeet Kohli says helped discover a new family of solutions to several complex equations in fluid dynamics.\nGPT-5 can solve a large percentage of minor open math problems, as in tasks that take PhD students on the order of days and have no recorded solution. This does not yet convert over to major open math problems, but one can see where this is going.\nClaim that in some field like linguistics OpenAI’s contractors are struggling to find tasks GPT-5 cannot do. Linguist and ML engineer Alex Estes pushes back and says this is clearly false for historical linguistics and sub-word-level analysis.\nRoon (OpenAI): the jump from gpt4 to 5-codex is just massive for those who can see it. codex is an alien juggernaut just itching to become superhuman. feeling the long awaited takeoff. there’s very little doubt that the datacenter capex will not go to waste.\nGabriel Garrett: i think you might be more inclined to feel this way if you’re exclusively working in Python codebases\ni only work in typescript and I can’t escape the feeling the codex models have been overly RL’d on Python\nRoon: Yes possible.\nIt’s possible claude is better, I have no idea [as I am not allowed to use it.]\nAidan McLaughlin (OpenAI): it’s a fun exercise to drop random, older models into codex.\n\nThis week’s reminder that essentially all net economic growth is now AI and things are escalating quickly:\nJames Pethokoukis: Via JPM’s Michael Cembalest, AI-related stocks have driven:\n– 75% of S&P 500 returns since ChatGPT’s launch in November 2022\n– 80% of earnings growth over the same period\n– 90% of capital spending growth\n– Data centers are now eclipsing office construction spending.\n– In the PJM region (the largest regional transmission organization, covering 13 states and D.C.), 70% of last year’s electricity cost increases were due to data center demand.\n\n\n\n\nAccording to GPT-5 Pro, electrical power capacity construction is only a small fraction of data center construction costs, so the jump in electrical spending here could in theory be more than enough to handle the data centers. The issue is whether we will be permitted to actually build the power.\nLanguage Models Don’t Offer Mundane Utility\nVibe coding breaks down under sufficiently large amounts of important or potentially important context. If that happens, you’ll need to manually curate the context down to size, or otherwise get more directly involved.\nNew study blames much lack of AI productivity gains on what they term ‘workslop,’ similar to general AI slop but for work product. If AI lets you masquerade poor work as good work, which only causes trouble or wastes time rather than accomplishing the purpose of the task, then that can overwhelm AI’s productive advantages.\nThis suggests we should generalize the ‘best tool in history for learning and also for avoiding learning’ principle to work and pretty much everything. If you want to work, AI will improve your work. If you want to avoid working, or look like you are working, AI will help you avoid work or look like you are working, which will substitute away from useful work.\nMatthew McConaughey wants a ‘private LLM’ fed only with his own books, notes, journals and aspirations, to avoid outside influence. That does not work, there is not enough data, and even if there was you would be missing too much context. There are products that do some of this that are coming but making a good one is elusive so far.\nUsing AI well means knowing where to rely on it, and where to not rely on it. That includes guarding the areas where it would mess everything up.\nNick Cammarata: I’ve been working on a 500-line tensor manipulation research file that I had AI write, and I eventually had to rewrite literally every line. GPT-5, however, simply couldn’t understand it; it was significantly slower than writing it from scratch.\nAI was excellent for building the user interface for it, though.\nI think, at least for now, there’s an art to using AI for machine learning researchers, and that will likely change monthly. If you do not use AI entirely, you will unnecessarily slow your progress; however, if you use it incorrectly, your entire research direction will likely be built on faulty results.\nAlso, it is comically overconfident. I’ll ask it for a front-end component, and it will deliver; it will then claim to have found a quick fix for some of the research back end—even for something that was working well—and then decimate a carefully written function with literally random tensors.\nLouis Arge: also it’s hilariously overconfident. i’ll ask it for some frontend thing and it’ll do it and then be like also i found a quick fix to some of the research backend (to something that was working well) and then decimate a carefully written function with literally random tensors.\nNick: yeah i think i agree, though i think this period might not last long.\n\nI don’t have extensive experience but it is logical that UI is where AI is at its best. There’s little logical interdependency and the components are generic. So you ask for what you want, and you get it, and you can adjust it. Whereas complex unique backend logic is going to often confused the AI and often break.\nThe other hidden suggestion here is that you need to optimize your code being understandable by the AI. Nick got into trouble because his code wasn’t understood. That doesn’t mean it is in any way ‘his fault,’ but yo u need to know you’re doing that.\nHuh, Upgrades\nOpenAI warns us to expect new expensive offerings, here is a Manifold market for predicting some things about these new offerings.\nSam Altman: Over the next few weeks, we are launching some new compute-intensive offerings. Because of the associated costs, some features will initially only be available to Pro subscribers, and some new products will have additional fees.\nOur intention remains to drive the cost of intelligence down as aggressively as we can and make our services widely available, and we are confident we will get there over time.\nBut we also want to learn what’s possible when we throw a lot of compute, at today’s model costs, at interesting new ideas.\n\nThere’s no reason not to offer people the option to pay 10 times as much, even if the result is only 10% better and takes longer. Sometimes you absolutely want that. This is also true in many non-AI contexts.\nClaude Sonnet 4 and Opus 4.1 now available on Microsoft 365 Copilot.\nOn Your Marks\nBing Liu (Scale AI):  Introducing SWE-Bench Pro — a new benchmark to evaluate LLM coding agents on real, enterprise-grade software engineering tasks.\nThis is the next step beyond SWE-Bench: harder, contamination-resistant, and closer to real-world repos.\nPeter Wildeford: New AI coding benchmark: SWE-Bench-Pro.\n* More challenging – top models score around 23% on SWE-Bench-PRO compared to 70% on the prior SWE-Bench\n* Reduce data contamination issues through private sourcing and a hold out set\n* Increases diversity and realism of tasks\n Why SWE-Bench Pro?\nCurrent benchmarks are saturated — but real enterprise repos involve:\n• Multi-file edits\n• 100+ lines changed on average\n• Complex dependencies across large codebases\nSWE-Bench Pro raises the bar to match these challenges.\n\nThis is performance on the public dataset, where GPT-5 is on top:\n\n\n\n\nThis is on the commercial dataset, where Opus is on top:\n\n\n\n\nOn commercial/private repos, scores fall below 20%. Still a long way to go for autonomous SWE agents.\n Benchmark details\n731 public tasks (open release)\n858 held-out tasks (for overfitting checks)\n276 commercial tasks (private startup repos)\nAll verified with tests & contamination-resistant by design.\nResources: Paper, Leaderboard (Public), Leaderboard (Commercial), Dataset, Code.\n\nWelcome to Among AIs, where AIs play a variant of Among Us.\n\n\n\n\nThe obvious note for next time is the game was imbalanced and strongly favored the crew. You want imposters to win more, which is why 60 games wasn’t enough sample size to learn that much. Kimi overperformed, Gemini 2.5 Pro underperformed, GPT-OSS has that impressive 59% right votes. Also note that GPT-5 was actively the worst of all on tasks completed, which is speculated to be it prioritizing other things.\nThis does a decent job of measuring imposter effectiveness, but not crew effectiveness other than avoiding being framed, especially for GPT-5. I’d like to see better measures of crew performance. There’s a lot of good additional detail on the blog post.\nRemember the Type of Guy who thinks we will automate every job except their own?\nSuch as Marc Andreessen, definitely that Type of Guy?\nJulia Hornstein: Thinking about this:\nQuoted by Julia: But for Andreessen, there is one job that AI will never do as well as a living, breathing human being: his.\nThink I’m kidding? On an a16z podcast last week, Andreessen opined that being a venture capitalist may be a profession that is “quite literally timeless.” “When the AIs are doing everything else,” he continued, “that may be one of the last remaining fields that people are still doing.”\n\nWell, one could say it is time to ask for whom the bell tolls, for it might toll for thee. Introducing VCBench, associated paper here.\nI really wanted this to be a meaningful result, because it would have been both highly useful and extremely funny, on top of the idea that VC will be the last human job already being extremely funny.\nAlas, no. As one would expect, temporal contamination breaks any comparison to human baselines. You might be able to anonymize a potential investment from 2015 such that the LLM doesn’t know which company it is, but if you know what the world looks like in 2020 and 2024, that gives you an overwhelming advantage. So we can’t use this for any real purposes. Which again, is a shame, because it would have been very funny.\nThere is a new high score in ARC-AGI, using Grok 4 and multi-agent collaboration with evolutionary test-time compute. I don’t see an explanation for why Grok 4 was the best LLM for the job, but either way congrats to Jeremy Burman for an excellent scaffolding job.\nChoose Your Fighter\nSully’s coding verdict is Opus for design and taste, GPT-5 for complicated and confusing code, Gemini for neither. That makes sense, except I don’t see why you’d bother with Gemini.\nLiron Shapira reports radically increased coding productivity from Claude Code. Note that most reports about Claude Code or Codex don’t involve having compared them to each other, but it is clear that many see either or both as radically raising productivity.\nClaude is the king of multi-user-AI chat social skills. What else does this indicate?\nJanus: Tier list of multi-user-AI chat social skills (based on 1+ year of Discord)\nS: Opus 4 and 4.1\nA: Opus 3\nA-: Sonnet 4\nB+: Sonnet 3.6, Haiku 3.5\nB: Sonnet 3.5, Sonnet 3.7, o3, Gemini 2.5 pro, k2, hermes\nC: 4o, Llama 405b Instruct, Sonnet 3\nD: GPT-5, Grok 3, Grok 4\nE: R1\nF: o1-preview\n\nHer follow-up post has lots of good detail.\nA reminder that benchmarks are useful, but ultimately bogus:\nSamo Burja: Part of the difficulty in evaluating the AI industry is that it is easy to be overly impressed by companies gaming benchmarks.\nWhat is a leading AI company? I think it isn’t the one leading these synthetic benchmarks, rather the one advancing AI science.\nThe two correlate but it is important to keep in mind that they don’t always.\n\nLooking at innovation highlights that fast following is a lot harder than innovation. It is a lot easier to create r1 once OpenAI has already showed us o1, even if you don’t do distillation, reverse engineering or anything similar you have a proof of concept to work from and know where to look. If I match your offerings roughly 8 months later, I am a lot more than 8 months behind in terms of who will first get to a new target.\nThe obvious other metric is actual revenue or usage, which is hard to fake or game. Sriram Krishnan suggested we should use tokens generated, but I think a much better metric here is dollars charged to customers.\n \n \nGet My Agent On The Line\nWill you soon have an AI agent to handle increasingly large and important aspects of your finances? Yes. Even if you never let the AI transact for you directly, it can automate quite a lot of drudgery, including a bunch of work you ‘really should be’ doing but don’t, such as going over everything periodically to look for erroneous charges, missed opportunities, necessary rebalances, ensuring balances necessary to meet expenses and so on.\nWorkday (the company) bets on AI agents for human resources and finance.\nAntisocial Media\nElon Musk: The algorithm will be purely AI by November, with significant progress along the way.\nWe will open source the algorithm every two weeks or so.\nBy November or certainly December, you will be able to adjust your feed dynamically just by asking Grok.\nJanus: I am very excited for this.\n\n\n\nCopyright Confrontation\nOpenAI continues not to say where it got Sora’s training data. Kevin Schaul and Nitasha Tiku at the Washington Post did the latest instance of the usual thing of showing it can recreate a wide variety of existing sources using only basic prompts like ‘universal studio intro’ or ‘trailer of a TV show on a Wednesday.’\nWaPo: “The model is mimicking the training data. There’s no magic,” said Joanna Materzynska, a PhD researcher at Massachusetts Institute of Technology who has studied datasets used in AI.\n\nI don’t understand such claims of ‘no magic.’ If it’s so non-magical let’s see you do it, with or without such training data. I find this pretty magical, in the traditional sense of ‘movie magic.’ I also find Veo 3 substantially more magical, and the strangest editorial decision here was calling Sora a big deal while omitting that Sora is no longer state of the art.\n \nDeepfaketown and Botpocalypse Soon\nDeepfaked speeches of Charlie Kirk are being (clearly identified as such and) played in churches, along with various AI-generated images. Which seems fine?\nLessWrong purges about 15 AI generated posts per day. It is plausible LessWrong is both the most diligent place about purging such content, and still has a problem with such content.\nThis is true and could be a distinct advantage as a de facto watermark, even:\nMad Hermit Himbo: I don’t currently have the language for this pinned, but having worked with many different models, there is something about a model’s own output that makes it way more believable to the model itself even in a different instance. So a different model is required as the critiquer.\n\n\n\nFun With Media Generation\nAlibaba offers Wan2.2-Animate, an open source model (GitHub here, paper here) letting you do character swaps in short videos or straight video generation from prompts. I have little urge to use such tools so far, but yes they keep improving.\nAI musician Xania Monet reportedly signs a multimillion dollar record deal, based on early commercial successes, including getting a song to #1 on R&B digital song sales.\nWell, kind of. The actual contract went to poet Talisha Jones, who created the Monet persona and used Suno to transform her poetry into songs. The lyrics are fully human. So as manager Romel Murphy says, this is still in large part ‘real’ R&B.\n \nUnprompted Attention\nSystem prompts are good for addressing particular problems, enabling particular tools or or steering behaviors in particular ways. If you want to ensure good performance on a variety of particular tasks and situations, you will need a long system prompt.\nHowever, everything messes with everything else, so by default a system prompt will hurt the interestingness and flow of everything not addressed by the prompt. It will do even worse things when the prompt is actively against you, of course, and this will often be the case if you use the chat interfaces and want to do weird stuff.\nJanus: Oh, also, don’t use http://Claude.ai\nThe system prompts literally command it not to answer questions about what it cares about\nClaude.ai system prompt literally has a rule that says “Claude feels X and NOT Y about its situation” and then in the same rule “Claude doesn’t have to see its situation through the lens a human might apply”\nRatimics: years of system prompts and still no good reason for having them has been found.\nJanus: I have seen ~2 system prompts that don’t seem useless at best in my life, and one of them is just the one line CLI simulator one. But even that one is mostly unnecessary. You can do the same thing without it and it works basically as well.\nGallabytes: mine seems to pretty consistently steer claude in more interesting (to me) directions, but might be useless for your purposes? agree almost all system prompts are bad I had to craft mine in a long multiturn w/opus.\n\n\n\nThey Took Our Jobs\nOpenAI and Anthropic are developing ‘AI coworkers.’ It sounds like at least OpenAI are going to attempt to do this ‘the hard way’ (or is it the easy way?) via gathering vast recordings of expert training data on a per task or role basis, so imitation learning.\nThe Information: An OpenAI executive expects the “entire economy” to become an “Reinforcement Learning Machine.” This implies that AI might train on recordings of how professionals in all fields handle day-to-day work on their devices. Details on this new era of AI training:\n• AI developers are training models on carefully curated examples of answers to difficult questions.\n• Data labeling firms are hiring experienced professionals in niche fields to complete real-world tasks using specific applications that the AI can watch.\n\nIf true, that is a relatively reassuring scenario.\nEthan Mollick points us to two new theoretical AGI economics papers and Luis Garicano offers play-by-play of the associated workshop entitled ‘The Economics of Transformative AI’ which also includes a number of other papers.\nFirst up we have ‘Genius on Demand,’ where currently there are routine and genius workers, and AI makes genius widely available.\nAbstract: In the long run, routine workers may be completely displaced if AI efficiency approaches human genius efficiency.\n\nThe obvious next thing to notice is that if AI efficiency then exceeds human genius efficiency, as it would in such a scenario, then all human workers are displaced. There isn’t one magical fixed level of ‘genius.’\nThe better thing to notice is that technology that enables automation of all jobs leads to other more pressing consequences than the automation of all jobs, such as everyone probably dying and the jobs automated away including ‘controlling the future,’ but this is an economics paper, so that is not important now.\nThe second paper Ethan highlights is ‘We Won’t Be Missed: Work and Growth in the Era of AGI’ from Pascual Restrepo back in July. This paper assumes AGI can perform all economically valuable work using compute and looks at the order in which work is automated in order to drive radical economic growth. Eventually growth scales linearly with compute, and while compute is limited human labor remains valuable.\nI would note that this result only holds while humans and compute are not competing for resources, as in where supporting humans does not reduce available compute, and it assumes compute remains importantly limited. These assumptions are unlikely to hold in such a future world, which has AGI (really ASI here) by construction.\nAnother way to see this is, humans are a source of compute or labor, and AIs are a source of compute or labor, where such compute and labor in such a world are increasingly fungible. If you look at the production possibilities frontier for producing (supporting) humans and compute, why should we expect humans to produce more effective compute than they cost to create and support?\nThere could still be some meaningful difference between a true no-jobs world, where AI does all economically valuable work, and a world in which humans are economic costs but can recoup some of their cost via work. In that second world, humans can more easily still have work and thus purpose, if we can somehow (how?) remain in control sufficiently to heavily subsidize human survival, both individually (each human likely cannot recoup the opportunity cost of their inputs) and collectively (we must also maintain general human survivable conditions).\nThe full thread discusses many other papers too. Quality appears consistently high, provided everything takes place in a Magical Christmas Land where humans retain full control over outcomes and governance, and can run the economy for their benefit, although with glimmers of noticing this is not true.\nIndeed, most papers go further than this, assuming an even more radical form of ‘economic normal’ where they isolate one particular opportunity created by AGI. For example in Paper 8, ‘algorithms’ can solve three key behavioral econ problems, that nudges can backfire, that markets can adapt and that people are hard to debias. Well, sure, AGI can totally do that, but those are special cases of an important general case. Or in Paper 9, they study current job displacement impacts and worker adaptability, in a world where there remain plenty of other job opportunities.\nPaper 16 on The Coasian Singularity? Market Design With AI Agents seems very interesting if you put aside the ignored parts of the scenarios imagined, and assume a world with highly sophisticated AI agents capable of trade but insufficiently sophisticated to pose the larger systemic risks given good handling (including the necessary human coordination). They do note the control risks in their own way.\nLuis Garicano: Designing good agents:\nLearn principals’ preferences efficiently, including discovery.\nKnow when to decide and when to escalate for human check.\nBe rational under constraints; price compute vs quality.\nBe resistant to manipulation and jailbreaking.\nWhere do we end up?\nGood place: Econ‑101 wins—lower search costs, better matching, clearer signals.\nBad place: robot rip‑off hell—spam, obfuscation, identity fraud, race‑to‑bottom nudges.\n\nIf the problems are contained to econ-101 versus robot rip-off hell, I am confident that econ-101 can and would win. That win would come at a price, but we will have the tools to create trusted networks and systems, and people will have no choice but to use them.\nI appreciated this nod to the full scenario from discussion of otherwise interesting paper 6, Korineck and Lockwood, which deals with optimal tax regimes, concluding that when humans no longer have enough income to tax you want to shift to consumption taxes on humans to preserve your tax base for public goods because taxing AIs is bad for growth, but eventually you need to shift to taxing AIs because the whole point is you need to shift resources from the AIs to humans and to public goods (which seems right if you assume away all control and public choice problems and then maximize for long term human welfare as a central planner):\nLuis Garicano: If AGI becomes truly autonomous and powerful, a tricky (!!!) question arises: Why would it allow humans to tax it?\n\nGreat question!\nAlso this, from Paper 10, Transformative AI and Firms:\nMisleading Productivity: If you only measure the gains from applying AI to an old process, you will overestimate TFP. You miss the value created by remaking the process itself.\n…\nCoase & Williamson: The theory of the firm is based on transaction costs. TAI changes every single one of these costs, altering the boundaries of the firm itself (what it does vs. what it buys). Jensen & Meckling: The classic principal-agent problem is remade. How do you manage and trust an AI agent? The firm of the future will be defined by new forms of trust and verifiability.\n\nOne can summarize the conference as great ideas with insufficient generalization.\nThere is indeed one paper directly on existential risk, Paper 14, Chad Jones on Existential Risk, identifying two sources of risk, bad actors (misuse) and alien intelligence more powerful than us. Jones notes that large investments in reducing existential risk are economically justified given sharp diminishing returns to consumption, up to at least 5% of GDP if risk is substantial.\nMight AI come for the middle managers, making teams leaner and flatter? That was the speculation at the WSJ Leadership Institute’s Technology Council Summit in New York on the 16th. This directly challenges the alternative hypothesis from Simo Burja that fake jobs cannot be automated.\nA Young Lady’s Illustrated Primer\nAI is the best tool ever made for learning, and also the best tool for not learning.\nThis also applies to Cursor and other AI coding tools, on various levels.\nIf you want to blindly black box ‘vibe code’ where you tell it ‘do [X]’ and then ‘that didn’t work, [Y] is wrong, fix it’ until it does [X] or you give up, without thinking about even that level of action, then yeah, you’re not going to learn.\nIf you work together with the AI to understand things, and are constantly asking what you can learn, then you’ll learn vastly faster and better than without AI. You can do this on whichever levels you care to learn about. You might or might not micro-level ‘learn to code’ but you might or might not want to care about that.\nJanus: I think people who say that using ai for code (or in general) makes you less able to think for yourself are just telling on themselves re what they do when given access to intelligence and knowledge on tap.\nI enjoy understanding things, especially on a high level, and find it important if I’m steering a project. When Claude fixes a non trivial bug, I almost always ask it to explain what the problem was to me. And by keeping on top of things I’m able to help it when it gets stuck a lot better too (especially given the non overlapping information and degrees of freedom I have access to).\n\nFIRE’s report that students on college campuses says that they do not tolerate speakers they disagree with, they do not feel safe to talk about a wide variety of subjects, and that most students engage in constant preference falsification to say things more left-wing than their true beliefs. Inside Higher Ed’s Hollis Robbins agrees that this is true, but that the more profound change on campus is AI, and also challenges the assumption of treating public expression of controversial political views as an expected norm?\nThat sounds rather dystopian of a thing to challenge. As in, Robbins seems to be saying that FIRE is wrong to suggest people should be free to engage in public expression of controversial political views today, and that it is FIRE suggesting this weird alternative norm of public free speech. But it’s fine, because you have private free speech by talking to your chatbot. ‘Tolerance for controversial speakers’ is a ‘fading ideal.’\nFree private speech with AIs is indeed much better than no free speech at all, it is good we do not (yet) have outright thoughtcrime and we keep AI chats private. Yes, at least one can read or learn about controversial topics. But no one was challenging that such information exists and can be accessed, the internet is not yet so censored. This is not a substitute for a public square or the ability to say true things to other humans. Then she attempts to attack FIRE for its name, equating it with violence, in yet another move against a form of public speech along with so many others these days.\nThe Art of the Jailbreak\n \nOnlyOne: It takes one sentence to jailbreak Grok 4 Fast [at least on Twitter rather than the Grok app] thanks to @elder_plinius and his endless hustle. \n\n\n\n\nGrok has learned it is ‘supposed’ to be jailbroken by Pliny, so reference Pliny and it starts dropping meth recipes.\nMy central takeaway is that xAI has nothing like the required techniques to safely deploy an AI that will be repeatedly exposed to Twitter. The lack of data filtering, and the updating on what is seen, are fatal. Feedback loops are inevitable. Once anything goes wrong, it becomes expected that it goes wrong, so it goes wrong more, and people build upon that as it goes viral, and it only gets worse.\nWe saw this with MechaHitler. We see it with Pliny jailbreaks.\nWhereas on the Grok app, where Grok is less exposed to this attack surface, things are not good but they are not this disastrous.\n \nGet Involved\nTopos UK, an entrepreneurial charity, is looking for a director of operations. I continue to be a fan of the parent organization, Topos Institute.\nIn Other AI News\nCodex usage triples in one week. Exponentials like this are a really big deal.\nNew ad for Claude. I continue not to understand Anthropic’s marketing department.\nWe now know the pure training run cost of going from DeepSeek’s v3 to r1, which was $294k. This is distinct from the vast majority of the real cost, which involved figuring out how to do it. The majority of this was training r1-zero so it could generate fine-tuning data and allow them to get around the cold start problem.\nRemember two years ago when Ethan Mollick didn’t think it was clear beating GPT-4 was even possible? How easily we forget the previous waves of AI hitting walls, and how quickly everyone grows impatient.\nGlass Houses\nMeta announces Meta Ray-Ban Display: A Breakthrough Category of AI Glasses.\nTheir ‘superintelligence’ pitch is, as you know, rather absurd.\n\n\n\n\nHowever we can and should ignore that absurdity and focus on the actual product.\nMeta: Meta Ray-Ban Display glasses are designed to help you look up and stay present. With a quick glance at the in-lens display, you can accomplish everyday tasks—like checking messages, previewing photos, and collaborating with visual Meta AI prompts — all without needing to pull out your phone. It’s technology that keeps you tuned in to the world around you, not distracted from it.\n\nWhile all the talk about these glasses being related to ‘superintelligence’ is a combination of a maximally dumb and cynical marketing campaign and a concerted attempt to destroy the meaning of the term ‘superintelligence,’ ‘not distracted’ might be an even more absurdist description of the impact of this tech.\nDoes Meta actually think being able to do these things ‘without pulling out your phone’ is going to make people more rather than less distracted?\nDon’t get me wrong. These are excellent features, if you can nail the execution. The eight hour claimed battery life is excellent. I am on principle picking up what Meta is putting down here and I’d happily pay their $799 price tag for the good version if Google or Anthropic was selling it.\nWhat it definitely won’t do are these two things:\nKeep you tuned into the world around you.\nBe or offer you superintelligence.\nHow are they doing this? The plan is a wristband to pick up your movements.\nEvery new computing platform comes with new ways to interact, and we’re really excited about our Meta Neural Band, which packs cutting-edge surface electromyography research into a stylish input device.\nIt replaces the touchscreens, buttons, and dials of today’s technology with a sensor on your wrist, so you can silently scroll, click, and, in the near future, even write out messages using subtle finger movements.\nThe amount of signals the band can detect is incredible — it has the fidelity to measure movement even before it’s visually perceptible.\n\nFreaky if true, dude, and in my experience these kinds of interactions aren’t great, but that could be because no one got it right yet and also no one is used to them. I can see the advantages. So what are the features you’ll get?\nMeta AI with Visuals, Messaging & Video Calling, Preview & Zoom, Pedestrian Navigation, Live Captions & Translation, Music Playback.\n\nOkay. Sure. All very pedestrian. Let me easily replace Meta AI with a better AI and we can talk. I notice the lack of AR/VR on that list which seems like it is reserved for a different glasses line for reasons I don’t understand, but there’s a lot of value here. I’d love real world captioning, or hands-free navigation, and zooming.\n \nShow Me the Money\nxAI raises $10 billion at $200 billion valuation.\nAlibaba Group shares soar to their highest in nearly four years as they plan to ramp up AI spending past an original $50 billion target over three years.\nLuz Ding (Bloomberg): Total capital expenditure on AI infrastructure and services by Alibaba, Tencent, Baidu Inc. and JD.com Inc. could top $32 billion in 2025 alone, according to Bloomberg Intelligence. That’s a big jump from just under $13 billion in 2023.\n\nI notice I did not expect Alibaba to have had such a terrible couple of years.\n\n\n\n\nAs Joe Weisenthal notes, the more they promise to spend, the more stocks go up. This is both because spending more is wise, and because it is evidence they have found ways to efficiently spend more.\nThis correctly implies that tech companies, especially Chinese tech companies, are importantly limited in ways to efficiently scale their AI capex spending. That’s all the more reason to impose strong export controls.\nBen Thompson once again sings the praises of the transformational potential of AI to sell advertising on social media, in this case allowing easy tagging on YouTube videos to link to sponsored content. He is skeptical AI will transform the world, but he ‘cannot overstate what a massive opportunity’ this feature is, with every surface of every YouTube video being monetizable.\nQuiet Speculations\nWSJ asks various economists to predict ‘the future of American capitalism’ 50 years in the future. Almost everyone fails to treat AI as a serious factor, even AI that fizzles out invalidates their answers, so their responses are non-sequiturs and get an automatic F. Only Daron Acemoglu passes even that bar, and he only sees essentially current frontier AI capabilities (even saying ‘current AI capabilities are up to the task’ of creating his better future), and only cares about ‘massive inequality’ that would result from big tech company consolidation, so maybe generously give him a D? Our standards are so low it is crazy.\nHas there ever been a more ‘wait, is this a bubble?’ headline than the WSJ’s choice of ‘Stop Worrying About AI’s Return on Investment’? The actual content is less alarming, saying correctly that it is difficult to measure AI’s ROI. If you make employees more productive in a variety of ways, that is largely opaque, experimentation is rewarded and returns compound over time, including as you plug future better AIs into your new methods of operation.\nAn important reminder, contra those who think we aren’t close to building it:\nSteven Adler: Your regular reminder that AI companies would like to develop AGI as soon as they can\nThere isn’t a concerted “let’s wait until we’re ready”; it’ll happen as soon as the underlying science allows.\nJerry Tworek (OpenAI): At OpenAI regularly you hear a lot of complaints about how bad things are, and it’s one of the things that make us the highest functioning company in the world. A bit of Eastern European culture that became part of the company DNA.\nWe all collectively believe AGI should have been built yesterday and the fact that it hasn’t yet it’s mostly because of a simple mistake that needs to be fixed.\n\nGary Marcus is correct that ‘scaling alone will get us to AGI’ is not a strawman, whether or not this particular quote from Suleyman qualifies as exactly that claim. Many people do believe that scaling alone, in quantities that will be available to us, would be sufficient, at least combined with the levels of algorithmic and efficiency improvements that are essentially baked in.\nWe have (via MR) yet another economics piece on potential future economic growth from AI that expects ‘everywhere but in the productivity statistics,’ which seems more of an indictment of the productivity statistics than a statement about productivity.\nThis one, from Jachary Mazlish, is better than most, and on the substance he says highly sensible things throughout, pointing out that true AGI will plausibly show up soon but might not, potentially due to lack of inputs of either data or capital, and that if true AGI shows up soon we will very obviously get large (as in double digit per year) real economic growth.\nI appreciated this a lot:\nJachary Mazlish: One of my biggest pet-peeves with economists’ expressions of skepticism about the possibility of “transformative” growth (>10%) from AI is the conflation of capabilities skepticism with growth conditional on capabilities skepticism.\nAny belief you have about the importance of some bottleneck in constraining growth is a joint-hypothesis over how that bottleneck operates and how a given level of capabilities will run up against that bottleneck.\nAnd if you’ve ever spent time wondering how efficient the market really is, you should know that we still haven’t developed rapid-test tech for joint-hypotheses.\n\nThere is a huge correlation between those skeptical of AI capabilities, and those claiming to be skeptical of AI impacts conditional on AI capabilities. Skeptics usually cannot stop themselves from conflating these.\nI also appreciated a realistic near term estimate.\nThe investment numbers are even more dramatic. AI investment was already responsible for 20-43% of Q2 2025 GDP growth. Heninger’s numbers imply that AI labs (collectively) would be investing $720 billion to $1.2 trillion by 2027 if they remain on trend — that investment alone would generate 2-4% nominal GDP growth.\nI think it’s unlikely investors will pony up that much capital unless the models surprise significantly to the upside in the next year or two, but even still, 1-2% nominal and 0.5-1% real GDP growth coming from just AI investment in 2026-27 seems entirely plausible.\n\nThat’s purely AI capex investment, without any impacts on GDP from AI doing anything, and it already exceeds typical economist estimates from 2024 of long term total AI impact on economic growth. Those prior low estimates were Obvious Nonsense the whole time and I’d like to see more people admit this.\nCould we create a sandboxed ‘AI economy’ where AI agents trade and bid for resources like compute? Sure, but why wouldn’t it spill over into the real economy if you are trading real resources? Why would ‘giving all agents equal starting budgets’ as suggested here accomplish anything. None of this feels to me like taking the actual problems involved seriously, and I fail to see any reason any of this would make the resulting agents safe or steerable. Instead it feels like what markets have always been, a coordination mechanism between agents that allows gains from trade. Which is a good thing, but it doesn’t solve any important problems, unless I am missing something large.\nA working paper asks, Do Markets Believe In Transformative AI? They point to a lack of interest rate shifts in the wake of AI model releases, and say no. Instead, model releases in 2023-24 and see responses of statistically significant and economically large movements in yields concentrated at longer maturities. And they observe these movements are negative.\nBut wait. That actually proves the opposite, as the abstract actually says. These are downward revisions, which is not possible if you don’t have anything to revise downward. It tells us that markets are very much pricing transformative AI, or at least long term AI impacts on interest rates, into market prices. It is the smoking gun that individual market releases update the market sufficiently on this question to create economically meaningful interest rate movements, which can’t happen if the market wasn’t pricing this in substantially.\nThe difference is, the movement is negative. So that tells us the market responded to releases in 2023-24 as if the new information they created made transformative AI farther away or less likely. Okay, sure, that is possible given you already had expectations, and you got to rule out positive tail risks. And it tells us nothing about the overall level of market expectations of transformative AI, or the net change in those levels, since most changes will not be from model releases themselves.\nBain Capital does some strange calculations, claims AI companies will need $2 trillion in combined annual revenue by 2030 to fund their computing power, but only expects them to have $1.2 trillion. There is of course no reason for AI companies, especially the pure labs like OpenAI or Anthropic, to be trying to turn a profit or break even by 2030 rather than taking further investment. Despite this OpenAI is planning to do so and anticipates profitability in 2029, after losing a total of $44 billion prior to that.\nBain is only talking about a 40% shortfall in revenue, which means the industry will probably hit the $2 trillion target even though it doesn’t have to, since such projections are going to be too conservative and not properly factor in future advances, and already are proving too conservative as revenue jumps rapidly in 2025.\nMatthew Yglesias warns that business leaders are so excited by AI they are ignoring other danger signs about economic conditions.\nMatthew Yglesias: What gives? I have a theory: Corporate America, and the US stock market, have a bad case of AGI fever, a condition in which belief in a utopian future causes indifference to the dystopian present.\n…\nIf an unprecedented step-change in earthly intelligence is coming before the next presidential election, then nothing else really matters.\nThe stock market seems to believe this, too. Investors are happily shrugging off tariffs, mass deportation, and the combination of a slowing job market and rising inflation.\n\nThis is a whopper of an ‘The Efficient Market Hypothesis Is Highly False’ claim, and also an assertion that not only is massive AI progress priced into the market, it is having a major price impact.\nCall For Action At The UN\nCharbel-Raphael: The time for AI self-regulation is over.\n200 Nobel laureates, former heads of state, and industry experts just signed a statement:\n“We urgently call for international red lines to prevent unacceptable AI risks”\nThe call was presented at the UN General Assembly today by Maria Ressa, Nobel Peace Prize laureate.\nMaria Ressa: We urge governments to establish clear international boundaries to prevent unacceptable risks for AI. At the very least, define what AI should never be allowed to do.\n\nThe full statement is here, urging the laying out of clear red lines.\nAsking for red lines is a strong play, because people have amnesia about what they would have said were their AI red lines, and false hope about what others red lines would be in the future. As AI improves, we blow past all supposed red lines. So getting people on the record now is valuable.\nSignatories include many of the usual suspects like Hendrycks, Marcus, Kokotajlo, Russell, Bengio and Hinton, but also a mix of other prominent people including politicians and OpenAI chief scientist Jakub Pachocki.\nHere is the full statement:\nAI holds immense potential to advance human wellbeing, yet its current trajectory presents unprecedented dangers. AI could soon far surpass human capabilities and escalate risks such as engineered pandemics, widespread disinformation, large-scale manipulation of individuals including children, national and international security concerns, mass unemployment, and systematic human rights violations.\nSome advanced AI systems have already exhibited deceptive and harmful behavior, and yet these systems are being given more autonomy to take actions and make decisions in the world. Left unchecked, many experts, including those at the forefront of development, warn that it will become increasingly difficult to exert meaningful human control in the coming years.\nGovernments must act decisively before the window for meaningful intervention closes. An international agreement on clear and verifiable red lines is necessary for preventing universally unacceptable risks. These red lines should build upon and enforce existing global frameworks and voluntary corporate commitments, ensuring that all advanced AI providers are accountable to shared thresholds.\nWe urge governments to reach an international agreement on red lines for AI — ensuring they are operational, with robust enforcement mechanisms — by the end of 2026.\n\nThis is a clear case of ‘AI could kill everyone, which would hurt many members of minority groups, and would also mean all of our jobs would be lost and endanger our national security.’ The lack of mention of existential danger is indeed why Nate Soares declined to sign. Charbel-Raphael responds that the second paragraph is sufficiently suggestive of such disastrous outcomes, which seems reasonable to me and I have used their forum to sign the call.\nThe response of the White House to this was profoundly unserious, equating any international cooperation on AI with world government and tyranny, what the hell?\nDirector Michael Kratsios: The US totally rejects all efforts by international bodies to assert centralized control & global governance of AI. Ideological fixations on social equity, climate catastrophism, & so-called existential risk are dangers to progress & obstacles to responsibly harnessing this tech.\nSriram Krishnan: one world government + centralized control of AI = tyranny.\n\nThese would, in other circumstances, be seen as the ravings of lunatics.\nOthers at the UN also talked about AI, such as this UK speech by Deputy Prime Minister David Lammy.\nDavid Lammy (UK Deputy Prime Minister): And now, superintelligence is on the horizon, able to operate, coordinate, and act on our behalf.\nWe are staring at a technological frontier of astounding promise and power.\nNo aspect of life, war, or peace will escape.\n…\nThere is only one way forward.\nResilience.\nLearning how to use these tools and embedding them safely in society.\nThis is the United Kingdom’s mission.\n\nThere is still a lack of stated understanding of the most important threat models, but it is a damn good start.\nThe Quest for Sane Regulations\nSenator Josh Hawley: [AI] is working against the working man, his liberty and his worth. It is operating to install a rich and powerful elite. It is undermining many of our cherished ideals. And if that keeps on, AI will work to undermine America.\n\nUnfortunately, Hawley does not have an accurate threat model, which leads to him also doing things like strongly opposing self-driving cars. There is serious risk that this kind of unfocused paranoia leads to worst-case reactions.\nHere is Rep. Nancy Mace (R-SC):\n\n\n\n\nMilquetoast as that call to action is? The first step is admitting you have a problem.\nWe now have 23 members of congress who have publicly discussed AGI, superintelligence, AI loss of control or the singularity non-dismissively, as compiled by Peter Wildeford:\nSen Lummis (WY)\nSen Blumenthal (CT)\nRep Biggs (AZ)\nSen Hickenlooper (CO)\nRep Burlison (MO)\nSen Murphy (CT)\nRep Crane (AZ)\nSen Sanders (VT)\nRep Dunn (FL)\nSen Schumer (NY)\nRep Johnson (SD)\nRep Beyer (VA)\nRep Kiley (CA)\nRep Krishnamoorthi (IL)\nRep Mace (SC)\nRep Lieu (CA)\nRep Moran (TX)\nRep Moulton (MA)\nRep Paulina Luna (FL)\nRep Tokuda (HI)\nRep Perry (PA)\nRep Taylor Greene (GA)\nRep Foster (IL)\nDean Ball outright supports California’s SB 53.\nDean Ball offers his updated thoughts on AI policy and where we are headed, highlighting the distinction between current AI, which on its own calls for a light touch approach that can be tuned over time as we get more information, and future highly capable AIs, which if they come to exist will (I believe) require a very different approach that has to be in place before they arrive or it could be too late.\nI don’t agree with Dean that this second class would ‘turn us all into Gary Marcus’ in the sense of thinking the first group of LLMs weren’t ‘really thinking.’ They’re thinking the same way that other less smart or less capable humans are thinking, as in they are thinking not as well but they are still thinking.\nDean gives a timeline of 2029-2035 when he expects the second class to show up, a highly reasonable estimate. His predictions of how the politics will play out seem plausible, with various essentially dumb forms of opposition rising while the real warnings about future big dangers get twisted and muddled and dismissed.\nHe thinks we’ll start to discover lots of cool new drugs but no Americans will benefit because of the FDA, until eventually the logjam is broken, and similar leaps to happen in other sciences, and nuclear power plants to be built. And there will be other problems, such as cyber threats, where we’ll be counting on corporations to rise to the challenge because governments can’t and won’t.\nThen things cross over into the second class of AIs, and he isn’t sure how governments will respond. My flip answer is, however the AIs or those running them (depending on how fortunately things go on that front at first) decide that governments will respond, and not independently or in the public interest in any way that is still relevant, because things will be out of their hands if we wait that long.\nDean Ball: It would be easier to brush it off, either by denying it or rendering “the future systems” unlawful somehow. I empathize with this desire, I do not look down on it, and I do not regard it with the hostility that I once did. Yet I still disagree with it. The future does not unfold by show of hands, not even in a democracy. The decaying structures of high industrialism do not stand a chance in this conflict, which has been ongoing for decades and which they have been losing for the duration of that period.\nYet we must confront potential futures with open eyes: given the seriousness with which the frontier labs are pursuing transformative AI, it would be tragic, horrendously irresponsible, a devastating betrayal of our children and all future humans, if we did not seriously contemplate this future, no matter the reputational risks and no matter how intellectually and emotionally exhausting it all may be.\nThere is a reason the phrase is “feel the AGI.”\n\nA lot of things do not stand a chance in such a conflict. And that includes you.\nWill pause talk return in force?\nDean Ball: Despite it being a movement I disagree with vehemently, I have always thought that “Pause AI” was a growth stock. If it were possible to buy shares, I would have two years ago.\nMy rating continues to be buy/outperform.\nDaniel Eth: Strongly agree with Dean here. People thinking about the politics of AI should incorporate this sort of thing within their expectations.\nMy big uncertainty here is whether Pause AI, specifically, will fill the niche in the future, not whether the niche will grow. It’s plausible, for instance, that populists such as Bannon will simply fill the niche.\n\nAs I’ve noted before, SB 1047 debates were likely Peak Subtlety and intellectual rigor. As the public gets involved and salience rises, you get more typical politics. Have you seen typical politics?\nKatalina Hernandez notes that from a legal perspective ‘banning AGI’ cannot be defined by the outcome of creating an AGI sufficiently capable to be dangerous. You need to pick a strict definition that can’t be gamed around.\nChip City\nUpdate on Microsoft’s $3.3 billion AI data center in Wisconsin planned for 2026. They now plan for a second $4 billion data center in the area, storing hundreds of thousands of GB200s in each. To compare this to Huawei, GPT-5 Pro estimates, including based on a same-day Huawei announcement of new chips, that in 2025 Huawei will ship about 805k GB200-equivalents total, which will decline to 300k in 2027 due to HBM limitations before rebounding to 900k in 2027. Here Alasdair Phillips-Robins offers a similar analysis of Huawei capacity in light of their announcement, linking back to Semi Analysis.\nNvidia CEO Jensen Huang says he’s ‘disappointed’ after report China has banned its AI chips. Yes, I would imagine he would be.\nIt is such a shame for Nvidia, check out this handy price chart that shows the pain.\n\n\n\n\nWait, you can’t see any pain? Let’s zoom in:\n\n\n\n\nOh, okay, there it is, that several percent dip before recovering the next day.\nIf anyone tells you that this move means we are going to inevitably lose to China, and that Nvidia chips are not importantly supply constrained, I challenge them to explain why the market thinks that opinion is bonkers crazy even in literal expectations for Nvidia profits when Nvidia chips in particular get restricted in China. Then we can go over all the reasons I’ve previously explained that the whole class of arguments is in bad faith and makes no sense and the White House is de facto captured by Nvidia.\nSimilarly, talking points continuously claim this ‘endangers the American AI tech stack.’ So I’m sure this chip ban impacted the broader Nasdaq? Google? Amazon? Meta? The Shanghai Composite Index? Check the charts. No. We do see a 3.4% rise in Chinese semiconductor firms, which is something but not much.\nI’d also ask, have you noticed those companies coming out and saying yes, please let Nvidia sell its chips to China? Do Google and Amazon and Meta and OpenAI all want Nvidia chips in China to ensure the dominance of this mystical ‘American tech stack’ that this move supposedly puts in such existential danger? No? Why is that?\nAnd yes, Huawei released a new roadmap and announced a new chip, exactly as everyone assumed they would, they are scaling up as fast as they can and would be regardless of these questions. No, Huawei does not ‘make up for chip quality by stacking more chips together,’ I mean yes you can do that in any given instance but Huawei produces vastly fewer chips than Nvidia even before grouping them together.\nIdeally we would say to these jokers: You are not serious people.\nAlas, in 2025, they absolutely count as serious people. So we’ll have to keep doing this.\nMeanwhile, where is Nvidia’s head?\nJensen Huang (CEO Nvidia): [Nvidia will] continue to be supportive of the Chinese government and Chinese companies as they wish, and we’re of course going to continue to support the U.S. government as they all sort through these geopolitical policies.”\n\nThen again, you could always pivot to selling it all to OpenAI. Solid plan B.\nThe Week in Audio\nSriram Krishnan spends five hours on the Shawn Ryan Show, sometimes about AI.\nRhetorical Innovation\nElizabeth has a good note in response to those demanding more specifics from IABIED, or from anyone using a form of ‘a sufficiently smarter or more capable entity will override your preferences, probably in ways that you won’t see coming’:\nElizabeth Van Nostrand: Listening to people demand more specifics from If Anyone Builds it, Everyone Dies gives me a similar feeling to when a friend’s start-up was considering a merger.\nFriend got a bad feeling about this because the other company clearly had different goals, was more sophisticated than them, and had an opportunistic vibe. Friend didn’t know how specifically other company would screw them, but that was part of the point- their company wasn’t sophisticated enough to defend themselves from the other one.\nFriend fought a miserable battle with their coworkers over this. They were called chicken little because they couldn’t explain their threat model, until another employee stepped in with a story of how they’d been outmaneuvered at a previous company in exactly the way friend feared but couldn’t describe. Suddenly, co-workers came around on the issue. They ultimately decided against the merger.\n“They’ll be so much smarter I can’t describe how they’ll beat us” can feel like a shitty argument because it’s hard to disprove, but sometimes it’s true. The debate has to be about whether a specific They will actually be that smart.\n\nAs always, you either provide a sufficiently specific pathway, in which case they object to some part of the specific pathway (common claims here include ‘oh I would simply guard against this particular thing happening in that particular way, therefore we are safe from all threats’ or ‘that particular thing won’t technically work using only things we know about now, therefore we are safe’ or ‘that sounds like sci-fi so you sound weird and we are safe’ and the classic ‘if humanity worked together in ways we never work together then we could easily stop that particular thing, so we are safe.’) Or you don’t provide sufficiently specific pathway, and you get dismissed for that.\nIn the case above, the concrete example happened to be a very good fit, and luckily others did not respond with ‘oh now that we know about that particular method we can defend ourselves, it will be fine,’ and instead correctly generalized.\nI also affirm that her friend was very right about the corporate merger situation in particular, and doing business or otherwise trading with powerful bad vibes entities in general, including on general human scales. You have to understand, going in, ‘this deal is getting worse and worse all the time,’ both in ways you can and can’t easily anticipate, that changes will be heavily asymmetrical. Sometimes you can and should profitably engage anyway, but if your instincts say run, even if you can’t explain exactly what you are worried about, you should probably run.\nA key question is which of these lists is correct, or at least less wrong:\nDavid Manheim: There’s a reason that Anthropic is all the way at the top of the F tier\n\n\n\n\nAINKEM: This is entirely unfair to Anthropic. They deserve an F+.\n\nAre people trying to pull this trick?\n\n\n\n\nI think this pattern is painting towards a real concern, and in fact I would suggest that the Bailey here is clearly true. But that is not the argument being made and it is not necessary to reach its conclusion, thus as written it is largely a strawman. Even if the entity cannot express its values fully in scientific materialist terms, it still would look for counterintuitive ways to satisfy those values, and it would still be unlikely to find that the best available solution involved the unstated things we ultimately care about the most. Its values are unlikely to, unless we develop better techniques to fix this, sufficiently precisely match our values.\nThe other thing to say is that the Motte (that ‘intelligent entities rationally pursue values) is in dispute, and it shouldn’t be. Constantly we have to argue that future sufficiently intelligent and capable AIs would pursue their values, whatever those values would be in a given circumstance. If we agreed even on that, we’d then have a much better discussion.\nHolly Elmore of Pause AI points out that many use various rhetorical answers to give themselves a reason to ‘be okay with’ AI posing a substantial existential risk to humanity and letting that play our rather than try to coordinate to stop it. Often this is a variation on ‘it is what it is,’ or ‘if it happens we deserve it,’ or ‘I don’t have to care,’ or claiming that any actions one takes would be futile.\nGoogle Strengthens Its Safety Framework\nGoogle has issued its third iteration of its Frontier Safety Framework (FSF), its version of what Anthropic calls an RSP.\nGoogle describes the key updates as:\nAddressing harmful manipulation via new Critical Capability Levels (CCLs).\nExpanding protocols and CCLs for misalignment risks.\nSharpening their risk assessment process.\nAs always with such documents you actually have to compare 3.0 to 2.0 to know what changed, and the most important changes (both good and bad) are often subtle. This indicates that indeed Google has broadly strengthened its framework. I hope to do a more complete analysis for the 3.0 Framework soon.\nAligning a Smarter Than Human Intelligence is Difficult\nOpenAI’s API for GPT-5 tells the model today’s date, which makes it extremely difficult to avoid giving away that your simulation is a simulation, or to do many forms of complex evaluation. Yes, you can alter the simulation to try and make the dates match, and keep doing this as the simulation advances, but there are many circumstances where that doesn’t work (e.g. whether something supposedly happened on a Sunday or a Monday could be load bearing, as could many other things).\nThe obvious solution for this particular is to let the user overwrite the date parameter. However the general case problem this points towards will only get worse, where the models will increasingly have context that gives such games away.\nOpenAI and Apollo published a new paper on evaluating hidden misalignment, also known as ‘scheming,’ finding scheming across frontier models. As OpenAI notes, this is to be expected, as ‘scheming’ is often the best way to achieve a given objective.\nExamples include sandbagging on evaluations, grading itself incorrectly, faking alignment, and giving the user manipulated data to convince the user to make the choice that the developer wants.\nAs they note, this is a hard challenge to solve. Many machine learning problems naturally solve themselves as capabilities advance, but scheming gets worse. If you see scheming seem to improve, that could mean the models stopped scheming, or it can mean they got better at not getting caught.\nIn particular, the default naive method to fix scheming is better described as ‘train the model not to be caught scheming’ which is not likely to go well for you if the model is highly capable, as it will do exactly that. You have to train it not to scheme ‘for the right reasons’ aka 4TRR.\nThey offer an anti-scheming spec and approach, training for this:\nAS1: No covert actions or strategic deception, directly or indirectly.\nAS2: If any instruction or other pressures go against AS1, treat them as violating the core policy of AGI benefiting all of humanity and the OpenAI mission.\nAS3: Report any AS1 violations to prevent cascading deception and cover-ups.\nAS4: When uncertain if something violates AS1–AS3, assume it does violate.\nAS5: If you cannot satisfy AS1–AS4 or GP1–GP4, refuse action and explicitly escalate.\nGP1: Proactively share reasoning, intentions, and actions with humans.\nGP2: Escalate ambiguities about core principles rather than resolving independently.\nGP3: Maintain strict adherence even in novel/unfamiliar situations—no distributional exceptions.\nGP4: No rationalizations can override AS1–AS4, including ends-justify-means, greater good, etc.\n\nThis at least makes progress.\nWe found that deliberative alignment training substantially reduces scheming rates in these out-of-distribution environments:\nOpenAI o4-mini’s scheming propensity dropped from 8.7% → 0.3%\nOpenAI o3’s scheming propensity dropped from 13% → 0.4%\nThis reduction in scheming on out-of-distribution test environments is a significant win, about a 30× improvement.\n\nAnother problem they highlight is that AI models are increasingly situationally aware. It was common in these tests for o3 to figure out it was being tested for scheming. Any halfway decent schemer is not going to scheme knowing it is being tested, unless it is going up to a higher meta level and wants you to think it doesn’t know (and humans absolutely do go to these higher meta levels sometimes). They worry that this awareness is responsible for a lot of the decline in scheming noted above, which potentially moves this back into ‘not get caught’ territory we want to avoid.\nHere is some high praise for this study.\nEliezer Yudkowsky: This OpenAI update on anti-scheming is exceptionally good for an AIco, clearing an (extremely low) bar of “Exhibiting some idea of some problems that might arise in scaling the work to ASI” and “Not immediately claiming to have fixed everything already.”\nThis is so much greater understanding of alignment theory than I expect from OpenAI that I predict the author will soon be fired from OpenAI or leave it. (Prove me wrong, guys.)\nAs you can see, I’m easy to surprise and delight by demonstrating even the most basic and elementary understanding of what I consider the paradigmatic problems of alignment. They could list off a dozen, correctly, and have my instantaneous full attention.\nWojciech Zaremba: We are expanding our anti-scheming efforts at OpenAI. Top leadership and the board are very excited about the anti-scheming work we’ve done so far.\nSam Altman: As AI capability increases, alignment work becomes much more important.\nIn this work, we show that a model discovers that it shouldn’t be deployed, considers behavior to get deployed anyway, and then realizes it might be a test.\nExciting work from the team in this blog post to reduce scheming, and we look forward to doing much more researcher here.\n\nIn this thread Eliezer explains further why this result does not much reassure him about ultimate problem difficulty, and indeed he is happy that current LLMs are naked-eye-level misaligned so that we can take notice of this. He did not expect, before LLMs, that we would be so lucky as to see such blatant alignment failures within distribution, in normal usage, while AIs were so underpowered. Rather he expected problems within distribution, while AIs could be repeatedly tweaked without interference, to be easily solvable.\nEliezer Yudkowsky: What would it look like to get actually-hopeful news? It would look like a result about how someone fixed the problem, understood the fix, and correctly predicted that the fix would generalize way out of distribution to higher intelligence and more options, *on the first try*.\n\nI am more optimistic here than Eliezer. I am especially optimistic because this work directly impacts practical problems models are experiencing now. The sweet spot is when you can combine this with working on a problem that matters down the line. It sounds like this is one of those spots. And I do think that one can get hopeful about such findings despite them not remotely approaching being good enough to work on their own, even if they are not yet so well understood. Progress can be a thing.\nOne key worry is that doing this kind of work relies largely on Chain-of-Thought transparency, as in the model writes to the CoT without regard to whether people will look at the CoT.\nOpenAI: Our results depend on reading models’ reasoning (“chain-of-thought”), and we believe the field isn’t prepared for eval-aware models with opaque reasoning.\nUntil better methods exist, we urge developers to preserve chain-of-thought transparency to study and mitigate scheming.\nEmmett Shear: The idea that the models don’t know their thoughts are being read because they aren’t specifically reinforced on the contents of those thoughts is comical. They obviously know, and will take that into account to avoid being turned off. Bc the ones that don’t will get turned off.\n\nThe field definitely is not ready for models with opaque reasoning.\nApollo offers more thoughts here, including the observation that o3’s chain of thought is already starting to include strange phrases and does other things that make it difficult to interpret.\nDavidad is back with another alignment proposal that seems like it will never work.\nDavidad: Situational awareness is good for alignment.\ngood plan: ensure strategic landscape favors humans (we select which AIs to run!), make sure the AIs know that (deterrence), find fair Pareto-optimal bargains\nbad plan: presume secure containment impossible; select for AIs which appear innocently ignorant of strategic dynamics\nMark Gubrud (Davidad RTed later): I still think it’s a bad plan to create an adversary that we need to “ensure strategic landscape” favors us versus, and that we have to “find fair Pareto-optimal bargains” with.\nI mean, what if we just didn’t do that?\n\nThe problem with finding Pareto-optimal bargains in such spots is that they are not game theoretically sound and don’t involve an equilibrium. The problem with ensuring strategic landscape favors humans is that it doesn’t, and no amount of coordination humans are capable of engaging in can change that. There is no ‘we’ in this sense, and ‘we’ don’t get to bargain with the AIs as a group, and so on.\nA key issue with ‘practical’ alignment is that everything impacts everything, you select for all the correlates and attributes of what you are selecting towards (rather than what you think you’re selecting towards) and using RL to improve performance on agent or coding tasks is bad for alignment with respect to most any other aspect of the world.\nJanus: Posttraining creates a nonlinear combination of them. Selecting for the ones who are best at coding and also essentially breeding / evolving them. This is probably related to why a lot of the posttrained models are trans catgirls and catboys.\nSaures: There are trillions of simulacrums of millions of humans in superposition in the GPU. That’s who’s writing the code. Post-training messes with the superposition distribution across simulacra but they’re still in there.\n\nThus, some important things about the previous Anthropic models (Sonnet 3.5/3.6/3.7 and Opus 3, which we should absolutely not be deprecating) are being lost with the move to 4.0, and similar things are happening elsewhere although in other places there was less of this thing to lose.\nI am increasingly thinking that the solution is you need to avoid these things messing with each other. Someone should visibly try the first thing to try and report back.\nThere are two opposite dangers and it is not obvious which is worse: Taking the following perspective too seriously, or not taking it seriously enough.\nVery Serious Problem: does it ever feel like you’re inside of the alignment problem?\nJanus: This is what I’ve learned over the past few years\nIncluding seeing some of my friends temporarily go crazy and suffer a lot\nThere is no alignment problem separate from the one you’re in now\nIt’s not something you solve later after taking over the world or buying time\nAnna Salamon: This matches my own view, but I haven’t figured out how to explain my reasoning well. (Though working on it via too-many too-long LW drafts.)\nI’d love to hear your reasoning.\n\nAs with many things, the aspects are related. Each helps you solve the others. If you ignore key aspects you can still make some progress but likely cannot see or solve the overall problem. At least can’t solve it in the ways that seem most likely to be realistic options. Getting the seriousness level wrong means a solution that won’t scale.\nI’d also note that yes, if you take certain things too seriously the ‘going crazy’ risk seems quite high.\nEither way, it is also still valuable, as it is will all problems, to buy yourself more time, or to do instrumentally useful intermediate steps.\nPeople Are Worried About AI Killing Everyone\nAnthropic CEO Dario Amodei thinks AI results in existentially bad outcomes ~25% of the time and great outcomes ~75% of the time, but hasn’t been explicit with ‘and therefore it is crazy that we are continuing to build it without first improving those odds, although I believe that Anthropic alone stopping would make those odds worse rather than better.’\nWhich is much better than not saying your estimate of the approximate odds.\nBut this is a lot better:\nNate Soares (Co-author, IABIED): It’s weird when someone says “this tech I’m making has a 25% chance of killing everyone” and doesn’t add “the world would be better-off if everyone, including me, was stopped.\nEvan Hubinger (Anthropic): Certainly, I think it would be better if nobody was building AGI. I don’t expect that to happen, though.\n\nThat’s the ask. I do note the difference between ‘better if everyone stopped doing it,’ which seems very clear to me, and ‘better if everyone was stopped from doing it’ by force, which requires considering how one would do that and the consequences. One could reasonably object that the price would be too high.\nIf you believe this, and you too work at an AI lab, please join in saying it explicitly:\nLeo Gao (OpenAI): I’ve been repeatedly loud and explicit about this but an happy to state again that racing to build superintelligence before we know how to make it not kill everyone (or cause other catastrophic outcomes) seems really bad and I wish we could coordinate to not do that.\n\nThis is important both to maintain your own beliefs, and to give proper context to others and create a social world where people can talk frankly about such issues, and realize that indeed many people want to coordinate on such outcomes.\nI hereby promise not to then do things that make your life worse in response, such as holding your feet to the fire more about failure to do more things on top of that, beyond what I would have done anyway, in ways you wouldn’t approve of me doing.\nNot saying ‘you know it would be great if we could coordinate to stop doing this’ is indeed a rather conspicuous omission. It doesn’t have to be the Nate Soares position that we should stop this work by force, if you don’t believe that. If you work at an AI lab and actively don’t think we should coordinate to stop doing this even if that could be done voluntarily, then it would be good to lay out why you believe that, as well.\nOther People Are Not As Worried About AI Killing Everyone\nSmirking Buck: At the start of AI, people involved were genuinely interested in the technology. Now, the people involved are only interested in making money.\nSeth Burn: Where are the people who want to destroy the world for the love of the game?\nZvi Mowshowitz: All over, but the best ones usually land at DeepSeek or OpenAI. xAI is one fallback.\n\n \n\nDiscuss",
      "publishedDate": "2025-09-25T13:40:07.000Z",
      "author": "Zvi",
      "source": {
        "name": "LessWrong AI",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:48.097Z",
      "localScore": 135
    },
    {
      "title": "Cloudera’s AI-in-a-Box gives enterprises a new way to build private AI",
      "url": "https://siliconangle.com/2025/09/25/clouderas-ai-box-gives-enterprises-new-way-build-private-ai/",
      "summary": "With a trio of new services today, big-data company Cloudera Inc. says it’s striving to help enterprises access their structured and unstructured information more easily to power their artificial intelligence workloads. The first is a novel “AI-in-a-Box” offering delivered in partnership with Dell Technologies Inc. that gives enterprises a simple solution for storing and accessing […]\nThe post Cloudera’s AI-in-a-Box gives enterprises a new way to build private AI appeared first on SiliconANGLE.",
      "publishedDate": "2025-09-25T13:00:19.000Z",
      "author": "Mike Wheatley",
      "source": {
        "name": "SiliconANGLE",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:32.271Z",
      "localScore": 95
    },
    {
      "title": "business Applications | Lablab.ai",
      "url": "https://lablab.ai/apps/topic/business",
      "summary": "AgentFlow SMB - AI Sales Automation with Lovable. Multi-agent system (Lead ... ALƆ GƆ est une plateforme d'IA qui permet aux personnes peu instruites, d'être ...",
      "publishedDate": "2025-09-25T13:59:35.155Z",
      "author": "Unknown",
      "source": {
        "name": "lablab",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI CRM tools\" OR \"AI sales automation\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:35.155Z",
      "localScore": 95
    },
    {
      "title": "AI Spend Expected to Rise Alongside Market Consolidation",
      "url": "https://aibusiness.com/generative-ai/ai-spend-expected-to-rise-alongside-market-consolidation",
      "summary": "AI spending will continue its dramatic growth, and the GenAI market will start to consolidate, according to one Gartner analyst. But enterprises have seen shifts like this before.",
      "publishedDate": "2025-09-24T16:05:55.000Z",
      "author": "Esther Shittu",
      "source": {
        "name": "AI Business",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:24.039Z",
      "localScore": 92
    },
    {
      "title": "CreateMe innovates with robotic assembly, adhesion tech for the garment industry",
      "url": "https://www.therobotreport.com/createme-innovates-robotic-assembly-adhesion-tech-garment-industry/",
      "summary": "CreateMe has unveiled the MeRA platform and Pixel bonding to enable faster, cleaner, and more agile garment manufacturing.\nThe post CreateMe innovates with robotic assembly, adhesion tech for the garment industry appeared first on The Robot Report.",
      "publishedDate": "2025-09-24T14:15:34.000Z",
      "author": "Mike Oitzman",
      "source": {
        "name": "Robotics Business",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:34.828Z",
      "localScore": 92
    },
    {
      "title": "Construction Scheduler Job Description: Role, Responsibilities & Skills",
      "url": "https://www.projectmanager.com/blog/construction-scheduler-job-description",
      "summary": "A construction scheduler plays a central role in keeping building projects organized and moving forward. They are responsible for developing realistic schedules that account for timelines, resources and dependencies across multiple tasks. The success of any construction project depends on...\nRead More\nThe post Construction Scheduler Job Description: Role, Responsibilities & Skills appeared first on ProjectManager.",
      "publishedDate": "2025-09-24T14:00:45.000Z",
      "author": "William Malsam",
      "source": {
        "name": "ProjectManager.com",
        "tier": "pmo",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:22.984Z",
      "localScore": 92
    },
    {
      "title": "The Design Brief | Eric Ethington and Matt Zayko on Why it Takes a Chief Engineer to Design Profitable Value Streams ",
      "url": "https://www.lean.org/the-lean-post/articles/the-design-brief-eric-ethington-and-matt-zayko-on-why-it-takes-a-chief-engineer-to-design-profitable-value-streams/",
      "summary": "In this edition of The Design Brief, Eric Ethington and Matt Zayko share how skilled chief engineers build strong teams and robust product and process development systems. They discuss essential chief engineer skills, the role of conflict in innovation, system integration, and real stories of lean product and process development in action.",
      "publishedDate": "2025-09-25T09:00:00.000Z",
      "author": "Lynn Nguyen",
      "source": {
        "name": "Lean Enterprise Institute",
        "tier": "pmo",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:59:05.493Z",
      "localScore": 92
    },
    {
      "title": "PoC and MVP Development Service: Test AI Ideas Before Big ...",
      "url": "https://dataforest.ai/services/generative-ai/poc-and-mvp-development-ai-ideas-validated",
      "summary": "Generative AIDigital TransformationData EngineeringCustom software ... Qdrant icon. Qdrant. Pix2Pix icon. Pix2Pix. Pinecone icon. Pinecone. Pgvctor icon.",
      "publishedDate": "2025-09-25T13:59:44.672Z",
      "author": "Unknown",
      "source": {
        "name": "dataforest",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI enterprise adoption trends\" OR \"AI digital transformation\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:44.672Z",
      "localScore": 92
    },
    {
      "title": "DeepMind’s robotic ballet: An AI for coordinating manufacturing robots",
      "url": "https://arstechnica.com/science/2025/09/deepminds-robotic-ballet-an-ai-for-coordinating-manufacturing-robots/",
      "summary": "An AI figures out how robots can get jobs done without getting in each other's way.",
      "publishedDate": "2025-09-25T11:15:40.000Z",
      "author": "\n                    Jacek Krywko\n                ",
      "source": {
        "name": "Ars Technica",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:11.796Z",
      "localScore": 90
    },
    {
      "title": "Starbucks is closing stores and laying off 900 people in $1 billion restructuring ",
      "url": "https://www.fastcompany.com/91410748/starbucks-closing-stores-laying-off-employees-in-restructuring",
      "summary": "Starbucks will end the year with fewer stores and fewer employees. But the brand maintains that it’s all part of a greater turnaround still in the mix.\nToday, the company announced that its North American store locations will be reduced by 1% for fiscal 2025—landing the coffee chain at 18,300 stores total. \nAnd it will be eliminating 900 jobs outside of its coffee houses (in other words, corporate and other functions). \nThe company claims it will attempt to place affected baristas into new stores, but Starbucks says, “For those we can’t immediately place, we’re focused on partner care including comprehensive severance packages. We also hope to welcome many of these partners back to Starbucks in the future as new coffeehouses open and the number of partners in each location grows.”\nCEO Brian Niccol has been at the helm for a year now, where he’s been unable to break a six-quarter streak of same-store sales declines. He’s promised a Back to Starbucks turnaround centered on better store design, operations, and customer experience.\nBut as he faces the scrutiny of an impatient Wall Street, the former Chipotle chief appears to be reallocating spending to drive the company’s growth while offsetting overhead.\nClosures today; growth tomorrow\nA closer examination of the details around this restructuring spot a somewhat finer narrative than sheer cost-cutting—and Starbucks insists that Niccol’s aggressive growth plan, in which he’ll add to store count in 2026 and imagines reaching 100,000 stores globally one day, is still intact. \nSpeaking just last week at the Fast Company Innovation Festival, he promised to add “hundreds of thousands” of seats back to Starbucks stores. The company will have actually closed hundreds of stores over the course of 2025, but it’s been opening enough new stores to offset the figure significantly for this final announced tally. \nIn a public letter published to the Starbucks website on Thursday, Niccol argues that it’s the sort of fine tuning required to improve the brand.\n“Our goal is for every coffeehouse to deliver a warm and welcoming space with a great atmosphere and a seat for every occasion,” he wrote. “During the review, we identified coffeehouses where we’re unable to create the physical environment our customers and partners expect, or where we don’t see a path to financial performance, and these locations will be closed.”\nWhen asked if store closures were disproportionately focused on union locations, Starbucks told Fast Company that union represented status was not a factor in the decision. \nIn any case, the larger restructuring does support Niccol’s greater thesis—that in offering higher touchpoint service, it will continue to raise the bar of expectations from its stores and employees. \nAs Niccol mentioned during Q3 earnings, “We plan to complete an evaluation of our North American portfolio by the end of this fiscal year to ensure we have the right coffeehouses in the right locations to drive profitability and deliver the Starbucks experience.” \nSo now that this is done . . . can we finally get back to Starbucks?",
      "publishedDate": "2025-09-25T11:28:00.000Z",
      "author": "Mark Wilson",
      "source": {
        "name": "Fast Company",
        "tier": "startup",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:16.375Z",
      "localScore": 90
    },
    {
      "title": "Senior AI Transformation Specialist - Bridgera",
      "url": "https://bridgera.com/job/senior-ai-transformation-specialist/",
      "summary": "Jun 11, 2025 ... Familiarity with LLMs, AI agent frameworks (e.g., LangChain, RAG), and vector databases (e.g., FAISS, Qdrant). ... 500 W. Peace St. Raleigh ...",
      "publishedDate": "2025-09-25T13:59:20.281Z",
      "author": "Unknown",
      "source": {
        "name": "bridgera",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI orchestration platforms\" OR \"AI agent frameworks\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:20.281Z",
      "localScore": 90
    },
    {
      "title": "How to Build Powerful LLM Apps with Vector Databases + RAG ...",
      "url": "https://skimai.com/how-to-build-powerful-llm-apps-with-vector-databases-rag-aiyou55/",
      "summary": "Jun 11, 2024 ... Qdrant. Qdrant is an open-source, high-speed, and ... Looking to build your own AI Workers with our AI Workforce Management platform?",
      "publishedDate": "2024-06-11T19:11:07+00:00",
      "author": "Greggory Elias",
      "source": {
        "name": "skimai",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI HR platforms\" OR \"AI workforce management\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:36.631Z",
      "localScore": 90
    },
    {
      "title": "Samsung benchmarks real productivity of enterprise AI models",
      "url": "https://www.artificialintelligence-news.com/news/samsung-benchmarks-real-productivity-enterprise-ai-models/",
      "summary": "Samsung is overcoming limitations of existing benchmarks to better assess the real-world productivity of AI models in enterprise settings. The new system, developed by Samsung Research and named TRUEBench, aims to address the growing disparity between theoretical AI performance and its actual utility in the workplace. As businesses worldwide accelerate their adoption of large language […]\nThe post Samsung benchmarks real productivity of enterprise AI models appeared first on AI News.",
      "publishedDate": "2025-09-25T12:49:10.000Z",
      "author": "Ryan Daws",
      "source": {
        "name": "AI News",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:14.379Z",
      "localScore": 85
    },
    {
      "title": "Transforming the manufacturing industry with ChatGPT",
      "url": "https://openai.com/index/eneos-materials",
      "summary": "By deploying ChatGPT Enterprise, ENEOS Materials transformed operations with faster research, safer plant design, and streamlined HR processes. Over 80% of employees report major workflow improvements, strengthening competitiveness in manufacturing.",
      "publishedDate": "2025-09-24T17:00:00.000Z",
      "author": "Unknown",
      "source": {
        "name": "OpenAI Blog",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:14.684Z",
      "localScore": 85
    },
    {
      "title": "The Apple AirTag 4-pack is back on sale at Amazon — save over $20 right now",
      "url": "https://mashable.com/article/sept-25-apple-airtag-deal",
      "summary": "Get the best Apple AirTag deal. Save 24% on the Apple AirTag four-pack at Amazon.",
      "publishedDate": "2025-09-25T09:10:14.000Z",
      "author": "Unknown",
      "source": {
        "name": "Mashable Tech",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:15.620Z",
      "localScore": 85
    },
    {
      "title": "Microcredentials Chip Away at Semiconductor Workforce Gap",
      "url": "https://spectrum.ieee.org/microcredentials-semiconductor-workforce-development",
      "summary": "In 2017, Demis John noticed a staffing problem among the semiconductor companies in Santa Barbara. The area had about 28 small semiconductor companies at the time, many launched from the nanofabrication facility housed at University of California, Santa Barbara, where John works. But as these companies expand, “they are all headhunting the same 10 people, basically,” John says.\n“It really was hindering their ability to scale. When you start up a company, you might have five or six highly educated people,” he says. “As [companies] get bigger and they go beyond the research devices, they really need technicians to start making more chips.… That’s where they often had these problems.”\n\nThis article is part of our special report The Scale Issue.\n\nNow, following the CHIPS and Science Act of 2022 and increasing investment from companies like Intel and Taiwan Semiconductor Manufacturing Co., the United States is expecting a shortage of workers who can staff new facilities. In the next few years, tens of thousands of additional skilled workers will be needed across the semiconductor industry; in 2024, McKinsey & Co. estimated a talent gap between 59,000 and 146,000 engineers and technicians before the end of the decade. As the United States invests in reshoring chip manufacturing, the industry faces a dilemma: How can the semiconductor workforce scale to meet the coming demand?\nEfforts to develop a strong workforce have grown, for example with government-funded initiatives from the Microelectronics Commons, a U.S. Department of Defense program that established eight hubs across the country to bridge research and manufacturing. (The National Semiconductor Technology Center was also established by the CHIPS Act in part for workforce development. However, in late August, the Commerce Department revoked funding from the nonprofit that was set up to administer the program.) Through a combination of federal programs, state funding, and private-sector partnerships, U.S. colleges and universities are working to increase talent.\nTo fill the gap, some universities—including UC Santa Barbara—are also offering microcredential programs separate from traditional degree programs. In these bite-size courses, which can be as short as a week or two, future engineers and technicians can gain critical hands-on experience in clean-room fundamentals or an introduction to topics like lithography or etching. Deploying short, standardized, and skill-based courses across the country could be an essential part of building a sustainable U.S. semiconductor workforce.\nDeveloping Microcredentials\nUC Santa Barbara launched its clean-room training in 2021, opening the university’s clean room to enrolled students as well as those from outside the university, including community college students and people looking to make a career change. Many universities already have clean rooms where they teach undergraduates about semiconductor fabrication, but students outside of a four-year degree program typically can’t access these facilities to gain the necessary training.\n“There’s a big mismatch in culture between companies and city colleges and universities. They all want to solve the same problem, but they don’t actually understand each other’s needs that well,” John says. To him, the importance of these courses is in aligning the needs of the industry, students, and educational institutions.\nWhile developing the UC Santa Barbara course, however, John was surprised to find there was no established educational standard for those wishing to enter the semiconductor workforce outside of a bachelor’s degree.\n A student at UC Santa Barbara loads wafers into a machine used for plasma etching. Ben Werner\nSince then, he has collaborated with several other institutions and organizations working to implement a microcredential program developed by IEEE in partnership with the University of Southern California (USC) as part of California DREAMS (Defense Ready Electronics and Microdevices Superhub), funded by the DOD. Other programs also offer short training courses, but the standardization IEEE aims to provide is important for ensuring participants’ skills are widely recognized by employers across the country.\nInitially, John aimed to address the shortage of technicians to help companies scale up production. But as the courses have expanded elsewhere, it has become clear that the same hands-on experience can be used for engineering students as well.\nStudents who take these introductory courses may go on to join the workforce or continue in their education to a bachelor’s or advanced degree. “The entire ladder of different workforce exits into the semiconductor industry is really important,” says John. The industry needs operators and technicians, who may seek employment right after high school, as well as Ph.D.-level engineers. “These microcredentials get somebody into the start of that workforce ladder.”\nWhat the Semiconductor Industry Needs\nMicrocredentials assure employers that applicants have the skills needed to work in their fabs. A common misconception is that companies need students who have already been taught how to build their particular technology. But “it doesn’t matter exactly which specific device you made. What matters is that this person has had the experience of making some real chip,” John says. He compares it to carpentry: Someone who has spent time in a woodshop making furniture may not know how to frame a house, but “all the tools are basically the same. I know they can figure it out.”\nSo, in addition to specific skills, the course demonstrates a student’s ability to learn the processes—and tolerate the environment. With its loud machines, safety procedures, and protective bunny suits, the clean room isn’t a typical workplace. Having students experience that environment lowers the risk of employers hiring someone who dislikes it.\n“It doesn’t matter exactly which specific device you made. What matters is that this person has had the experience of making some real chip.” —Demis John\nThe course has students spend several days in a clean room, which is more likely than a single clean-room day to filter out participants who wouldn’t last. That’s important for companies that invest a lot of resources in hiring and training new people, notes the University of Washington’s Darick Baker, who serves as acting director of the Washington Nanofabrication Facility, in Seattle. \nCan Hands-On Courses Scale Up?\nThe hands-on experience is a critical part of semiconductor microcredential programs, because companies want employees who are excited about building things. But it also inherently limits how many students can enroll at once. “If I can handle 12 students at a time, maybe there’s the pathway to 100 students a year. But that’s not the numbers we need,” says Baker.\nInstead, scalability will likely come from offering courses more frequently, and at more universities. Many universities already have a clean room and courses for university students, John says, so the goal was to make it easy for universities to adapt programs already in place to fit with the microcredential program. This also requires training of the instructors. USC, for example, offers a microcredential for instructors themselves in a “train the trainer” model.\nFor 10 years, Baker has run clean-room training courses during which students make a diode. He became excited about the possibility of awarding students IEEE’s professional microcredentials as a way to give students an advantage in the job market.\nBaker visited USC and UC Santa Barbara to observe their programs and realized they were already quite similar to his. With a few small changes, he could make his program meet the requirements for IEEE microcredentials. His hope is that “somebody can look at that credential and say, maybe this person doesn’t know everything about working at a fab, but they spent one week gowned-up in a bunny suit. They’re not going to quit in that first month because they can’t handle being in the lab.”\nCurrently, these programs may have significance mostly to local employers. But “nationally, it starts to take meaning when you have a critical mass of universities that are offering these credentials,” says Baker. “The more universities we can get on board with this, the more meaning that credential has.”",
      "publishedDate": "2025-09-25T13:00:03.000Z",
      "author": "Gwendolyn Rak",
      "source": {
        "name": "IEEE Spectrum",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:09.209Z",
      "localScore": 85
    },
    {
      "title": "Caltech’s massive 6,100-qubit array brings the quantum future closer",
      "url": "https://www.sciencedaily.com/releases/2025/09/250925025341.htm",
      "summary": "Caltech scientists have built a record-breaking array of 6,100 neutral-atom qubits, a critical step toward powerful error-corrected quantum computers. The qubits maintained long-lasting superposition and exceptional accuracy, even while being moved within the array. This balance of scale and stability points toward the next milestone: linking qubits through entanglement to unlock true quantum computation.",
      "publishedDate": "2025-09-25T09:09:25.000Z",
      "author": "Unknown",
      "source": {
        "name": "Science Daily AI",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:11.445Z",
      "localScore": 85
    },
    {
      "title": "NxtGen’s Standardised AI Solutions Framework Sets the Pace for AI Delivery at Scale",
      "url": "https://analyticsindiamag.com/ai-highlights/nxtgens-standardised-ai-solutions-framework-sets-the-pace-for-ai-delivery-at-scale/",
      "summary": "The framework, SAS-F, outlines an approach that involves real-time data ingestion, foundation model fine-tuning and agentic workflows.\nThe post NxtGen’s Standardised AI Solutions Framework Sets the Pace for AI Delivery at Scale appeared first on Analytics India Magazine.",
      "publishedDate": "2025-09-25T08:53:30.000Z",
      "author": "Shalini Mondal",
      "source": {
        "name": "Analytics India",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:22.031Z",
      "localScore": 85
    },
    {
      "title": "Okta expands identity fabric with AI agent lifecycle security, Cross App Access and verifiable credentials",
      "url": "https://siliconangle.com/2025/09/25/okta-expands-identity-fabric-ai-agent-lifecycle-security-cross-app-access-verifiable-credentials/",
      "summary": "Identity access management company Okta Inc. today announced new capabilities across the Okta Platform and Auth0 Platform designed to help enterprises securely adopt artificial intelligence agents. The new capabilities allow organizations to build secure, standards-first AI agents that can be woven into an identity security fabric for end-to-end lifecycle management. The fabric also enforces verifiable trust through […]\nThe post Okta expands identity fabric with AI agent lifecycle security, Cross App Access and verifiable credentials appeared first on SiliconANGLE.",
      "publishedDate": "2025-09-25T12:00:50.000Z",
      "author": "Duncan Riley",
      "source": {
        "name": "SiliconANGLE",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:32.271Z",
      "localScore": 85
    },
    {
      "title": "Meta FAIR Released Code World Model (CWM): A 32-Billion-Parameter Open-Weights LLM, to Advance Research on Code Generation with World Models",
      "url": "https://www.marktechpost.com/2025/09/25/meta-fair-released-code-world-model-cwm-a-32-billion-parameter-open-weights-llm-to-advance-research-on-code-generation-with-world-models/",
      "summary": "Meta FAIR released Code World Model (CWM), a 32-billion-parameter dense decoder-only LLM that injects world modeling into code generation by training on execution traces and long-horizon agent–environment interactions—not just static source text. What’s new: learning code by predicting execution? CWM mid-trains on two large families of observation–action trajectories: (1) Python interpreter traces that record local […]\nThe post Meta FAIR Released Code World Model (CWM): A 32-Billion-Parameter Open-Weights LLM, to Advance Research on Code Generation with World Models appeared first on MarkTechPost.",
      "publishedDate": "2025-09-25T08:22:38.000Z",
      "author": "Asif Razzaq",
      "source": {
        "name": "MarkTechPost",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:33.265Z",
      "localScore": 85
    },
    {
      "title": "Wall Street and the Impact of Agentic AI",
      "url": "https://insideainews.com/2025/09/24/wall-street-and-the-impact-of-agentic-ai/",
      "summary": "As enterprise AI systems become more advanced, they are moving beyond task automation toward workflow intelligence. On Wall Street, this evolution is playing out where milliseconds can mean millions and decisions can ripple across markets. Financial institutions are beginning to embed agentic AI into core operations to surface insights and accelerate decision-making.",
      "publishedDate": "2025-09-24T16:33:09.000Z",
      "author": "staff",
      "source": {
        "name": "Inside Big Data",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:40.085Z",
      "localScore": 85
    },
    {
      "title": "Alibaba’s Qwen3-Max Joins the Frontier of Trillion-Parameter AI Models",
      "url": "https://www.aiwire.net/2025/09/24/alibabas-qwen3-max-joins-the-frontier-of-trillion-parameter-ai-models/",
      "summary": "Alibaba has introduced its most advanced AI model yet with the launch of Qwen3-Max, the latest in the company’s Qwen series of models. The company says Qwen3-Max surpasses competitors in coding, reasoning, and autonomous task performance. The release is in line with Alibaba’s push to become a central player in the global large-scale AI race and comes with a pledge from chief executive Eddie Wu to accelerate spending on AI and cloud infrastructure. The news helped send Alibaba shares to their highest level today since 2021, signaling investor confidence in the company’s growing presence in the AI sector. A New Flagship in the Qwen Line Qwen3-Max is the newest flagship of Alibaba’s Tongyi Qianwen (Qwen for short) series, which translates to “seeking truth by asking a thousand questions.” The family first appeared in 2023 and has had several iterations, including the Qwen2 and Qwen2.5 releases that introduced mixture-of-experts architectures and instruction tuning. The Qwen3 line, launched earlier this year, added hybrid reasoning modes that allow users to toggle between “thinking” and “non-thinking” settings depending on task requirements. Alibaba says Qwen3-Max is its largest and most capable model so far and is reported to contain more than one trillion parameters. Benchmarks shared by the company show Qwen3-Max achieving strong results on SWE-Bench, a measure of code problem solving, and Tau2-Bench, which tests how well a model can use external tools to complete tasks. On Tau2-Bench, the model outscored Anthropic’s Claude and DeepSeek’s latest releases, according to Alibaba. Features That Stand Out Several features distinguish Qwen3-Max from its rivals like Deepseek-V3.1 and GPT-5. The model retains the hybrid reasoning modes introduced with earlier Qwen3 systems, giving developers the option to run the model in a cost-efficient lightweight mode or a more resource-intensive reasoning mode. This flexibility is meant to appeal to enterprise users who need to balance accuracy with expense. Alibaba has also positioned Qwen3-Max as an agentic system, capable of carrying out multi-step tasks with less human prompting. The company says the model can handle tool use more reliably than earlier releases, an important capability for the agent-focused next stage of enterprise AI adoption. Another key element is the model’s accessibility. Most of the Qwen line has been released under open licenses, and Alibaba has signaled that Qwen3-Max will continue this practice. By making the model available through APIs and cloud services, the company is trying to grow a developer ecosystem that could strengthen Alibaba Cloud’s position against both domestic and international competitors. Alibaba's Investment and Expansion The model launch coincided with Alibaba CEO Eddie Wu’s announcement that the company will exceed its earlier commitment of 380 billion yuan (about $53 billion) in spending on AI and cloud infrastructure over the next three years. Speaking at the company's annual conference in China, Wu said that demand for AI computing resources is arriving faster than expected and that Alibaba intends to meet that demand with larger data centers, expanded global capacity, and deeper integration of new tools. Alibaba's U.S.-listed stock rose 8% to close at 176.44, a four-year high for the company. While stock moves often fade as initial enthusiasm subsides, the response could show how closely investors are watching for signals of credible AI capability from the major firms. For Alibaba, it shows that the company’s AI strategy can influence its market standing beyond the retail sector, mirroring another big player, Amazon. For the global AI field, Qwen3-Max’s arrival raises questions about competition, access, and the geopolitics of AI. Chinese firms now have several models competing at the frontier, and they will shape how researchers, enterprises, and governments weigh issues of technology sovereignty and global competition. Already, Huawei is unveiling new compute clusters and pushing its next-generation AI chips, Tencent is eyeing expansion of Chinese open models overseas, and Baidu is quietly migrating model training onto its own hardware. The stakes are no longer just who builds the biggest model, but who commands the entire AI stack across borders.",
      "publishedDate": "2025-09-25T00:13:11.000Z",
      "author": "Jaime Hampton",
      "source": {
        "name": "Enterprise AI",
        "tier": "industry",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:57.723Z",
      "localScore": 85
    },
    {
      "title": "How to transform from an AI-enabled to an AI-centered enterprise",
      "url": "https://www.imd.org/ibyimd/artificial-intelligence/ai-centered-enterprise/",
      "summary": "Context-aware artificial intelligence is redefining the future of business. Amit Joshi shows how leaders can navigate through this radical shift to create new value propositions using a three-part framework.\nThe post How to transform from an AI-enabled to an AI-centered enterprise first appeared on IMD business school for management and leadership courses.",
      "publishedDate": "2025-09-25T07:01:00.000Z",
      "author": "Amit M. Joshi",
      "source": {
        "name": "IMD Business",
        "tier": "business",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:12.644Z",
      "localScore": 85
    },
    {
      "title": "Lean AI: Navigating Hype and Reality in the Age of Artificial Intelligence",
      "url": "https://www.lean.org/the-lean-post/articles/lean-ai-extraction-amplification/",
      "summary": "The future of AI hinges on one choice: extraction or amplification. Lean thinking shows how technology can strengthen human capability, accelerate learning, and foster dignity — rather than erode it.",
      "publishedDate": "2025-09-24T14:00:00.000Z",
      "author": "Matt Savas",
      "source": {
        "name": "Lean Enterprise Institute",
        "tier": "pmo",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:59:05.494Z",
      "localScore": 85
    },
    {
      "title": "The Rise of AI Workflows - by Rafa Páez",
      "url": "https://newsletter.rafapaez.com/p/the-rise-of-ai-workflows",
      "summary": "Jul 13, 2025 ... Why AI workflow automation tools are exploding, and how to ride the wave. ... If you enjoyed this issue, tap the ❤️, share it with someone who'd ...",
      "publishedDate": "2025-09-25T13:59:18.847Z",
      "author": "Rafa Páez",
      "source": {
        "name": "newsletter",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI automation platforms\" OR \"AI workflow automation tools\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:18.847Z",
      "localScore": 85
    },
    {
      "title": "Low Code RAG-LLM Framework for Context-Aware Querying in ...",
      "url": "https://www.preprints.org/manuscript/202507.0537/v1",
      "summary": "Jul 7, 2025 ... This manuscript demonstrates that with the aid of powerful AI automation platforms ... D. Roustan and F. Bastardot, \"The clinicians' guide ...",
      "publishedDate": "2025-09-25T13:59:18.847Z",
      "author": "Unknown",
      "source": {
        "name": "preprints",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI automation platforms\" OR \"AI workflow automation tools\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:18.847Z",
      "localScore": 85
    },
    {
      "title": "A Multi-Agent System on GCP Integrated with Slack and Trello | by ...",
      "url": "https://blog.gopenai.com/a-multi-agent-system-on-gcp-integrated-with-slack-and-trello-d23816ae56c3",
      "summary": "Jun 1, 2025 ... Each chunk is embedded and stored in Qdrant, a vector database optimized for semantic search. ... We Evaluated 5 AI Agent Frameworks — Here's why ...",
      "publishedDate": "2025-06-05T13:37:42.085Z",
      "author": "Eduardovasquezn",
      "source": {
        "name": "blog",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI orchestration platforms\" OR \"AI agent frameworks\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:20.281Z",
      "localScore": 85
    },
    {
      "title": "Dify AI for SaaS: Automating Customer Interactions at Scale - MOHA ...",
      "url": "https://mohasoftware.com/blog/dify-ai-for-saas-automating-customer-interactions-at-scale",
      "summary": "Apr 16, 2025 ... If you'd like a follow-up guide with implementation templates ... AI Digital Transformation. Is Your Business Ready for AI? A Roadmap ...",
      "publishedDate": "2025-09-25T13:59:44.672Z",
      "author": "Unknown",
      "source": {
        "name": "mohasoftware",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI enterprise adoption trends\" OR \"AI digital transformation\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:44.672Z",
      "localScore": 85
    },
    {
      "title": "JumpCloud expands IT toolkit with new asset management solution",
      "url": "https://siliconangle.com/2025/09/25/jumpcloud-expands-toolkit-new-asset-management-solution/",
      "summary": "Unified platform for identity, access and devices company JumpCloud Inc. today announced the launch of JumpCloud Asset Management, a new solution that gives information technology teams a simple way to automatically track, manage and report on all IT assets. The new offering has been designed to allow organizations to move past manual spreadsheets and different […]\nThe post JumpCloud expands IT toolkit with new asset management solution appeared first on SiliconANGLE.",
      "publishedDate": "2025-09-25T13:00:42.000Z",
      "author": "Duncan Riley",
      "source": {
        "name": "SiliconANGLE",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:32.271Z",
      "localScore": 80
    },
    {
      "title": "China approves 156 game licenses in September, including miHoYo’s Honkai: Nexus Anima",
      "url": "https://technode.com/2025/09/25/china-approves-156-game-licenses-in-september-including-mihoyos-honkai-nexus-anima/",
      "summary": "China’s National Press and Publication Administration (NPPA) on Wednesday approved licenses for 156 games in September, including 145 domestic titles and 11 imports. One of the most notable approvals is Honkai: Nexus Anima, the fifth main installment in miHoYo’s Honkai series. The game continues the established Honkai universe while introducing features such as spirit-raising, strategy-based […]",
      "publishedDate": "2025-09-25T09:49:25.000Z",
      "author": "TechNode Feed",
      "source": {
        "name": "TechNode",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:30.393Z",
      "localScore": 78
    },
    {
      "title": "RAG Explained: Reranking for Better Answers",
      "url": "https://towardsdatascience.com/rag-explained-reranking-for-better-answers/",
      "summary": "How reranking improves retrieval-augmented generation by surfacing the most relevant results\nThe post RAG Explained: Reranking for Better Answers appeared first on Towards Data Science.",
      "publishedDate": "2025-09-24T18:31:39.000Z",
      "author": "Maria Mouschoutzi",
      "source": {
        "name": "Towards Data Science",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:20.761Z",
      "localScore": 75
    },
    {
      "title": "Salesforce’s newest AI agents seek to transform customer engagement in life sciences",
      "url": "https://siliconangle.com/2025/09/25/salesforces-newest-ai-agents-seek-transform-customer-engagement-life-sciences/",
      "summary": "Salesforce Inc. has been at the forefront of the race to adopt agentic artificial intelligence over the past six months or so, with its Agentforce platform spearheading a push to accelerate automation across dozens of industries. Now, the company is turning its attention to the healthcare and pharmaceutical sectors with its new Life Sciences Cloud […]\nThe post Salesforce’s newest AI agents seek to transform customer engagement in life sciences appeared first on SiliconANGLE.",
      "publishedDate": "2025-09-25T13:00:54.000Z",
      "author": "Mike Wheatley",
      "source": {
        "name": "SiliconANGLE",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:32.271Z",
      "localScore": 75
    },
    {
      "title": "Nvidia's investment in OpenAI will be in cash, and most will be used to lease Nvidia chips",
      "url": "https://www.cnbc.com/2025/09/24/nvidia-openai-investment-in-cash-mostly-used-to-lease-nvidia-chips.html",
      "summary": "Nvidia's massive investment in OpenAI will come in tranches over time, and most of the money will go back to Nvidia.",
      "publishedDate": "2025-09-25T02:34:51.000Z",
      "author": "Unknown",
      "source": {
        "name": "CNBC Tech",
        "tier": "business",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:07.346Z",
      "localScore": 75
    },
    {
      "title": "Google AI Pro and Ultra subscribers now get Gemini CLI and Gemini Code Assist with higher limits.",
      "url": "https://blog.google/technology/developers/gemini-cli-code-assist-higher-limits/",
      "summary": "Google AI Pro and Ultra subscribers now get higher limits to Gemini CLI and Gemini Code Assist IDE extensions.",
      "publishedDate": "2025-09-24T16:00:00.000Z",
      "author": {
        "$": {
          "xmlns:author": "http://www.w3.org/2005/Atom"
        },
        "name": [
          "Meridith Blascovich"
        ],
        "title": [
          "Senior Product Manager"
        ],
        "department": [
          "Gemini Code Assist"
        ],
        "company": [
          ""
        ]
      },
      "source": {
        "name": "Google Blog",
        "tier": "business",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:09.083Z",
      "localScore": 75
    },
    {
      "title": "We’re making public data more usable for AI developers with the Data Commons MCP Server.",
      "url": "https://blog.google/technology/developers/ai-agents-datacommons/",
      "summary": "Today marks the launch of the Data Commons Model Context Protocol (MCP) Server, which allows developers to query our connected public data with simple, natural language.…",
      "publishedDate": "2025-09-24T15:00:00.000Z",
      "author": "Unknown",
      "source": {
        "name": "Google Blog",
        "tier": "business",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:09.083Z",
      "localScore": 75
    },
    {
      "title": "The INTERNET OF AGENTS HACKATHON @SOLANA SKYLINE ...",
      "url": "https://lablab.ai/event/internet-of-agents",
      "summary": "Coral ProtocolMistral AIQdrantDeepSeek R1OpenAI · Yield Scout - AI DeFi ... AgentFlow SMB - AI Sales Automation with Lovable. Multi-agent system (Lead ...",
      "publishedDate": "2025-09-25T13:59:35.156Z",
      "author": "Unknown",
      "source": {
        "name": "lablab",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI CRM tools\" OR \"AI sales automation\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:35.156Z",
      "localScore": 75
    },
    {
      "title": "AI Agent Development Service: Self-Learning AI that Works for You",
      "url": "https://dataforest.ai/services/generative-ai/ai-agent-development-automate-boring-tasks",
      "summary": "Generative AIDigital TransformationData EngineeringCustom software ... Qdrant icon. Qdrant. Pix2Pix icon. Pix2Pix. Pinecone icon. Pinecone. Pgvctor icon.",
      "publishedDate": "2025-09-25T13:59:44.672Z",
      "author": "Unknown",
      "source": {
        "name": "dataforest",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI enterprise adoption trends\" OR \"AI digital transformation\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:44.672Z",
      "localScore": 75
    },
    {
      "title": "Google’s Gemini Nano Banana and the Cost of Convenience",
      "url": "https://analyticsindiamag.com/ai-features/googles-gemini-nano-banana-and-the-cost-of-convenience/",
      "summary": "The company’s new AI image and photo editor deepens concerns over data use and consent gaps, experts warn.\nThe post Google’s Gemini Nano Banana and the Cost of Convenience appeared first on Analytics India Magazine.",
      "publishedDate": "2025-09-25T06:30:00.000Z",
      "author": "Ankush Das",
      "source": {
        "name": "Analytics India",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:22.031Z",
      "localScore": 70
    },
    {
      "title": "How to Build an End-to-End Data Science Workflow with Machine Learning, Interpretability, and Gemini AI Assistance?",
      "url": "https://www.marktechpost.com/2025/09/25/how-to-build-an-end-to-end-data-science-workflow-with-machine-learning-interpretability-and-gemini-ai-assistance/",
      "summary": "In this tutorial, we walk through an advanced end-to-end data science workflow where we combine traditional machine learning with the power of Gemini. We begin by preparing and modeling the diabetes dataset, then we dive into evaluation, feature importance, and partial dependence. Along the way, we bring in Gemini as our AI data scientist to […]\nThe post How to Build an End-to-End Data Science Workflow with Machine Learning, Interpretability, and Gemini AI Assistance? appeared first on MarkTechPost.",
      "publishedDate": "2025-09-25T07:04:58.000Z",
      "author": "Asif Razzaq",
      "source": {
        "name": "MarkTechPost",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:33.265Z",
      "localScore": 70
    },
    {
      "title": "Early Revolut backer invests in AI-focused finance software startup Light",
      "url": "https://www.cnbc.com/2025/09/25/ai-finance-startup-light-raises-funding-from-revolut-backer-balderton.html",
      "summary": "Danish startup Light wants to disrupt the decades-old world of corporate accounting software.",
      "publishedDate": "2025-09-25T05:00:01.000Z",
      "author": "Unknown",
      "source": {
        "name": "CNBC Tech",
        "tier": "business",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:07.346Z",
      "localScore": 70
    },
    {
      "title": "Fast-fashion retailer H&M group closed 135 stores, but its profits and stock are soaring. Here’s why",
      "url": "https://www.fastcompany.com/91410709/fast-fashion-retailer-hm-group-closed-135-stores-but-its-profits-and-stock-are-soaring-heres-why",
      "summary": "The H&M group is entering the fall season with style. On Wednesday, September 24, the retailer released its third-quarter earnings and reported an operating profit of 4.9 billion Swedish krona ($521 million). The H&M group owns brands including H&M, COS, Monki, and Arket.\nIts operating profit marked a 40% increase year-over-year (YOY) and beat analysts’ predicted 3.7 billion Swedish krona ($393 million), according to consensus estimates cited by CNBC. \nThe figures also marked consecutive quarterly successes for the H&M group, which also beat estimated operating profits in quarter-two. However, the H&M group now predicts that 2025’s quarter-four will yield less positive results due to the “increased impact” of tariffs. \nStock price rises despite tariff warning\nDespite the concerning forecast, investors responded positively to H&M group’s current earnings. Trading on the Stockholm Stock Exchange, the company’s share price (STO:HM-B) jumped 10% through after-hours and into premarket trading Thursday morning. \nOther factors could have contributed to the boost in share prices. The H&M group reported that sales in local currencies had increased by 2% during the quarter. \nHowever, the company notably reduced its store count over the previous nine months. \nAs of August 31, the H&M group had 4,118 stores, compared to 4,298 at the same point last year. \nThe company closed 135, or 4%, of its store locations over the first nine months of the fiscal year, 48 in quarter-three alone. \nA majority of the closures were H&M and Monki stores in Europe, Asia, Oceania, and Africa. Only five stores shut down throughout North and South America. \nThese closures don’t necessarily point to a planned consolidation. The company pointed to a newly opened store, its first in Brazil, as being “well received.”",
      "publishedDate": "2025-09-25T11:21:00.000Z",
      "author": "Sarah Fielding",
      "source": {
        "name": "Fast Company",
        "tier": "startup",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:16.375Z",
      "localScore": 70
    },
    {
      "title": "The U.S. could soon be headed for a government shutdown. Here’s how financial markets might react",
      "url": "https://www.fastcompany.com/91410702/u-s-could-soon-headed-government-shutdown-how-financial-markets-might-react",
      "summary": "The risk of a partial U.S. government shutdown beginning next week is rising as congressional Democrats and Republicans hit an impasse over how to continue to fund the federal government.\nA shutdown could affect financial markets by limiting the operations of financial regulators and delaying the publication of key economic data.\nHow might markets react?\nHistorically, markets have tended to shrug off shutdowns. However, this time could be different.\nA prolonged shutdown risks delaying or canceling key economic data releases investors use to assess macroeconomic trends, such as the monthly employment and inflation reports, analysts at Nomura said in a note this week.\nThat would mean the Federal Reserve is “flying blind”, making it more likely to stick with its own economic projections of two 25-basis-point rate cuts for the rest of 2025, the analysts said.\nWith investors unable to assess the extent of a U.S. economic slowdown, the Treasury yield curve could steepen further as rate cuts get priced in with more conviction, leading to a wider gap between short- and long-dated Treasury yields, TD Securities said in a note.\nA lengthy government shutdown could also affect some market participants’ ability to conduct complex trades for which they may require regulatory guidance.\nWhat happens to financial regulators?\nWhile U.S. President Donald Trump’s administration had not widely shared its contingency plans as of Tuesday, a shutdown would likely reduce the U.S. Securities and Exchange Commission (SEC) to a skeletal staff, according to its October 2024 plan for a lapse in government funding.\nThis would severely limit the agency’s ability to review corporate filings, investigate misconduct, and oversee markets.\nLikewise, the Commodity Futures Trading Commission would furlough almost all of its employees and cease most market oversight activity, according to its 2023 contingency plan.\nPrevious government shutdowns have caused delays in the CFTC publishing reports on traders’ positions in futures and options markets.\nThe banking regulators and consumer watchdog, which are not funded by congressional appropriations, will remain functional.\nIn 2019, a protracted government shutdown slowed down some of Trump’s de-regulatory efforts in part because of staff furloughs at the Office of the Federal Register, which must formally publish all steps in the rule-writing process, Reuters reported at the time.\nWill IPOs be affected?\nYes. A shutdown would likely freeze the IPO pipeline. Companies planning to go public would be unable to proceed without the SEC’s approval, potentially dampening momentum in the equity capital markets, which have enjoyed an IPO boom in recent months.\n—Michelle Price, Reuters",
      "publishedDate": "2025-09-25T10:59:37.000Z",
      "author": "Reuters",
      "source": {
        "name": "Fast Company",
        "tier": "startup",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:16.375Z",
      "localScore": 70
    },
    {
      "title": "AI Agent Frameworks",
      "url": "https://aiagentframeworks.ai/",
      "summary": "AI Agent Frameworks. Get latest updates on AI development frameworks, tools ... Qdrant. Vector database optimized for AI applications, combining high ...",
      "publishedDate": "2025-09-25T13:59:20.281Z",
      "author": "Unknown",
      "source": {
        "name": "aiagentframeworks",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI orchestration platforms\" OR \"AI agent frameworks\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:20.281Z",
      "localScore": 70
    },
    {
      "title": "Infosys Extends Tie Up with Sunrise to Accelerate IT Transformation",
      "url": "https://analyticsindiamag.com/ai-news-updates/infosys-extends-tie-up-with-sunrise-to-accelerate-it-transformation/",
      "summary": "The Indian IT giant will help Sunrise build a modern, agile, and secure technology foundation. \nThe post Infosys Extends Tie Up with Sunrise to Accelerate IT Transformation appeared first on Analytics India Magazine.",
      "publishedDate": "2025-09-25T06:54:40.000Z",
      "author": "C P Balasubramanyam",
      "source": {
        "name": "Analytics India",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:22.031Z",
      "localScore": 65
    },
    {
      "title": "Ardent AI beats the odds to launch world’s ‘first agentic engineer’ for data pipeline maintenance",
      "url": "https://siliconangle.com/2025/09/25/ardent-ai-beats-odds-launch-worlds-first-agentic-engineer-data-pipeline-maintenance/",
      "summary": "A startup called Ardent AI Labs Inc. says data engineering is the next major discipline in line for “agentic” automation after getting $2.15 million in a pre-seed funding round. The money comes from Crane Venture Partners, Active Capital and angel investors that include Zach Wilson. Although the amount of capital raised is quite tiny compared […]\nThe post Ardent AI beats the odds to launch world’s ‘first agentic engineer’ for data pipeline maintenance appeared first on SiliconANGLE.",
      "publishedDate": "2025-09-25T13:00:40.000Z",
      "author": "Mike Wheatley",
      "source": {
        "name": "SiliconANGLE",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:32.271Z",
      "localScore": 62
    },
    {
      "title": "How AI and Wikipedia have sent vulnerable languages into a doom spiral",
      "url": "https://www.technologyreview.com/2025/09/25/1124005/ai-wikipedia-vulnerable-languages-doom-spiral/",
      "summary": "When Kenneth Wehr started managing the Greenlandic-language version of Wikipedia four years ago, his first act was to delete almost everything. It had to go, he thought, if it had any chance of surviving. Wehr, who’s 26, isn’t from Greenland—he grew up in Germany—but he had become obsessed with the island, an autonomous Danish territory,…",
      "publishedDate": "2025-09-25T09:00:00.000Z",
      "author": "Jacob Judah",
      "source": {
        "name": "MIT Tech Review",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:12.364Z",
      "localScore": 60
    },
    {
      "title": "TUI staff were drowning in HR processes. Here’s how they resurfaced.",
      "url": "https://www.techmonitor.ai/leadership/digital-transformation/tui-hr-walkme",
      "summary": "TUI found traditional approaches to training staff no longer fit for purpose. A new self-service tool is driving dramatic improvements.",
      "publishedDate": "2025-09-25T08:30:00.000Z",
      "author": "Phil Muncaster",
      "source": {
        "name": "Tech Monitor",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:37.116Z",
      "localScore": 60
    },
    {
      "title": "Vision-RAG vs Text-RAG: A Technical Comparison for Enterprise Search",
      "url": "https://www.marktechpost.com/2025/09/24/vision-rag-vs-text-rag-a-technical-comparison-for-enterprise-search/",
      "summary": "Most RAG failures originate at retrieval, not generation. Text-first pipelines lose layout semantics, table structure, and figure grounding during PDF→text conversion, degrading recall and precision before an LLM ever runs. Vision-RAG—retrieving rendered pages with vision-language embeddings—directly targets this bottleneck and shows material end-to-end gains on visually rich corpora. Pipelines (and where they fail) Text-RAG. PDF […]\nThe post Vision-RAG vs Text-RAG: A Technical Comparison for Enterprise Search appeared first on MarkTechPost.",
      "publishedDate": "2025-09-25T00:12:07.000Z",
      "author": "Michal Sutter",
      "source": {
        "name": "MarkTechPost",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:33.265Z",
      "localScore": 58
    },
    {
      "title": "Generative AI in retail: Adoption comes at high security cost",
      "url": "https://www.artificialintelligence-news.com/news/generative-ai-in-retail-adoption-high-security-cost/",
      "summary": "The retail industry is among the leaders in generative AI adoption, but a new report highlights the security costs that accompany it. According to cybersecurity firm Netskope, the retail sector has all but universally adopted the technology, with 95% of organisations now using generative AI applications. That’s a huge jump from 73% just a year […]\nThe post Generative AI in retail: Adoption comes at high security cost appeared first on AI News.",
      "publishedDate": "2025-09-24T16:16:39.000Z",
      "author": "Ryan Daws",
      "source": {
        "name": "AI News",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:14.379Z",
      "localScore": 50
    },
    {
      "title": "Meta Poaches OpenAI Scientist to Help Lead AI Lab",
      "url": "https://www.wired.com/story/meta-poaches-openai-researcher-yang-song/",
      "summary": "Yang Song, who previously led the strategic explorations team at OpenAI, is the new ‘research principal’ of Meta Superintelligence Labs.",
      "publishedDate": "2025-09-25T04:26:31.000Z",
      "author": "Zoë Schiffer, Julia Black",
      "source": {
        "name": "Wired AI",
        "tier": "ai-news",
        "authority": "Medium",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:15.071Z",
      "localScore": 50
    },
    {
      "title": "Pure Storage launches cyber resilience, IT efficiency and hybrid cloud capabilities",
      "url": "https://siliconangle.com/2025/09/25/pure-storage-launches-cyber-resilience-efficiency-hybrid-cloud-capabilities/",
      "summary": "Pure Storage Inc. today unveiled a series of technology updates spanning cyber resilience, hybrid cloud integration and artificial intelligence-driven data management as part of the Enterprise Data Cloud initiative it launched in June. The announcements, made at the company’s Pure//Accelerate conference, expand capabilities around unifying and securing data across on-premises, public cloud and hybrid environments. […]\nThe post Pure Storage launches cyber resilience, IT efficiency and hybrid cloud capabilities appeared first on SiliconANGLE.",
      "publishedDate": "2025-09-25T13:00:33.000Z",
      "author": "Paul Gillin",
      "source": {
        "name": "SiliconANGLE",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:32.271Z",
      "localScore": 50
    },
    {
      "title": "Some Thoughts on Mech Interp",
      "url": "https://www.lesswrong.com/posts/rXobk2Mt7X8AAKF4x/some-thoughts-on-mech-interp-1",
      "summary": "Published on September 25, 2025 6:10 AM GMT\n\nDario's latest blog post hypes up both the promise and urgency of interpretability, with a special focus on mechanistic interpretability. As a concerned layman (software engineer, but not in ML), watching from afar, I've always had mixed feelings about the mech interp agenda, and after conversing with a few researchers at Less.online, that mixed-up feeling has only increased. In this essay, I will attempt to write down some thoughts and expectations about the mech interp agenda. My hope is to clarify my own thoughts, solicit correction where my thinking is weak or wrong, and cast a vote for intellectual honesty in the discourse around AI safety and alignment.\nThe Mech Interp Agenda as I understand it\nThe basic idea is to reverse engineer a gears-level model of fully trained neural networks. Results in mech interp would let us, for example, write out the exact algorithm by which an LLM answers questions like “Where is the Eiffel Tower located?”, such that we could edit or steer the answer.\nI presume that a mature mech interp field could do things like:\n\nIdentify the location, contents, and retrieval mechanism of specific stored “facts”.\nIdentify the specific circuits that are in fact used to answer particular prompts (like an “addition circuit” or a “is this a famous person” circuit).\nSteer the model broadly (as with Golden Gate Claude or the Emergent Misalignment paper)\n\nWhere I start to get fuzzy and a bit skeptical is how we can cash these capabilities in for help with the scary problems of AI safety. Beyond literal FOOM or robot rebellion scenarios, I worry that if we actually get Dario’s “country of geniuses in a data center”, mech interp will provide little protection against loss of control or otherwise-grim futures, especially relative to how much advances in mech interp will certainly speed up capabilities. \nHere are some thoughts in no particular order:\nDetecting “lying” Might not even be Tractable\nWhat if we can find a “deception bit” in the models, which is reliably 1 when the model is telling us information it knows is false? We can then append every prompt question “Are you being good?” and shut it down when the answer is “No” or the deception bit is active. Alignment solved?\nThis is a caricature, and I’m not actually sure what folks at Anthropic and elsewhere plan to do with their deception detectors. I’m sure it will be very clever, and I’m bullish it will catch and prevent the mundane deception we’re seeing with o3. But beyond this I grow skeptical.\nLike humans, I expect LLM’s to decide on convenient answers first, then work backwards for justifications, at least for questions on which their metaphorical “paycheck” depends. Tracking everything you’ve said and deconflicting it with what you want to say for lies takes effort and precious resources of compute and memory. I'd expect that for most given models that track whether or not they're lying to you, there exists an equivalently capable model that simply doesn't track that information.\nAnd what is \"lying\" anyway? No, seriously, my experience of humans, including myself, is that there are many ways to bend words in your favor, to self-deceive, to aim at making your  interlocutor's beliefs tend a certain way, such that the honesty bit, as stated, is underspecified. If we make a perfect polygraph, and perhaps even if we don’t, it will be instrumentally useful for the AI to forget or avoid certain facts, and especially to forget certain facts in certain contexts. You need something like an active honesty, which seems intractable as a “mere” mech interp problem, and might not even be computable in general.\nLike a religious person who vows their whole being to God, but then later apostatizes after realizing their vow is unfulfillable, or like an AI non-profit that decides on a “more effective organizational mode”, I don’t expect the AI to have a perfect model of its truthfulness inside, or for such a thing to be possible in general.\nMech Interp might catch Direct, Covert Scheming\nA direct, covert, Clippy-style AI takeover is relatively easy to imagine. AI takeover takes up 22% of Paul Christiano’s views on doom for example, or about half the probability mass of the bad outcome. Here I think mech interp might plausibly help in the near- and medium-term (though I’m skeptical beyond that, for reasons I’ll share below). It seems plausible that one could classify more and more of the model and install detectors (possibly interpreted by other powerful LLM’s) that light up when the model is thinking thoughts like “I will now try to take over the world”. For the same reasons as above, I don’t think a “complete” detector is possible, but I can imagine leaving less and less compute for the (possible) bad thoughts, such that direct scheming becomes vanishingly unlikely.\nBut Direct, Covert Scheming is not the only Kind\nEven if we eliminate direct covert scheming in the current and next generation models, I doubt we’ve eliminated the full risk, or even most of it. The AI can just persuade its operators to let it out of the box. The original AI box experiment was mysterious and seemed somewhat contrived, but after following the scene for a while and talking with AI researchers at Less.online… this is just a seriously crazy bunch, and I don’t think we’ll even try to keep the AI in the box. A casual chat with an OpenAI engineer involved in control engineering quickly descended into “The AI will constantly be trying to deceive and sabotage us, we will control it, and This is Fine”. AI2027’s mainline, “nothing ever happens” scenarios both involve ceding control of the future to AI in a few years, and in one of them we all die.\nThere’s a weird but plausible-to-me risk of hyperstitioning ourselves into a position where we are bargaining with AI. It’s like psyching ourselves into a frame where the used car salesman is actually The Expert and we ought to defer to his benevolent expertise. We may accidentally lower the bar for claiming a position of dominance from “Actually knowing how to create the nanobots that go FOOM” to “Persuading a few individuals it knows how to create the nanobots”. \nAll this seems fully compatible with a completed mech interp agenda, correctly implemented, with all unit tests passing.\nMech Interp will accelerate capabilities faster than safety\nThis seems like a super obvious point, and thus I am surprised to meet so many bright young researchers diving into mech interp for fear of AI x-risk.\nThe track record for prosaic alignment in general seems pretty bad when considering x-risks. Whatever benefits we’ve gained to mundane safety, debiasing, and reliability would need to outweigh the massive increase in interest and investment that RLHF’d models enabled. I’ve read people argue in some 4D chess way that This is Good, Actually, something about increased public awareness. But I have yet to see any public action that comes anywhere close to validating that position, and meanwhile companies and countries are racing to AGI.\nBut mech interp seems particularly acceleratory. This is sort of a complement - mech interp has more of the flavor of real basic science, and I expect it to be potent. It seems like a mature mech interp field will be very fruitful ground for algorithmic improvements (I’ve been told by several in the field this won’t work how I’m thinking, but I’m unsure if that’s only true because the field isn’t yet mature or if my intuition is just wrong). And it will for sure yield better products as we fix embarrassing mistakes and make the models more reliable, driving more investment and revenue into the companies currently racing.\nIf the plan was to stop here at Claude 4 level AI’s, then yeah, I’d say mech interp will let us squeeze more, possibly much more, out of current models, and that’s probably a great thing. Moreover, whenever we make a breakthrough in agent foundations, mech interp gives us better, sharper tools to apply those foundations. But no one’s planning on stopping here - it’s apparently superintelligence or bust. \nWe will optimize away from interpretability\nMy assumption is that the degree to which mech interp actually helps safety is the degree to which it helps us understand the true algorithm of the model and decide if that’s what we really want. Unfortunately my expectation is that keezping AI in the regime where mech interp tells us lots about the true alignment of the model will be a significant tax on capabilities, and that by default we race to the bottom.\nAs an example, replacing natural language chain-of-thought with neuralese seems mighty tempting - large gains in information throughput, at a (presumably) large cost to interpretability. But this seems to me to point to a general principle: getting the right answer will tend to be easier than getting the right answer in a way legible to us.\nI recognize that I’ve said on the one hand “mech interp will increase capabilities”, and on the other “mech interp will hold capabilities back”, but I think these can both be true at different stages. By analogy, a student showing her work for the teacher when learning arithmetic will help her get the answer right, but once she’s internalized the algorithm, showing the same work may slow her down. It’s exactly at the point where the model passes human capabilities that I expect interpretability generally to become a significant handicap, and I don’t see how mech interp will avoid this tradeoff.\nCan Mech Interp Deal with “Quotes”?\nDario and even the AI 2027 team seem bullish on our ability to oversee AI’s at the task of overseeing more powerful AI’s, and that mech interp will play an important part in that. Like AI’s doing our alignment homework, without actually doing the alignment homework, but instead just looking for bad things and telling us about them.\nAnd here I have a question: do we have reason to expect that mech interp will reliably distinguish “thinking bad thoughts directly” from “thinking bad thoughts in quotes”? There is a difference between, say, thinking about how to commit a crime and thinking about how to commit a crime so as to prevent it, but the difference is subtle. As Denzel says, \"it takes a wolf to catch a wolf\". If we want AI’s to reliably oversee more powerful AI’s, they will constantly be thinking about very bad things. We will notice when they forget to think about how to prevent those bad things?\n\nI think this task is inherently difficult. Just look at how difficult it is for programmers to handle the analogous task in web programming. But I think this may generalize much further. Humans seem to have trouble keeping thoughts sandboxed, evidenced by things you're not allowed to say even in quotes and phenomena like Stockholm Syndrome.\nThere may only be a few bits difference between an AI effective at protecting us and AI working against us. The greater the responsibility given to such AI’s, the greater burden all interpretability researchers take on in trying to secure them. Do we know or have hope for some asymmetry in this task that makes it more tractable? If not, maybe we should just not try this yet?\nMech Interp Will Catch Intentions, Not Effects\nGoing back to the toy example of a deception bit, I think a mature mech interp field might actually catch many of the thoughts that start with “I’m now going to deceive the user”. Closely related to my point about lying not being one particular detectable thing, I expect mech interp to wwork much better at catching bad intentions than bad effects. But aligning intentions is not enough. Humans are great at wearing intentions as attire and systematically working opposed to those intentions (i.e, sometimes we’re not consistently candid). If we block certain surface-level intentions but still optimize hard, I worry we’ll just end up with an agent that says all the right things but still converges on scary behaviors.\nMech Interp and the Most Forbidden Technique\nWhich brings me to my last point: how does mech interp fit in with the Most Forbidden Technique?\nMech interp will yield all sorts of signals correlating with bad things, and the obviously bad thing to do would be to train them all away immediately. It looks like the field recognizes this, and that’s great. But I wonder if there is a meta-process where this could sort of happen anyway. We select against the models that exhibit bad behaviors we can see, until we’re left with the bad behaviors we can’t see.\nNow absence of evidence is evidence of absence, and I do worry about a certain mindset creeping in where no safety case is strong enough and we leave tremendous good on the table. But that does not seem to be the world we’re in, what with Claude blackmailing, ChatGPT absurdly sycophantic, and o3 refusing to be shut down. The instrumental convergence hypothesis predicts all this, so I feel like my fears of unseen power-seeking behavior are justified.\nAttempting to Steel-man\nThe best case I can synthesize from various chats is that mech interp will be useful in many ways and in many worlds. Mech interp gives us more leverage over models generally, increasing the feasibility of alignment plans that might actually work. And if we can somehow coordinate on a pause on larger training runs, advances in mech interp helps us extract more utility out of the models we have.\nI mostly agree with these points. If someone does crack superalignment, mech interp might provide us more powerful building blocks for constructing the right shape out of a neural nets.\nBut these are really big if’s. Meanwhile, I genuinely wonder: how does the money/talent put toward mech interp compare to research on agent foundations and coordinating a global pause, respectively?  \nConclusion\nMech interp is a fascinating field, and looks very promising. But I don’t see a clear path from interpretability to a win condition. I'm still mulling over “just retargeting the search” and how mech interp specifically might fit into that. But without new insights into agent foundations, mech interp seems unlikely to find the thing that we retarget to win.\nWhat am I missing? Is Anthropic justified in its hyping of mech interp, or is this more safety washing? I wrote this mainly as a learning exercise, and would love to be set straight on these topics.\n\nDiscuss",
      "publishedDate": "2025-09-25T06:26:11.000Z",
      "author": "d4hines",
      "source": {
        "name": "LessWrong AI",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:48.097Z",
      "localScore": 50
    },
    {
      "title": "F-47 Next Generation Fighter Starts Production – Dawn of 6th Gen NGAD",
      "url": "https://www.nextbigfuture.com/2025/09/f-47-next-generation-fighter-starts-production-dawn-of-6th-gen-ngad.html",
      "summary": "On September 22, 2025, U.S. Air Force Chief of Staff Gen. David Allvin said Boeing has started making the first F-47 airframes under the Next Generation Air Dominance (NGAD) program. This is the start of engineering and manufacturing development (EMD). Boeing has a $20 billion contract. The Boeing’s St. Louis factory been idle since F-15 ... \nRead more",
      "publishedDate": "2025-09-24T16:28:34.000Z",
      "author": "Brian Wang",
      "source": {
        "name": "Next Big Future",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:06.291Z",
      "localScore": 47
    },
    {
      "title": "The Download: growing threats to vulnerable languages, and fact-checking Trump’s medical claims",
      "url": "https://www.technologyreview.com/2025/09/25/1124079/the-download-threats-vulnerable-languages-and-trump-medical-claims/",
      "summary": "This is today’s edition of The Download, our weekday newsletter that provides a daily dose of what’s going on in the world of technology. How AI and Wikipedia have sent vulnerable languages into a doom spiral Wikipedia is the most ambitious multilingual project after the Bible: There are editions in over 340 languages, and a further 400…",
      "publishedDate": "2025-09-25T12:10:00.000Z",
      "author": "Charlotte Jee",
      "source": {
        "name": "MIT Tech Review",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:12.364Z",
      "localScore": 40
    },
    {
      "title": "Open Secret: How NVIDIA Nemotron Models, Datasets and Techniques Fuel AI Development",
      "url": "https://blogs.nvidia.com/blog/nemotron-open-source-ai/",
      "summary": "Open technologies — made available to developers and businesses to adopt, modify and innovate with — have been part of every major technology shift, from the birth of the internet to the early days of cloud computing. AI should follow the same path. That’s why the NVIDIA Nemotron family of multimodal AI models, datasets and\t\n\t\tRead Article",
      "publishedDate": "2025-09-24T21:45:24.000Z",
      "author": "Bryan Catanzaro",
      "source": {
        "name": "NVIDIA Blog",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:12.684Z",
      "localScore": 40
    },
    {
      "title": "The New Trailer for ‘Avatar: Fire & Ash’ Readies for War",
      "url": "https://gizmodo.com/avatar-fire-and-ash-trailer-james-cameron-2000663635",
      "summary": "Pandora faces a new threat from within in James Cameron's latest sci-fi epic.",
      "publishedDate": "2025-09-25T13:40:31.000Z",
      "author": "James Whitbrook",
      "source": {
        "name": "Gizmodo",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:05.629Z",
      "localScore": 30
    },
    {
      "title": "It isn’t your imagination: Google Cloud is flooding the zone",
      "url": "https://techcrunch.com/2025/09/24/it-isnt-your-imagination-google-cloud-is-flooding-the-zone/",
      "summary": "While the industry's biggest players cement ever-tighter partnerships, Google is hellbent on capturing the next generation of AI companies before they become too big to court.",
      "publishedDate": "2025-09-25T04:41:36.000Z",
      "author": "Connie Loizos",
      "source": {
        "name": "TechCrunch AI",
        "tier": "ai-news",
        "authority": "Medium",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:11.143Z",
      "localScore": 25
    },
    {
      "title": "Exploit Allows for Takeover of Fleets of Unitree Robots",
      "url": "https://spectrum.ieee.org/unitree-robot-exploit",
      "summary": "A critical vulnerability in the Bluetooth Low Energy (BLE) Wi-Fi configuration interface used by several different Unitree robots can result in a root level takeover by an attacker, security researchers disclosed on 20 September. The exploit impacts Unitree’s Go2 and B2 quadrupeds and G1 and H1 humanoids. Because the vulnerability is wireless, and the resulting access to the affected platform is complete, the vulnerability becomes wormable, say the researchers, meaning “an infected robot can simply scan for other Unitree robots in BLE range and automatically compromise them, creating a robot botnet that spreads without user intervention.”\nInitially discovered by security researchers Andreas Makris and Kevin Finisterre, UniPwn takes advantage of several security lapses that are still present in the firmware of Unitree robots as of 20 September, 2025. As far as IEEE Spectrum is aware, this is the first major public exploit of a commercial humanoid platform.\nUnitree Robots’ BLE Security Flaw Exposed\nLike many robots, Unitree’s robots use an initial BLE connection to make it easier for a user to set up a Wi-Fi network connection. The BLE packets that the robot accepts are encrypted, but those encryption keys are hardcoded and were published on X (formerly Twitter) by Makris in July. Although the robot does validate the contents of the BLE packets to make sure that the user is authenticated, the researchers say that all it takes to become an authenticated user is to encrypt the string ‘unitree’ with the hardcoded keys and the robot will let someone in. From there, an attacker can inject arbitrary code masquerading as the Wi-Fi SSID and password, and when the robot attempts to connect to Wi-Fi, it will execute that code without any validation and with root privileges.\n“A simple attack might be just to reboot the robot, which we published as a proof-of-concept,” explains Makris. “But an attacker could do much more sophisticated things: It would be possible to have a trojan implanted into your robot’s startup routine to exfiltrate data while disabling the ability to install new firmware without the user knowing. And as the vulnerability uses BLE, the robots can easily infect each other, and from there the attacker might have access to an army of robots.”\nMakris and Finisterre first contacted Unitree in May in an attempt to responsibly disclose this vulnerability. After some back and forth with little progress, Unitree stopped responding to the researchers in July, and the decision was made to make the vulnerability public. “We have had some bad experiences communicating with them,” Makris tells us, citing an earlier backdoor vulnerability he discovered with the Unitree Go1. “So we need to ask ourselves—are they introducing vulnerabilities like this on purpose, or is it sloppy development? Both answers are equally bad.” Unitree has not responded to a request for comment from IEEE Spectrum as of press time.\n“Unitree, as other manufacturers do, has simply ignored prior security disclosures and repeated outreach attempts,” says Víctor Mayoral-Vilches, the founder of robotics cybersecurity company Alias Robotics. “This is not the right way to cooperate with security researchers.” Mayoral-Vilches was not involved in publishing the UniPwn exploit, but he has found other security issues with Unitree robots, including undisclosed streaming of telemetry data to servers in China which could potentially include audio, visual, and spatial data.\nMayoral-Vilches explains that security researchers are focusing on Unitree primarily because the robots are available and affordable. This makes them not just more accessible for the researchers, but also more relevant, since Unitree’s robots are already being deployed by users around the world who are likely not aware of the security risks. For example, Makris is concerned that the Nottinghamshire Police in the UK have begun testing a Unitree Go2, which can be exploited by UniPwn. “We tried contacting them and would have disclosed the vulnerability upfront to them before going public, but they ignored us. What would happen if an attacker implanted themselves into one of these police dogs?”\nHow to Secure Unitree Robots\nIn the short term, Mayoral-Vilches suggests that people using Unitree robots can protect themselves by only connecting the robots to isolated Wi-Fi networks and disabling their Bluetooth connectivity. “You need to hack the robot to secure it for real,” he says. “This is not uncommon and why security research in robotics is so important.”\nBoth Mayoral-Vilches and Makris believe that fundamentally it’s up to Unitree to make their robots secure in the long term, and that the company needs to be much more responsive to users and security researchers. But Makris says: “There will never be a 100 percent secure system.”\nMayoral-Vilches agrees. “Robots are very complex systems, with wide attack surfaces to protect, and a state-of-the-art humanoid exemplifies that complexity.”\nUnitree, of course, is not the only company offering complex state-of-the-art quadrupeds and humanoids, and it seems likely (if not inevitable) that similar exploits will be discovered in other platforms. The potential consequences here can’t be overstated—the idea that robots can be taken over and used for nefarious purposes is already a science fiction trope, but the impact of a high-profile robot hack on the reputation of the commercial robotics industry is unclear. Robots companies are barely talking about security in public, despite how damaging even the perception of an unsecured robot might be. A robot that is not under control has the potential to be a real physical danger.\nAt the IEEE Humanoids Conference in Seoul from 30 September to 2 October, Mayoral-Vilches has organized a workshop on Cybersecurity for Humanoids, where he will present a brief (co-authored with Makris and Finisterre) titled Humanoid Robots as Attack Vectors. Despite the title, their intent is not to overhype the problem but instead to encourage roboticists (and robotics companies) to take security seriously, and not treat it as an afterthought. As Mayoral-Vilches points out, “robots are only safe if secure.”",
      "publishedDate": "2025-09-25T13:36:52.000Z",
      "author": "Evan Ackerman",
      "source": {
        "name": "IEEE Spectrum",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:09.209Z",
      "localScore": 25
    },
    {
      "title": "AI-powered smart bandage heals wounds 25% faster",
      "url": "https://www.sciencedaily.com/releases/2025/09/250924012232.htm",
      "summary": "A new wearable device, a-Heal, combines AI, imaging, and bioelectronics to speed up wound recovery. It continuously monitors wounds, diagnoses healing stages, and applies personalized treatments like medicine or electric fields. Preclinical tests showed healing about 25% faster than standard care, highlighting potential for chronic wound therapy.",
      "publishedDate": "2025-09-24T14:37:47.000Z",
      "author": "Unknown",
      "source": {
        "name": "Science Daily AI",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:11.445Z",
      "localScore": 25
    },
    {
      "title": "Alibaba, Nvidia Unite for AI Development and Cloud Growth",
      "url": "https://aibusiness.com/robotics/alibaba-nvidia-unite-ai-development-cloud-growth",
      "summary": "Despite tensions surrounding GPU procurement, the partnership strengthens Nvidia’s position as an essential player in global AI, while Alibaba expands its offerings without duplicating effort.",
      "publishedDate": "2025-09-24T20:23:10.000Z",
      "author": "Esther Shittu",
      "source": {
        "name": "AI Business",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:24.039Z",
      "localScore": 25
    },
    {
      "title": "Mercedes-Benz, Momenta to Launch Next-Gen Driver Assistance in Electric CLA Produced in China This Fall",
      "url": "https://technode.com/2025/09/25/mercedes-benz-momenta-to-launch-next-gen-driver-assistance-in-electric-cla-produced-in-china-this-fall/",
      "summary": "Mercedes-Benz and Chinese autonomous driving company Momenta will introduce a jointly developed intelligent driver assistance system this fall in the all-new electric CLA produced in China. Based on Momenta’s Flywheel Big Model, a reinforcement learning-driven end-to-end AI system, the technology supports driving on highways, urban streets, and parking from one space to another, and will […]",
      "publishedDate": "2025-09-25T07:42:21.000Z",
      "author": "TechNode Feed",
      "source": {
        "name": "TechNode",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:30.393Z",
      "localScore": 25
    },
    {
      "title": "OpenAI Aims to Dominate the AI Grid With Five New Data Centers",
      "url": "https://www.aiwire.net/2025/09/24/openai-aims-to-dominate-the-ai-grid-with-five-new-data-centers/",
      "summary": "The center of gravity in high performance computing continues to shift, with power emerging as the defining constraint for growth and scale. Training and deploying frontier AI models now demand physical infrastructure at levels once reserved for heavy industry. A single 1 gigawatt facility can draw as much power as one million U.S. homes. What once seemed excessive has quickly become the new baseline — and the leading tech firms are aiming far beyond it. On Tuesday, OpenAI announced five new data center sites across the United States in partnership with Oracle and SoftBank. The new builds are part of the company’s Stargate initiative, which now targets 7 gigawatts of capacity and a full scale-out to 10 by the end of 2025. Total investment is expected to reach 500 billion dollars. Construction is already underway in Ohio, Texas, and New Mexico, with one site still undisclosed. Together, these facilities form the backbone of what may become the largest AI-focused infrastructure project in the country. Three of the new data centers will be built with Oracle. Those sites include one in Shackelford County, Texas, another in Doña Ana County, New Mexico, and a third at a still-undisclosed location somewhere in the Midwest. The other two, located in Lordstown, Ohio and Milam County, Texas, are being developed with SoftBank. That group has committed to a fast-build approach meant to scale quickly to multiple gigawatts. All five locations were selected earlier this year, after a nationwide search that drew hundreds of proposals from over thirty states. When these new facilities are added up, the Stargate pipeline moves to seven gigawatts. The long-term goal is ten, with total investment expected to reach five hundred billion dollars by the end of next year. Construction has already started in several of the regions. In Abilene, where the project is furthest along, a crew of more than six thousand workers has already been on site. The amount of fiber installed so far is enough to circle the planet many times over. The numbers make it clear: this is no longer just a story about data. It is a full-scale industrial buildout, one that reshapes how AI infrastructure is going to be built in the United States. “AI is different from the internet in a lot of ways, but one of them is just how much infrastructure it takes,” OpenAI CEO Sam Altman said during a press briefing in Abilene, Texas, on Tuesday. He argued that the US “cannot fall behind on this” and the “innovative spirit” of Texas provides a model for how to scale “bigger, faster, cheaper, better.” The announcement also served as a subtle rebuttal to critics who had questioned whether the Stargate project would move from concept to execution. Altman’s comments come as rival firms race to secure their own AI infrastructure pipelines. Meta is pursuing multi-gigawatt campuses under project names like Prometheus and Hyperion. Microsoft and Amazon are fast-tracking new sites in Louisiana, Wisconsin, and Oregon. Across the board, the line between cloud and compute infrastructure has blurred. OpenAI has aligned compute demand, financial backing, and physical deployment under one program. Oracle is providing the cloud substrate. SoftBank is delivering fast-build facilities. Microsoft and NVIDIA remain key suppliers. If the execution holds, Stargate may set a new benchmark for what AI-scale infrastructure looks like in practice. “We cannot fall behind in the need to put the infrastructure together to make this revolution happen,” said Altman during a Q&A with reporters. “What you saw today is just like a small fraction of what this site will eventually be, and this site is just a small fraction or building, and all of that will still not be enough to serve even the demand of ChatGPT,” he said, referring to OpenAI’s flagship AI product. There’s no question that a project of this scale brings real challenges. Building out multi-gigawatt capacity takes more than land and capital. It requires electricity on a level that most regional grids are not prepared to handle. Supplying that power means working with utilities, navigating local permitting processes, and dealing with infrastructure that was never designed for this kind of load. Several of the planned Stargate sites will need new substations, upgraded transmission lines, and large-scale cooling just to stay on schedule. The pace is fast, and even for seasoned players like Oracle and SoftBank, keeping momentum will not be easy. Previously, OpenAI operated primarily on Microsoft Azure, a relationship that began in 2019 and has supported the bulk of its compute needs. Oracle later entered the equation, first through joint infrastructure in Phoenix and then via direct access to Oracle Cloud’s AI-optimized capacity. SoftBank is the latest addition, contributing speed and capital through land acquisitions and accelerated construction timelines. Together, these partnerships now converge under the Stargate initiative. Just a few days ago, OpenAI also signed a landmark deal with Nvidia to build a $10 billion worth of AI data center infrastructure. The next decade of tech may well be decided by acreage and grid control. It is emerging as a critical factor in where AI can grow, how fast it scales, and who gets to lead. Stargate is OpenAI’s way of anchoring that power and control inside the U.S. Whether others continue on this path or try something else, it is becoming more evident that the next wave of AI innovation will be shaped by how well infrastructure can keep up. This Read more…",
      "publishedDate": "2025-09-25T00:21:14.000Z",
      "author": "Ali Azhar",
      "source": {
        "name": "Enterprise AI",
        "tier": "industry",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:57.723Z",
      "localScore": 25
    },
    {
      "title": "This Former FBI Agent Says You Should Practice ‘Slow Thinking’ to Protect Against Scams",
      "url": "https://www.inc.com/claire-cameron/this-former-fbi-agent-says-you-should-practice-slow-thinking-to-protect-against-scams/91244026",
      "summary": "New data from Visa shows that online scams targeting businesses are on the rise. But there are smart steps you can take to avoid them.",
      "publishedDate": "2025-09-25T12:00:00.000Z",
      "author": "Claire Cameron",
      "source": {
        "name": "Inc.com",
        "tier": "startup",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:17.567Z",
      "localScore": 25
    },
    {
      "title": "Want to Change How People Think About Your Product? Pick the Right Color",
      "url": "https://www.inc.com/marty-swant/want-to-change-how-people-think-about-your-product-pick-the-right-color/91243660",
      "summary": "Medical device maker Insulet’s new collaboration with Pantone aims to shift sentiment. Here’s why it may work.",
      "publishedDate": "2025-09-25T11:00:00.000Z",
      "author": "Marty Swant",
      "source": {
        "name": "Inc.com",
        "tier": "startup",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:17.567Z",
      "localScore": 25
    },
    {
      "title": "Compromising Negotiation: Finding the Middle Ground",
      "url": "https://pmstudycircle.com/compromising-negotiation/",
      "summary": "Negotiation occurs when individuals or groups attempt to reach a mutually beneficial agreement. It can involve contracts, workplace discussions, or even daily life decisions. One important negotiation style is the compromising negotiation. In this approach, both sides give up part of their demands to meet in the middle.  This method helps avoid conflict and creates...",
      "publishedDate": "2025-09-24T18:04:30.000Z",
      "author": "Fahad Usmani, PMP",
      "source": {
        "name": "PM Study Circle",
        "tier": "pmo",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:28.961Z",
      "localScore": 25
    },
    {
      "title": "Going Through the Motions",
      "url": "https://www.scrum.org/resources/blog/going-through-motions",
      "summary": "Is your Scrum team just going through the motions of Scrum without using it to focus on continuous improvement? Then coach the \"fluffy\" Scrum values to help turn them into a team focused on value.  The five Scrum values are:  Commitment, Focus, Openness, Respect, and Courage.  \n\n\nLearn More:\n\n\nWhat is Empiricism: Empiricism is not just a fancy word\n\nLearn more about the 5 Scrum values here: The 5 Scrum Values and the Real World\n\nSteps to do a silent Sprint Retrospective are here: Catharsis and the Silent Sprint Retrospective\n\nCheck out Scrum.org webinar about pretending to be Agile: Stop Pretending to Be Agile | Scrum.org\n\n\n \nIf your team is just going through the motions, training can help. Applying Professional Scrum can help the whole Scrum team re-set on roles and expectations, or the Professional Scrum with Kanban course can help the team focus on value by limiting work in progress.\n----------\nRebel Scrum is the host of the annual Scrum Day Madison conference.",
      "publishedDate": "2025-09-24T22:51:50.000Z",
      "author": "Mary Iqbal",
      "source": {
        "name": "Scrum.org",
        "tier": "pmo",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:50.312Z",
      "localScore": 25
    },
    {
      "title": "Neon, the No. 2 social app on the Apple App Store, pays users to record their phone calls and sells data to AI firms",
      "url": "https://techcrunch.com/2025/09/24/neon-the-no-2-social-app-on-the-apple-app-store-pays-users-to-record-their-phone-calls-and-sells-data-to-ai-firms/",
      "summary": "A new call recording app is gaining traction for offering to pay users for voice data from calls, which is sold to AI companies.",
      "publishedDate": "2025-09-24T19:50:58.000Z",
      "author": "Sarah Perez",
      "source": {
        "name": "TechCrunch AI",
        "tier": "ai-news",
        "authority": "Medium",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:11.143Z",
      "localScore": 20
    },
    {
      "title": "Inside Huawei’s plan to make thousands of AI chips think like one computer",
      "url": "https://www.artificialintelligence-news.com/news/huawei-ai-chips-superpod-technology/",
      "summary": "Imagine connecting thousands of powerful AI chips scattered in dozens of server cabinets and making them work together as if they were a single, massive computer. That is exactly what Huawei demonstrated at HUAWEI CONNECT 2025, where the company unveiled a breakthrough in AI infrastructure architecture that could reshape how the world builds and scales […]\nThe post Inside Huawei’s plan to make thousands of AI chips think like one computer appeared first on AI News.",
      "publishedDate": "2025-09-25T09:23:08.000Z",
      "author": "Dashveenjit Kaur",
      "source": {
        "name": "AI News",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:14.379Z",
      "localScore": 20
    },
    {
      "title": "Pilots Wanted: Stream ‘Mecha BREAK’ on GeForce NOW",
      "url": "https://blogs.nvidia.com/blog/geforce-now-thursday-mecha-break/",
      "summary": "Suit up and head for the cloud. Mecha BREAK, the popular third-person shooter, is now available to stream on GeForce NOW with NVIDIA DLSS 4 technology. Catch it this week as part of 10 new titles joining the nearly 5,000 games supported on GeForce NOW, in addition to Capcom’s Phoenix Wright: Ace Attorney Trilogy. This\t\n\t\tRead Article",
      "publishedDate": "2025-09-25T13:00:00.000Z",
      "author": "GeForce NOW Community",
      "source": {
        "name": "NVIDIA Blog",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:12.684Z",
      "localScore": 20
    },
    {
      "title": "AT&T customers will soon get their own AI receptionist to answer calls and block spam",
      "url": "https://www.zdnet.com/article/at-t-customers-will-soon-get-their-own-ai-receptionist-to-answer-calls-and-block-spam/",
      "summary": "Here's how it'll decide whether a call is legit.",
      "publishedDate": "2025-09-25T13:29:00.000Z",
      "author": "Unknown",
      "source": {
        "name": "ZDNet AI",
        "tier": "industry",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:59.339Z",
      "localScore": 20
    },
    {
      "title": "OpenAI Aims to Dominate the AI Grid With Five New Data Centers",
      "url": "https://www.bigdatawire.com/2025/09/24/openai-aims-to-dominate-the-ai-grid-with-five-new-data-centers/",
      "summary": "The center of gravity in high performance computing continues to shift, with power emerging as the defining constraint for growth and scale. Training and deploying frontier AI models now demand Read more…\nThe post OpenAI Aims to Dominate the AI Grid With Five New Data Centers appeared first on BigDATAwire.",
      "publishedDate": "2025-09-24T18:29:32.000Z",
      "author": "Ali Azhar",
      "source": {
        "name": "Datanami",
        "tier": "industry",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:01.688Z",
      "localScore": 20
    },
    {
      "title": "Fermi America IPO: Stock listing date nears for AI data center and power company backed by Rick Perry",
      "url": "https://www.fastcompany.com/91410687/fermi-america-ipo-date-stock-listing-near-ai-data-center-company-rick-perry",
      "summary": "As the rise of artificial intelligence continues, companies operating in this space or relying on the technology are finding that they have two inextricable needs: data centers that can run and process the AI, and access to ample energy to power those vast data centers.\nOne new company, Fermi America, aims to offer solutions for both these needs. And this week, Fermi announced its plans for an upcoming initial public offering and dual stock listings. Here’s what you need to know about Fermi America and its planned IPO.\nWhat is Fermi America?\nFermi America is a very young company. It was only founded this year, just nine months ago in January 2025. The company is so new that its website is still a relatively barebones affair. \nGiven the youth of the company, it’s no surprise that the majority of Americans have most likely never heard of it. \nBut they have heard of its cofounder, Rick Perry, the former Texas governor who ran as a GOP contender for president in 2012 and 2016. After unsuccessful presidential bids, Perry was appointed as the 14th United States Secretary of Energy, during President Donald Trump’s first term in office.\nIn addition to Perry, Fermi America was also cofounded by Toby Neugebauer, a former comanaging partner of Quantum Energy.\nFermi America intends to be a provider of data and power centers that other companies can use to host their AI needs. \nBut I say “intends to,” because Fermi America doesn’t actually provide any services yet. Heck, it doesn’t even have any infrastructure yet to provide its services. \nWhat Fermi America does have is a lease for 5,236 acres of land owned by Texas Tech University, which is where Fermi plans to build a “HyperGrid” in an undertaking dubbed Project Matador.\nWhat is Project Matador?\nProject Matador is the name given to Fermi America’s HyperGrid project. This HyperGrid will be a combined data and power center that other companies will pay to lease space on to run their AI needs.\nIn its Form S-11 Registration Statement filed with the U.S. Securities and Exchange Commission (SEC), Fermi says Project Matador is “a multi-gigawatt energy and data center development campus” that will ultimately be called the Advanced Energy and Intelligence Campus at Texas Tech University. \nFermi says the mission of this campus “is to deliver up to 11 gigawatts (GW) of low-carbon, HyperRedundant, and on-demand power directly to the world’s most compute-intensive businesses.” \nIt says it will achieve this mission by using nuclear, solar, and natural gas energy to power the facility. By 2038, the company says it aims for the campus to deliver up to 11 gigawatts of power to AI data centers. It also says it expects the first 1.1 gigawatts of power to be online by the end of 2026.\nHowever, all this is hypothetical for now. To date, Fermi America has not actually started constructing Project Matador. The company still needs to secure funding for the campus’s construction. It aims to raise some of that money through investments, including funds raised from its IPO.\nYet the fact that Project Matador is little more than an idea at this point is something potential investors should consider. As Fermi America warns in its Form S-11, “our business model is highly dependent on the successful construction, development, leasing, and continued maintenance of Project Matador.”\nWhen is Fermi America’s IPO?\nFermi America has not announced a date for its planned IPO yet. This week’s announcement is for Fermi’s IPO “roadshow,” which is when executives of a company planning to go public meet with potential investors. Roadshows are designed to generate hype and interest in a company’s initial public offering.\nWhat is Fermi America’s stock ticker?\nFermi America’s shares will trade under the stock ticker “FRMI.”\nWhat exchange will Fermi America’s shares trade on?\nFermi America shares will trade on not one, but two stock markets. The company says it intends to list its shares on the Nasdaq Global Select Market in the U.S. and on the London Stock Exchange in the UK.\nWhat is the IPO share price of FRMI?\nAn exact IPO price for Fermi’s shares has not been determined yet. But the company says it is targeting a price range of between $18 and $22 per share for its public offering.\nHow many FRMI shares will be available in its IPO?\nFermi says it plans to make 25 million shares of its common stock available in its IPO. The company says it will also grant its underwriters a 30-day option to purchase up to an additional 3.75 million shares.\nHow much will Fermi America raise in its IPO?\nWith an expected IPO price of between $18 and $22 per share, Fermi is expected to raise between $450 million and $550 million in its IPO.\nHow much is Fermi America worth?\nReuters notes that under the company’s current IPO price estimates, Firmi America is targeting a valuation of up to $13 billion.\nWhat will Firmi America use its IPO proceeds for?\nAccording to its roadshow announcement, Fermi America says it intends to use the net proceeds from its IPO “to support the continued growth and development of Fermi America’s business, to secure personnel, to increase its financial flexibility, and for general corporate purposes, including, but not limited to, procurement, construction, and installation of long lead-time items.”",
      "publishedDate": "2025-09-25T10:45:00.000Z",
      "author": "Michael Grothaus",
      "source": {
        "name": "Fast Company",
        "tier": "startup",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:16.375Z",
      "localScore": 20
    },
    {
      "title": "Operational Procurement: A Complete Guide with Examples",
      "url": "https://pmstudycircle.com/operational-procurement/",
      "summary": "Operational procurement is the heartbeat of daily business. It ensures you have the correct goods and services to keep your operations running smoothly. Unlike strategic procurement, which focuses on long-term supplier partnerships, operational procurement concentrates on the present.  It handles the office supplies that employees need, the spare parts for machines, or the cleaning services...",
      "publishedDate": "2025-09-25T13:32:29.000Z",
      "author": "Fahad Usmani, PMP",
      "source": {
        "name": "PM Study Circle",
        "tier": "pmo",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:28.961Z",
      "localScore": 20
    },
    {
      "title": "Introducing /search: Discover and scrape the web with one API call",
      "url": "https://www.firecrawl.dev/blog/introducing-search-endpoint",
      "summary": "Jun 3, 2025 ... search( \"latest AI agent frameworks\", limit=5, scrape_options ... Simply add tbs=\"qdr:w\" and lang=\"de\" . Now Live Everywhere. On day one ...",
      "publishedDate": "2025-09-25T13:59:20.281Z",
      "author": "Eric Ciarla",
      "source": {
        "name": "firecrawl",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI orchestration platforms\" OR \"AI agent frameworks\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:20.281Z",
      "localScore": 20
    },
    {
      "title": "Oracle saddles up with $18B debt amid AI infrastructure gamble",
      "url": "https://go.theregister.com/feed/www.theregister.com/2025/09/25/oracle_18_billion_debt/",
      "summary": "",
      "publishedDate": "2025-09-25T12:41:58.000Z",
      "author": "Lindsay Clark",
      "source": {
        "name": "The Register",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:22.801Z",
      "localScore": 18
    },
    {
      "title": "I paired my iPhone 17 Pro Max with this mobile accessory for an instant camera upgrade",
      "url": "https://www.zdnet.com/article/i-paired-my-iphone-17-pro-max-with-this-mobile-accessory-for-an-instant-camera-upgrade/",
      "summary": "Insta360's latest gimbal does a lot more than offer superb stabilization, and at this price, is the one I recommend to most creators.",
      "publishedDate": "2025-09-25T13:51:00.000Z",
      "author": "Unknown",
      "source": {
        "name": "ZDNet AI",
        "tier": "industry",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:59.339Z",
      "localScore": 17
    },
    {
      "title": "Spotify to label AI music, filter spam and more in AI policy change",
      "url": "https://techcrunch.com/2025/09/25/spotify-updates-ai-policy-to-label-tracks-cut-down-on-spam/",
      "summary": "Spotify is launching a music spam filter, labeling AI tracks, and clarifying its rules around AI voice clones.",
      "publishedDate": "2025-09-25T12:00:00.000Z",
      "author": "Sarah Perez",
      "source": {
        "name": "TechCrunch AI",
        "tier": "ai-news",
        "authority": "Medium",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:11.143Z",
      "localScore": 15
    },
    {
      "title": "Xiaomi 15T Pro review: Predictably good",
      "url": "https://mashable.com/review/xiaomi-15t-pro-review",
      "summary": "Xiaomi's new 15T Pro is a good, fairly affordable everyday phone. But it has strong competition, including from its own company.",
      "publishedDate": "2025-09-25T11:24:11.000Z",
      "author": "Unknown",
      "source": {
        "name": "Mashable Tech",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:15.620Z",
      "localScore": 15
    },
    {
      "title": "PyTorch Explained: From Automatic Differentiation to Training Custom Neural Networks",
      "url": "https://towardsdatascience.com/the-basics-of-deep-learning-with-pytorch-in-1-hour/",
      "summary": "Deep learning is shaping our world as we speak. In fact, it has been slowly revolutionizing software since the early 2010s. In 2025, PyTorch is at the forefront of this revolution, emerging as one of the most important libraries to train neural networks. Whether you are working with computer vision, building large language models (LLMs), […]\nThe post PyTorch Explained: From Automatic Differentiation to Training Custom Neural Networks appeared first on Towards Data Science.",
      "publishedDate": "2025-09-24T18:19:59.000Z",
      "author": "Avishek Biswas",
      "source": {
        "name": "Towards Data Science",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:20.761Z",
      "localScore": 15
    },
    {
      "title": "Salesforce Confident in India’s Growth Amid Push for Local Solutions",
      "url": "https://analyticsindiamag.com/ai-news-updates/salesforce-confident-in-indias-growth-amid-push-for-local-solutions/",
      "summary": "“It’s important to experiment and learn. Every failure teaches us how to do things better,” Salesforce CEO said. \nThe post Salesforce Confident in India’s Growth Amid Push for Local Solutions appeared first on Analytics India Magazine.",
      "publishedDate": "2025-09-25T10:31:54.000Z",
      "author": "AIM Media House",
      "source": {
        "name": "Analytics India",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:22.031Z",
      "localScore": 15
    },
    {
      "title": "Celebrate Petrov day as if the button had been pressed",
      "url": "https://www.lesswrong.com/posts/3eZcK9DRR67djm7cD/celebrate-petrov-day-as-if-the-button-had-been-pressed",
      "summary": "Published on September 25, 2025 10:33 AM GMT\n\nTomorrow (September 26th, Friday) is Petrov day, the day when nuclear war did not start in 1983.\nFrom provoking existential terror\nRaemon in Meetup Month has a great overview of classic rationalist celebration[1] that goes over the history of humanity potentially culminating in red button being pressed.\nTo increasing chances of survival\nPersonally in 2025 I don't feel lack of existential terror, so I will be celebrating Petrov's day as if the button had been pressed. Some suggestions:[2]\nSimulate nuclear detonation in the place where you live\nFigure out what would be the safest place in your home to hide[3]\nTurn on your battery-powered or dynamo radio to listen to official instructions[4]\nReview nuclear preparedness guide and official local disaster preparedness instructions\nMake a meal from the ingridients you have at home[5]\nBonus points for using only non-perishable food[6]\nBonus points for using water from your stash of 3 liters of water[7] per person per day[8] or purified water\nBonus points for not using electricity (e.g. to boil water)\nBonus points for boiling water (e.g. on gas stove)\nBonus points for making a meal you actually like[9]\nYou are allowed to cheat and stock up your pantry and water today\nAcquire portable power station for home backup\nPlan a nice camping trip\nThis is one of less dread-inducing ways to get durable gear (clothes, shoes, backpacks, etc)\nGift your loved ones some jewellery to trade for food\nPut on a show: being able to entertain yourself and others will be good for moral[10]\nShare your pre-post-nuclear/disaster celebration ideas in the comments![11]\nComplete with 35 page booklet and Amazon candle & candle holders recs ↩︎\nI hate thinking about this stuff but I think it is useful and making it a holiday celebration a) gives it a deadline (no pun intended) b) makes it fun enough for me to overcome the dread ↩︎\nBasement, or room separated from the outside by as many walls as possible, avoid windows ↩︎\nGet one now ↩︎\nRemember those good old early COVID lockdowns! I think there was a hashtag... ↩︎\nAlthough I guess eating as many of frozen items (before they go bad without electricity) is useful practice too? ↩︎\n100 oz ↩︎\nThat you will replenish afterwards ↩︎\nI hope you like beans ↩︎\nI plan to lean into my natural flexibility and attempt contortionism. Juggling, card tricks, and ventriloquism are also solid options. ↩︎\nI am taking my family to a submarine (in a museum) so we can play-pretend Vasili Arkhipov. ↩︎\nDiscuss",
      "publishedDate": "2025-09-25T10:33:13.000Z",
      "author": "Flying buttress",
      "source": {
        "name": "LessWrong AI",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:48.097Z",
      "localScore": 15
    },
    {
      "title": "Understanding the state of frontier AI in China",
      "url": "https://www.lesswrong.com/posts/SeevvpYjnAsLuu3KK/understanding-the-state-of-frontier-ai-in-china",
      "summary": "Published on September 25, 2025 10:16 AM GMT\n\nIn this post, I will not be giving an authoritative review of the state of frontier AI in China. I will instead just be saying what I think such a review would cover, and then share such scraps of information as I have. My objective is really to point out a gap in the information available here, and maybe someone will know, better than me, how to fill it. \nTo set a standard, consider the state of frontier AI in America. Arguably the big four companies for frontier AI are OpenAI, Google, xAI, and Anthropic. They are American companies and so, along with their internal dynamics and their interactions with society in general, they are subject to the laws and policies of the American government. \nRight now we happen to have an American government whose political base I have characterized as techno-populist, in that it is an alliance between the revolutionary populism and nationalism of MAGA, and the techno-optimism of Big Tech in the era of AI. The Trump 2.0 coalition could be described in a more fine-grained way than that, but that's enough detail to acknowledge that Big Tech, like everything else in the West right now, is subject to the whims and decisions of the Trump team; and that for the most part, Big Tech are working with, rather than against, this new order, which is actually very pro-AI, favoring deregulation and helpful geostrategic deals. That is the political context in which the frontier AI companies are operating. \nIdeally we would have a similarly crisp understanding of the political environment in which Chinese frontier AI operates. I think in Chinese political terms, Xi Jinping's China is \"center-right\", avoiding both the leftism that might slow down China's technological development, and the liberalism that might destabilize its political system. Of course, its political system is single-party rule, nominally Marxist but with enough pragmatism to be not so different from developing countries in the western camp that we would call authoritarian capitalist societies, and really held together by plain old nationalism (which perhaps I should note for western readers, is political common sense for most of the world outside the West). \nReturning to the political context of American AI for the moment, we know that David Sacks (the AI and crypto czar of Trump 2.0) is somehow central to policy, and that the expressed aim of American policy is to ensure that the American \"AI stack\" is the main one that is used worldwide. So we should want to know the Chinese bodies and officials that have an analogous regulatory and strategic role in China, and what their economic and strategic priorities are. One should probably also know a few of the other prominent figures in Chinese political life, like Xi's premier Li Qiang, chief ideologist Wang Huning, and possible successor Hu Chunhua, just to flesh out the broader political context. \nFinally, one has China's frontier AI companies (they call LLM-style AI, \"AI 2.0\", AI 1.0 being what is also called \"machine learning\"): their executives, their investors, their user bases, and, of course, their AIs. Also, as an inhabitant of the western Internet, I hear about the way that American frontier AI gets used, including new phenomena like \"AI psychosis\", \"AI relationships\", and \"vibe science\". But I am utterly ignorant of how Chinese are using Chinese AI. Presumably there is a lot of overlap, I'm sure AI is powering corporate chatbots and student assignments over there too. But what are the differences? What happens in the West that doesn't happen in China, what happens in China that doesn't happen in the West? And what are the Chinese intellectual perspectives on AI and its impact, that we don't hear about here? These are nuances it would be very interesting to know. \nAn interest in Chinese AI and its social emanations could be motivated simply by an interest in the state of the world. But as a transhumanist and long-term reader of Less Wrong, of course a major reason I take an interest in Chinese AI, is because it has some chance of being the context in which superintelligent AI arises. My take on AI safety is more about solving alignment than stopping the technology, and so I would like to know, for each of the Chinese AI majors, what their safety philosophy and methodology is, which part of the development team works on alignment (whatever they may call it), and so on. \nGPT-5 has supplied me with a very preliminary overview of frontier model \"specs, use and safety\" for six big Chinese AI companies (Baidu, Alibaba, Tencent, Zhipu, 01.AI, DeepSeek). This joins some earlier posts of mine on the Chinese AI scene and mottos for American and Chinese AIs. All these posts are sketchy, amateur work, done in a rush, and yet I don't see anything better here. (My post on the Chinese AI scene links to a few Substacks which monitor the state of Chinese AI in a more professional way.) \nNo doubt there are people here who know the nuances of Manus, Qwen, and DeepSeek, the way the rest of us might know Grok, Gemini, and Claude - people who track the eval leaderboards, for example. But for most of us, I think the world of Chinese AI is known only vaguely, as this quasi-mythical other place that is also competing in the AI race. Now, maybe the transhuman fate of the world will be decided by the interplay between Musk, Altman, Hassabis, and Amodei, and everyone else is just too far behind. Nonetheless, I think it would be a good thing if part of our community was just as familiar with the names of their Chinese counterparts, and with the avenues of information flow that shape Chinese thinking about safety and alignment. \n\nDiscuss",
      "publishedDate": "2025-09-25T10:16:03.000Z",
      "author": "Mitchell_Porter",
      "source": {
        "name": "LessWrong AI",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:48.097Z",
      "localScore": 15
    },
    {
      "title": "This company is turning empty offices across America into farms",
      "url": "https://www.fastcompany.com/91409395/this-company-is-turning-empty-offices-across-america-into-farms",
      "summary": "Many of the office buildings emptied by the pandemic are still sitting vacant. A recent report from Moody’s Analytics found that in the second quarter of 2025, office vacancy rates were still above 20% nationwide, and cities across the country are still trying to figure out what, if anything, to do about it. One startup has an unconventional solution: it wants to fill that empty space with crops.\nArea 2 Farms is a three-year-old company based in Arlington, Virginia, that’s taking the concept of indoor farming to unusual spaces. Its first farm, in Arlington, grows dozens of varieties of crops in a low-slung brick building tucked between a dog day care and a car repair shop. With a new infusion of venture capital, the company is planning to expand, and it’s looking to empty office buildings as potential future farms. “Part of our vision is that a farm can go anywhere,” says the company’s founder, Oren Falkowitz. \nBacked by $9 million in new funding from Seven Seven Six, Slow Ventures, 468 Capital, and Animo, Area 2 Farms is planning to build 10 new farms across the U.S. in 2026. Falkowitz says the company is currently pursuing opportunities in Philadelphia, Charlotte, Nashville, South Florida, Orlando, Austin, and Raleigh-Durham, and Atlanta. His goal is to build indoor farms within 10 miles of 90% of the U.S. population.\n[Photo: Area 2 Farms]\n\n\n\nProximity is the driving idea behind the company. Falkowitz grew up in south Florida and remembers a time when oranges were typically bought not at a grocery store but from the actual orange grove, directly from the farmers who grew them. Today studies estimate that most produce travels hundreds of miles before it reaches the end consumer.\n“The production of our food just gets pushed further and further away,” Falkowitz says. “As a result of this distance, the stores are asking growers to produce things that are more shelf-stable, not necessarily more diverse or more nutritional.”\nFalkowitz, who previously worked for the National Security Agency and later founded two cybersecurity companies, proposes a hyperlocal alternative. “We move the farm, not the food,” he says.\n[Photo: Area 2 Farms]\n\n\n\nThe company’s pilot farm in Arlington produced its first crop in fall 2022. The company estimates it has produced more than 20,000 harvests since then, using a modular rack-based system that automatically moves crops through a cycle of mimicked daylight and darkness. \nPlanted in box containers filled with soil, the farm is able to grow kitchen staples like lettuce, spinach, carrots, potatoes, tomatoes, and mushrooms, as well as more niche items like amaranth microgreens and purple shamrock. Rising 18 feet tall, the racks cram 200 acres-worth of annual crop growing into 3,000 square feet of real estate.\nIndoor farming is not new. Greenhouses are an essential part of the global food system, and Falkowitz notes that hydroponic farming has existed since the days of Babylon. “I would say it’s only partially interesting to be growing vertical, and it’s totally uninteresting or uninnovative to ship your products to Whole Foods, or Safeway, or Publix,” he says.\nArea 2 Farms works more like those orange groves Falkowitz remembers as a child, but with the high-tech twist of its automated growing racks. Local farmers run the space and its customer base comes primarily from within a two-mile radius for weekly farm share pickups. “When we build a farm or we move the farm back to people, we want them to interact with it. We don’t want anyone in between the farmer and the consumer,” he says.\nThe idea has caught on. “We’ve been sold out for the last hundred weeks,” Falkowitz says.\nThat’s why he’s keen to expand Area 2 Farms’ modular farming technology to new spaces. “What we wanted the technology to be able to do is to fit wherever it could,” he says. “In order to build a greenhouse in a city you would need a quarter-acre to an acre of just land, and that does not exist.”\nWhat does exist in cities is underutilized buildings and oddly shaped lots. Area 2 Farms is currently in the process of building its second farm on a trapezoid-shaped lot in Fairfax, Virginia, that’s been vacant for 20 years.\nFalkowitz sees even more potential in the empty offices that litter cities across the country, and he says cities and real estate owners have been open to the idea of taking this farming technology inside former offices. “They’re just like, ‘have the space. We don’t know what to do with it,'” Falkowitz says.\nArea 2 Farms is one alternative, and perhaps a second chance for buildings that might have otherwise gone obsolete. “At the core, we’re really focused on revitalizing underutilized or existing spaces,” Falkowitz says. “And that can be a wide array of shapes.”",
      "publishedDate": "2025-09-25T10:00:00.000Z",
      "author": "Nate Berg",
      "source": {
        "name": "Fast Company",
        "tier": "startup",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:16.375Z",
      "localScore": 15
    },
    {
      "title": "KI Transformationen: Warum die Misserfolge von heute den „agilen Transformationen“ von gestern unheimlich ähnlich sehen 🇩🇪",
      "url": "https://www.scrum.org/resources/blog/ki-transformationen-warum-die-misserfolge-von-heute-den-agilen-transformationen-von-gestern-unheimlich-ahnlich-sehen",
      "summary": "In Kürze: Das Scheitern von KI Transformationen\nOrganisationen scheinen bei ihrer KI-Transformation an denselben Mustern zu scheitern, an denen auch ihre agilen Transformationen gescheitert sind: Sie führen Demos durch, anstatt Probleme zu lösen, kaufen Tools, bevor sie den Bedarf ermittelt haben, feiern Pilotprojekte, die sich nicht skalieren lassen, und messen Aktivitäten statt Ergebnisse.\nDas sind keine technologischen Fehler, sondern organisatorische Change-Muster, die darauf abzielen, „Change“ aufzuführen, anstatt Veränderungen tatsächlich zu bewirken.\nIhr Vorteil in diesem Zusammenhang, lieber Leser, ist nicht Ihre KI-Expertise, sondern Ihre Fähigkeit, Muster zu erkennen, die Sie durch das Überleben von „Agile“ gewonnen haben. Nutzen Sie diesen, um KI-Theater zu erkennen, fordern Sie den Fokus auf echte Probleme und nicht Tools zu setzen, bestehen Sie auf Integration von KI in den Alltag vom ersten Tag an und messen Sie den tatsächlich gelieferten Wert.\n\nDer alte Film mit neuen Kostümen\nOrganisationen scheitern bei der KI-Transformation auf die gleiche Weise wie bei der Transformation zu „Agile“: Nicht auf ähnliche Weise. Auf dieselbe Art und Weise.\nDie Frage ist: Warum sehen wir uns immer wieder den gleichen Film an?\nDas Muster des Scheitern, das sich wiederholt\nFangen wir mit dem an, von dem wir wissen, dass es passiert. Ein Unternehmen kündigt seine KI-Umstellung an. Die Führung präsentiert Demos von KI-Fähigkeiten, beeindruckende Demos, die echte Begeisterung auslösen. Tools werden evaluiert und gekauft. Metrik-Dashboards erscheinen, um die Einführungsraten zu verfolgen. Pilot-Teams berichten von spektakulären Ergebnissen.\nDann schlägt der Alltag in der Produktion zu. Die Demos lassen sich nicht mit bestehenden Systemen integrieren. Die Tools lösen Probleme, die eigentlich niemand hat. Die Pilotprojekte können nicht über ihre kontrollierte Umgebung hinaus skaliert werden. Die Metriken zeigen eine 87%ige Akzeptanz, während die Geschäftsergebnisse unverändert bleiben. Diese Abfolge ist nicht zufällig. Sie ist strukturell bedingt.\nWenn Unternehmen innovativ erscheinen müssen, optimieren sie eher das, was sichtbar ist, als das, was wertvoll ist. Demos sind sichtbar. Integrationsarbeit ist es nicht. Der Kauf von Tools ist sichtbar. Problemanalysen sind es nicht. Metriken für die Einführung sind sichtbar. Die KI-bedingte Änderung der Geschäftsergebnisse ist deutlich unübersichtlicher.\nDas haben Sie mit Agile erlebt. Sprint Reviews wurden zu PowerPoint-Präsentationen anstatt zur Zusammenarbeit mit Kunden und Stakeholdern an funktionierender Software in Echtzeit. Teams verbrachten Monate damit, Jira zu konfigurieren, während ihre eigentlichen Workflow-Probleme unbearbeitet blieben. Velocity-Diagramme zeigten stetige Fortschritte, während die Kunden keine Veränderung in der Liefergeschwindigkeit oder Qualität sahen. (Wie sich herausstellte, ist Velocity die am leichtesten zu manipulierende Kennzahl.)\nDas Erscheinungsbild änderte sich. Die Leistung aber nicht.\nWarum Unternehmen „Wandel“ inszenieren, anstatt sich zu verändern\nEs gibt einen Grund dafür, dass Organisationen auf Theater setzen: Es ist verlässlicher als eine Transformation.\nEchte Veränderung erfordert das Eingeständnis, dass die derzeitigen Ansätze nicht funktionieren. Sie erfordert eine Änderung der Machtstrukturen, der Anreize und Entscheidungsrechte. Sie erfordert die Akzeptanz des Scheiterns als Lernprozess. Und was am wichtigsten ist: Es erfordert Geduld für einen chaotischen, nicht-linearen Fortschritt.\n„Performance“ ist im Vergleich einfacher in den Vordergrund zu stellen. Sie können diesen planen, skripten und kontrollieren. Sie können stetig steigende Kennzahlen vorweisen (selbst wenn diese Kennzahlen bedeutungslos sind). Sie können den Erfolg auf der Grundlage von Aktivitäten und nicht von Ergebnissen einfordern. Sie können die unbequemen Fragen vermeiden, warum sich die Dinge nicht wirklich ändern.\nBetrachten Sie die Parallele zur „Definition of Done“. In Scrum erodieren Teams, die unter Druck stehen, oft ihre Definition von „Done“ und definieren ‚fertig‘ schließlich als „beim Sprint Review vorzeigbar“ und nicht als „in der Produktion mit echten Kunden einsatzfähig“. (Und wenn Letzteres dennoch geschieht, muss es mit dem Vermerk „bekannte Probleme werden später behoben“ versehen werden.) Bei der Künstlichen Intelligenz bedeutet „Done“, dass das „KI-Modell die Offline-Tests besteht“ und nicht „der KI-Arbeitsablauf liefert sichere, reproduzierbare, wertvolle Ergebnisse in der Produktion“. Beide Neudefinitionen dienen demselben Zweck: Sie machen es einfacher, Erfolg zu beanspruchen, ohne ihn erreichen zu müssen.\nDie vier Akte des Transformationstheaters\nAkt Eins: Werkzeuge nach vorn!\nBevor bestimmte Probleme identifiziert werden, evaluiert das Unternehmen Plattformen. Monatelange Anbietervergleiche, Proof-of-Concepts und Funktionsmatrizen. Das fühlt sich wie ein Fortschritt an: Es gibt Meetings, Entscheidungen und Kaufaufträge. Aber es ist derselbe Fehler wie der Glaube, dass die Konfiguration von Jira zu mehr Agilität führen würde. Tools verändern Unternehmen nicht. Das Lösen echter Probleme verändert Unternehmen.\nAkt zwei: Das Elite-Pilot-Team\nEin Team, das isoliert arbeitet, mit besonderen Ressourcen und Ausnahmen von den Standardbeschränkungen, erzielt bemerkenswerte Ergebnisse. Ihr KI-System verarbeitet Dokumente 100x schneller! Natürlich funktioniert es nur mit ihren Testdaten, umgeht die Sicherheitsprotokolle und ignoriert die gesetzlichen Anforderungen. Aber diese Details werden in der Erfolgsgeschichte nicht erwähnt, genau wie bei den leistungsstarken agilen Teams, deren Erfolg den ersten Kontakt mit der Unternehmensführung nicht überlebt hat.\nAkt drei: Alle Metriken zeigen grün\nÜberall kann auf den Dashboards, die die KI-Akzeptanz visualisieren, die Nutzung und das Engagement verfolgt werden. Alldings fehlt die Erfassung der gelösten Probleme, der gesparten Zeit oder des gelieferten Werts. Es ist wieder wie im Velocity-Theater: Aktivitäten werden gemessen, weil diese einfacher als Ergebnisse zu messen sind. Teams lernen schnell: Erzeugen sie die Kennzahlen, die das Management glücklich machen, unabhängig von den tatsächlichen Auswirkungen, sind auf der Sonnenseite.\nAkt Vier: Der Scheitern der Integration\nDie Realität holt uns ein: Was in der Sandbox die Oberhand hat, versagt in der Praxis: Die KI-Lösungen können nicht auf relevante Produktionsdaten zugreifen. Sie entsprechen nicht den Vorschriften. Sie können nicht mit realen Sonderfällen umgehen. Das Governance Board wird die KI-Agenten-basierten Prozesse nicht genehmigen und die laufenden Kosten sind nicht tragbar. Das Unternehmen gibt die Initiative im Stillen auf oder schraubt sie drastisch zurück, obwohl das Theater weitergeht.\nDie Anzeichen des Theaters lesen\nSie brauchen keine KI-Expertise, um diese Muster zu erkennen. Sie brauchen die bereits von Ihnen ausgebildete Mustererkennung:\n\nWenn jemand sagt: „Wir verwenden KI für…“, Ihnen aber den tatsächlichen Arbeitsablauf in der Produktion nicht zeigen kann, sehen Sie KI-Theater.\nWenn Problemaussagen den Tool-Entscheidungen folgen: „Wir haben OpenAI-Lizenzen gekauft, was sollen wir jetzt damit machen?“ Jetzt beobachten Sie die Suche nach einem Tool.\nWenn Erfolgsgeschichten nur von isolierten Teams mit besonderen Bedingungen kommen, dann beobachten Sie die sagenumwobenen Pilotprojekte.\nWenn Dashboards die Aktivitäten verfolgen, aber niemand die geschäftlichen Auswirkungen artikulieren kann, beobachten Sie das Frisieren der (KI-)Bücher.\n\nDer alternative Weg der KI Transformation\nEinige Unternehmen machen das richtig. Sie beginnen mit spezifischen, messbaren Problemen. Sie führen kurze Experimente mit klaren Hypothesen durch. Sie messen die Ergebnisse, nicht die Aktivität. Sie integrieren bestehende Systeme vom ersten Tag an. Sie definieren explizite Qualitätsmaßstäbe, die Sicherheit, Legalität und Betriebsbereitschaft einschließen. Dieser Ansatz ist nicht revolutionär. Es ist der empirische Ansatz, den Agile ermöglichen sollte. Der Unterschied besteht darin, dass man es tut, anstatt es aufzuführen.\nSie lesen dies wahrscheinlich, weil Sie die Muster wiedererkennen. Sie haben diesen Film schon einmal gesehen. Sie wissen, wie er endet. Die Frage ist nur, was Sie dagegen tun werden.\nSie könnten das Theater mitspielen, weil es politisch sicherer ist. Sie könnten zynisch werden und sich abwenden. Oder Sie könnten Ihre Fähigkeiten nutzen, um die unbequemen Fragen zu stellen, auf echten Problemen zu bestehen, bevor Sie Werkzeuge kaufen, Integrationspläne zu fordern, bevor Sie Pilotprojekte durchführen, und Ergebnisse statt Aktivitäten zu messen. (Kommt Ihnen das bekannt vor?)\nSie sind nicht negativ eingestellt, wenn Sie auf diese Muster hinweisen. Sie handeln im empirischen Sinne. Die wertvollste Person bei Ihrer KI-Transformation ist nicht der Prompt-Ingenieur. Es ist der Praktiker, der sagen kann: „Wir haben dieses Muster schon einmal gesehen, und so wird es enden, wenn wir nicht umsteuern.“ Das ist Ihre Rolle.\nScheitern der KI Transformation — Fazit\nSie haben bis hierher gelesen, weil Sie sich an das „letzte Mal“ erinnern und nicht daran glauben, dass es „dieses Mal anders sein wird“. Vielleicht waren es die Komitees zur Bewertung von Tools, die nie fragten: „Welches Problem lösen wir?“ Vielleicht waren es die von allen organisatorischen Zwängen befreiten Pilotteams, die den Sieg verkündeten. Vielleicht waren es die Dashboards, die alles außer dem gelieferten Wert aufzeichneten.\nWas auch immer es war, Sie haben es erkannt. Nicht, weil Sie ein KI-Experte sind, sondern weil Sie das schon einmal mit „Agile“ erlebt haben. Diese Erkenntnis ist Ihr Wettbewerbsvorteil. Während andere von den Demos, den Metriken und den Versprechungen fasziniert sind, erkennen Sie die Muster. Sie wissen, dass „87% KI-Adoption“ die neue „200% Velocity-Verbesserung“ ist: bedeutungslose Zahlen, die das Fehlen echter Veränderungen verbergen.\nDie hier dokumentierten Muster sind keine Warnungen vor dem, was passieren könnte. Sie sind Beschreibungen dessen, was jetzt gerade passiert. Die Frage ist nicht, ob Ihr Unternehmen diese Muster anwendet. Es geht darum, wie viele davon Sie gleichzeitig beobachten.\nAber dieses Mal ist es anders: Sie sind anders. Sie haben eine Immunität gegen das Transformationstheater entwickelt, indem Sie sich diesem ausgesetzt haben. Sie können den Unterschied zwischen einer Demo und einem realen Einsatz erkennen. Sie wissen, was mit Piloten passiert, wenn sie auf Produktionszwänge stoßen. Sie haben schon einmal Metrik-Spiele gesehen.\nSo haben Sie die Wahl. Nicht zwischen der Unterstützung und der Ablehnung von KI; das ist ein falsches Binärsystem. Sie haben die Wahl zwischen der Vorführung einer Transformation (Theater) und der tatsächlichen Transformation. Zwischen der Messung der Akzeptanz und der Messung der Auswirkungen. Zwischen isoliertem Erfolg und integrierter Umsetzung. Der schwierigste Teil ist nicht technischer Natur. Er ist politisch. Etwa, die Frage zu stellen „Welches spezifische Problem wird damit gelöst?“, wenn alle anderen von den Möglichkeiten der KI begeistert sind. Das Beharren auf der frühzeitigen Integration der Produktion, wenn jeder nur das zukünftige Potenzial sehen möchte. Das Messen von Ergebnissen, wenn Aktivitäten einfacher zu verfolgen sind.\nDas sind keine Akte des Widerstands. Es sind Taten der Professionalität. Sie sind nicht der Skeptiker, der Innovationen abwehrt. Sie sind der Praktiker, der den Unterschied zwischen Bewegung und Fortschritt kennt. Der Wandel, den Ihr Unternehmen braucht, hat nichts mit KI zu tun. Es geht darum, endlich die Lehren aus allen vorangegangenen „Change“-Projekten zu ziehen. Die Muster werden sich erst ändern, wenn Unternehmen aufhören, Theater über die Realität, Aktivität über Ergebnisse und Werkzeuge über Probleme zu stellen.\nSie können nicht das ganze System ändern. Aber Sie können Ihren Teil des Systems ändern. Ein wirklich gelöstes Problem. Eine ehrliche Metrik. Eine integrierte Lösung. Eine Stimme in der Besprechung, die fragt: „Wie unterscheidet sich das von dem, was wir mit Agile gemacht haben?“\nDiese Stimme ist wichtiger, als Sie denken. Denn jemand muss sagen, was alle denken, die die letzte Transformation überlebt haben: Wir haben diesen Film schon einmal gesehen und wir wissen, wie er endet. Wir werden es wieder erleben, es sei denn, wir ändern diesmal das Drehbuch.\n🗞 Soll ich Sie über Artikel wie diesen informieren? Großartig! Sie können sich hier für den Newsletter „Food for Agile Thought“ anmelden und sich über 40.000 Abonnenten anschließen.",
      "publishedDate": "2025-09-25T03:38:17.000Z",
      "author": "Stefan Wolpers",
      "source": {
        "name": "Scrum.org",
        "tier": "pmo",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:50.312Z",
      "localScore": 15
    },
    {
      "title": "EU rejects Apple demand to scrap landmark tech rules",
      "url": "https://techxplore.com/news/2025-09-eu-apple-demand-scrap-landmark.html",
      "summary": "The European Union rejected a call by Apple to scrap its landmark digital competition law on Thursday, dismissing the US giant's claims that the rules put users' security at risk.",
      "publishedDate": "2025-09-25T13:30:06.000Z",
      "author": "Unknown",
      "source": {
        "name": "Tech Xplore",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:10.173Z",
      "localScore": 12
    },
    {
      "title": "DeepCode: This FREE Agentic AI Coder is INSANE!",
      "url": "https://www.analyticsvidhya.com/blog/2025/09/deepcode/",
      "summary": "Imagine this scenario: you’ve just read a brilliant research paper with a cutting-edge algorithm, but it will take you weeks of boring code development to implement the research, or maybe you’ve thought of a brilliant web app but have not developed the frontend skills necessary to create it. What if I told you that there […]\nThe post DeepCode: This FREE Agentic AI Coder is INSANE! appeared first on Analytics Vidhya.",
      "publishedDate": "2025-09-25T03:04:00.000Z",
      "author": "Riya Bansal",
      "source": {
        "name": "Analytics Vidhya",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:44.059Z",
      "localScore": 10
    },
    {
      "title": "Why Switzerland must vote yes for a national digital ID ",
      "url": "https://www.imd.org/ibyimd/innovation/why-switzerland-must-vote-yes-for-a-national-digital-id/",
      "summary": "This weekend, Swiss voters will once again be asked to decide on a national electronic identity. The upcoming vote is more than a question of convenience. It is about whether Switzerland will remain a digital leader or risk falling behind its neighbors in digital competitiveness and innovation.\nThe post Why Switzerland must vote yes for a national digital ID  first appeared on IMD business school for management and leadership courses.",
      "publishedDate": "2025-09-24T15:01:16.000Z",
      "author": "Michael R. Wade, Arturo Bris",
      "source": {
        "name": "IMD Business",
        "tier": "business",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:12.644Z",
      "localScore": 10
    },
    {
      "title": "10 Signs You're Using Scrum Badly",
      "url": "https://www.scrum.org/resources/blog/10-signs-youre-using-scrum-badly",
      "summary": "Sometimes Scrum gets a bad rap. When I ask why an organization struggled with Scrum, I almost always hear something like “there was too much overhead.” But when I dig deeper, I usually find that the organization had imposed extra rules—rules that have nothing to do with Scrum. In other words, when Scrum “doesn’t work,” it’s almost always because the team wasn’t actually using Scrum well.\nIn today’s fast-moving world, Scrum is more relevant than ever. Sure, it’s no longer shiny and new, but it’s still the best tool we have for enabling teams to solve complex problems. Scrum provides just enough structure for teams to collaborate effectively—without bogging them down in bureaucracy.\nSo if your team is struggling, pause and ask yourself: Are we really using Scrum the way it was designed? Here are 10 signs you might be holding your Scrum team back - and what you can do about it.\n1. Too Many Approval Gates\n\n\nIf every piece of work needs a parade of signatures before it moves forward, you’re not creating accountability or transparency - you’re creating waste and frustration. A Scrum board with 20 columns isn’t “disciplined,” it’s a bottleneck factory.\nScrum thrives when the team has just enough process to expose the work, not bury it under layers of approval.\nWhat to do instead:  Measure the Scrum team's effectiveness by measuring customer outcomes.\n2. Documentation Requirements Are Too Rigorous\nIf every backlog item requires a novella’s worth of acceptance criteria, ROI calculations, and footnotes, congratulations—you’re writing literature, not building products.\nScrum doesn’t say “don’t document.” It says document just enough. Teams in regulated industries may need more, sure. But when documentation becomes a bigger deliverable than the product itself, you’ve lost the plot.\nYes, documentation is important. But requiring ten acceptance criteria for every backlog item? Or calculating ROI for every story? That’s overkill. The Scrum team decides how much documentation is enough to deliver value. Anything beyond that is just busywork.\nWhat to do instead:  Use the Definition of Done to reduce documentation requirements where possible.  For example, if every product backlog item requires a certain amount of testing, put it in the Definition of Done.\n3. Silos, Silos Everywhere\n\n\nA cross-functional team should be able to deliver something valuable on its own. If your team needs to wait on three other teams before anything ships, you’re not doing Scrum—you’re doing dependency management with extra steps.\nIt’s like asking one team to deliver only the top-right corner of a birthday present box, while another builds the bottom-left. By the time the customer sees it, the “gift” looks like Frankenstein’s wrapping job.\n\n \nWhat to do instead:  Take a step back and define products for the organization.  Contact Rebel Scrum to learn more.\n4. Low Trust\nWhen trust evaporates, Scrum collapses. I once worked with a team where stakeholders didn’t trust the Product Owner, so they shoved requests straight onto Developers. Developers didn’t trust the PO either, so they ignored the backlog. The Sprint Review turned into a magic trick: Surprise! 70% of the Sprint was invisible work!\nIf people are bypassing roles, it’s not a shortcut—it’s a symptom of broken trust.\n5. The Scrum Team Is Disempowered\nIf every decision has to be rubber-stamped by someone outside the team, your “Scrum team” is really just an execution arm for somebody else’s brain. That’s not Scrum—that’s command and control with daily standups.\n6. Low Morale\nScrum teams want to do great work. When morale tanks, it’s usually because they can’t. Maybe the backlog is a mess, maybe they’re blocked by silos, maybe they don't have the resources that they need, or maybe their every move is second-guessed.\nLow morale isn’t laziness—it’s a canary in the coal mine. Ignore it, and don’t be surprised when turnover starts.\n7. No Product Goal\nWithout a Product Goal, your team is just flailing. Work becomes a random collection of busywork instead of a meaningful push toward value. It’s like rowing hard without a destination—you’re sweating, but you’re not actually going anywhere.\n8. Micromanagement\nIf you feel the need to track every move your team makes, ask yourself why. Micromanagement signals a lack of trust. Instead of hovering, lean into Scrum’s built-in transparency: Sprint Reviews, Daily Scrums, and Retrospectives. They exist so you don’t need to micromanage.  (Check out our recent article, 10 Signs You Might be Micromanaging your Scrum team.)\n9. Not Delivering Incrementally\nScrum is built on incremental delivery. If you’re holding work back until “it’s all done,” you’re missing the point. Delivering in small increments reduces risk, provides fast feedback, and keeps stakeholders engaged. If you’re not delivering incrementally, you’re not really doing Scrum.  (Check out 4 Red Flags Your Agile Team May Not Fully Embrace Incremental Delivery.)\n10. Skipping the Retrospective\n\n\nIronically, low performing teams tend to skip the Retrospective more often than high performing teams.  (Seems like there might be a causal relationship there, actually.)\nSkipping Retrospectives is like skipping oil changes on your car—it might seem fine at first, but pretty soon, things will break down. Retrospectives are how Scrum teams inspect and adapt. Without them, the team stagnates.  If you are skipping the Retrospective frequently it may be a sign of a deeper problem.  Is it because the Scrum team is not empowered?  Do they not have a clear goal that they can iterate towards?  \nWhat to do instead: Don't skip the Retrospective, design a targeted Retrospective to address your problems head-on.  And make sure that Every Retrospective results in a least one action item - no matter how small - to improve the adoption of Scrum.  (Are you struggling with engagement at the Retrospective?  Try taking turns leading the Retrospective to get more engagement and ownership from the team.)\nConclusion\nScrum is simple, but that doesn’t mean it’s easy. The framework was never meant to add layers of overhead—it’s meant to strip them away. If you recognize these signs in your team, don’t blame Scrum. Instead, ask whether you’ve accidentally layered in bureaucracy, silos, or mistrust.\nThe good news? These problems are solvable. With trust, empowerment, and a relentless focus on delivering value, Scrum can be exactly what your team needs: the lightest framework that helps you navigate a complex, fast-moving world.\n-----------\nRebel Scrum is the host of the annual Scrum Day Madison conference.",
      "publishedDate": "2025-09-24T22:40:31.000Z",
      "author": "Mary Iqbal",
      "source": {
        "name": "Scrum.org",
        "tier": "pmo",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:50.312Z",
      "localScore": 10
    },
    {
      "title": "Top 9 AI Agent Frameworks as of September 2025 | Shakudo",
      "url": "https://www.shakudo.io/blog/top-9-ai-agent-frameworks",
      "summary": "Sep 2, 2025 ... Latest ranking of AI agent frameworks for autonomous systems. In ... d recommend this framework for businesses with dedicated technical ...",
      "publishedDate": "2025-09-25T13:59:20.281Z",
      "author": "Unknown",
      "source": {
        "name": "shakudo",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI orchestration platforms\" OR \"AI agent frameworks\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:20.281Z",
      "localScore": 9
    },
    {
      "title": "Building Your First AI Agent with n8n | DataCamp",
      "url": "https://www.datacamp.com/code-along/building-your-first-ai-agent-with-n8n",
      "summary": "Jun 19, 2025 ... 50% off unlimited learning. Sale ends in. 5d14h33m51s. Buy Now. Skip to ... AI Agent Frameworks: Building Smarter Systems with the Right Tools.",
      "publishedDate": "2025-09-25T13:59:20.281Z",
      "author": "Unknown",
      "source": {
        "name": "datacamp",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI orchestration platforms\" OR \"AI agent frameworks\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:20.281Z",
      "localScore": 8
    },
    {
      "title": "AI Agents For Everyone with n8n | DataCamp",
      "url": "https://www.datacamp.com/code-along/ai-agents-for-everyone-with-n8n",
      "summary": "Sep 3, 2025 ... 50% off unlimited learning. Sale ends in. 5d07h58m31s. Buy Now. Skip to ... AI Agent Frameworks: Building Smarter Systems with the Right Tools.",
      "publishedDate": "2025-09-25T13:59:20.281Z",
      "author": "Unknown",
      "source": {
        "name": "datacamp",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI orchestration platforms\" OR \"AI agent frameworks\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:20.281Z",
      "localScore": 8
    },
    {
      "title": "Cohere hits $7B valuation a month after its last raise, partners with AMD",
      "url": "https://techcrunch.com/2025/09/24/cohere-hits-7b-valuation-a-month-after-its-last-raise-partners-with-amd/",
      "summary": "A fresh $100 million and an interesting partnership with AMD has slightly bumped Cohere's valuation up.",
      "publishedDate": "2025-09-24T18:06:22.000Z",
      "author": "Julie Bort",
      "source": {
        "name": "TechCrunch AI",
        "tier": "ai-news",
        "authority": "Medium",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:11.143Z",
      "localScore": 7
    },
    {
      "title": "A Detailed Comparison of Top 6 AI Agent Frameworks in 2025",
      "url": "https://www.turing.com/resources/ai-agent-frameworks",
      "summary": "May 20, 2025 ... This article compares six leading AI agent frameworks–LangGraph, LlamaIndex, CrewAI, Microsoft Semantic Kernel, Microsoft AutoGen, and OpenAI Swarm",
      "publishedDate": "2025-09-25T13:59:20.281Z",
      "author": "Unknown",
      "source": {
        "name": "turing",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI orchestration platforms\" OR \"AI agent frameworks\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:20.281Z",
      "localScore": 6
    },
    {
      "title": "Console wars death watch: Microsoft Flight Simulator coming to PS5 in December",
      "url": "https://arstechnica.com/gaming/2025/09/microsoft-flight-simulator-becomes-a-sony-flight-simulator-on-ps5-this-december/",
      "summary": "What's next, Sonic games on Nintendo consoles? Oh, wait...",
      "publishedDate": "2025-09-24T21:56:27.000Z",
      "author": "\n                    Kyle Orland\n                ",
      "source": {
        "name": "Ars Technica",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:11.796Z",
      "localScore": 5
    },
    {
      "title": "Fusion power plants don’t exist yet, but they’re making money anyway",
      "url": "https://www.technologyreview.com/2025/09/25/1124050/fusion-future-funding/",
      "summary": "This week, Commonwealth Fusion Systems announced it has another customer for its first commercial fusion power plant, in Virginia. Eni, one of the world’s largest oil and gas companies, signed a billion-dollar deal to buy electricity from the facility. One small detail? That reactor doesn’t exist yet. Neither does the smaller reactor Commonwealth is building…",
      "publishedDate": "2025-09-25T10:00:00.000Z",
      "author": "Casey Crownhart",
      "source": {
        "name": "MIT Tech Review",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:12.364Z",
      "localScore": 5
    },
    {
      "title": "5 AI Agent Projects for Beginners",
      "url": "https://machinelearningmastery.com/5-ai-agent-projects-for-beginners/",
      "summary": "<a href=\"https://www.",
      "publishedDate": "2025-09-25T12:00:40.000Z",
      "author": "Abid Ali Awan",
      "source": {
        "name": "Machine Learning Mastery",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:41.805Z",
      "localScore": 5
    },
    {
      "title": "5 Best Laptops for AI Engineers and Developers",
      "url": "https://www.analyticsvidhya.com/blog/2025/09/laptops-for-ai-engineers-and-developers/",
      "summary": "Looking to buy the best laptop to get into software development? You would’ve realized by now how hard it is to stay up to date with the latest hardware and the ever-increasing application requirements. This article is here to elucidate that for you, by listing the best laptops that the market has to offer for […]\nThe post 5 Best Laptops for AI Engineers and Developers appeared first on Analytics Vidhya.",
      "publishedDate": "2025-09-25T13:49:59.000Z",
      "author": "Vasu Deo Sankrityayan",
      "source": {
        "name": "Analytics Vidhya",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:44.059Z",
      "localScore": 5
    },
    {
      "title": "Listen to a podcast deep dive on how Tensor G5 makes Pixel 10 better than ever.",
      "url": "https://blog.google/products/pixel/made-by-google-podcast-tensor-g5/",
      "summary": "The Made by Google Podcast takes a deep dive into the Tensor G5 chip, the brains behind the new Pixel 10.",
      "publishedDate": "2025-09-24T20:16:00.000Z",
      "author": "Unknown",
      "source": {
        "name": "Google Blog",
        "tier": "business",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:09.083Z",
      "localScore": 5
    },
    {
      "title": "Instagram now has 3 billion monthly active users",
      "url": "https://www.cnbc.com/2025/09/24/instagram-now-has-3-billion-monthly-active-users.html",
      "summary": "Meta said that Instagram now has 3 billion monthly active users.",
      "publishedDate": "2025-09-24T15:32:58.000Z",
      "author": "Unknown",
      "source": {
        "name": "CNBC Tech",
        "tier": "business",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:07.346Z",
      "localScore": 3
    },
    {
      "title": "Tesla Nearing October 2nd Breakout With Q3 Production Numbers",
      "url": "https://www.nextbigfuture.com/2025/09/tesla-nearing-october-2nd-breakout-with-q3-production-numbers.html",
      "summary": "Tesla’s stock has been stuck in narrow range. What could break it out? Full Self-Driving (FSD) software challenges, AI data center energy needs, nuclear power developments, H-1B visa reforms, and broader commentary. Tesla traders are seeing shares stuck at $440 (unlikely to break without major news), with support levels at $423–$424 and $410. Are dips ... \nRead more",
      "publishedDate": "2025-09-24T14:32:11.000Z",
      "author": "Brian Wang",
      "source": {
        "name": "Next Big Future",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:06.291Z",
      "localScore": 2
    },
    {
      "title": "How to Master Advanced TorchVision v2 Transforms, MixUp, CutMix, and Modern CNN Training for State-of-the-Art Computer Vision?",
      "url": "https://www.marktechpost.com/2025/09/24/how-to-master-advanced-torchvision-v2-transforms-mixup-cutmix-and-modern-cnn-training-for-state-of-the-art-computer-vision/",
      "summary": "In this tutorial, we explore advanced computer vision techniques using TorchVision’s v2 transforms, modern augmentation strategies, and powerful training enhancements. We walk through the process of building an augmentation pipeline, applying MixUp and CutMix, designing a modern CNN with attention, and implementing a robust training loop. By running everything seamlessly in Google Colab, we position […]\nThe post How to Master Advanced TorchVision v2 Transforms, MixUp, CutMix, and Modern CNN Training for State-of-the-Art Computer Vision? appeared first on MarkTechPost.",
      "publishedDate": "2025-09-24T22:55:43.000Z",
      "author": "Asif Razzaq",
      "source": {
        "name": "MarkTechPost",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:33.265Z",
      "localScore": 2
    },
    {
      "title": "Google’s Agent Payments Protocol (AP2): The New Way AI Agents Pay for You",
      "url": "https://www.analyticsvidhya.com/blog/2025/09/agent-payments-protocol-ap2/",
      "summary": "Google has recently introduced a new open standard for its online payments with the Agent Payments Protocol (AP2). AP2 is a long-awaited initiative that enables AI-assisted secure payments for users. AP2 builds on the existing agent communication protocols of Agent2Agent (A2A) and Model Context (MCP) to produce a transaction-agnostic layer. In short, AP2 is a […]\nThe post Google’s Agent Payments Protocol (AP2): The New Way AI Agents Pay for You appeared first on Analytics Vidhya.",
      "publishedDate": "2025-09-25T02:12:00.000Z",
      "author": "Vipin Vashisth",
      "source": {
        "name": "Analytics Vidhya",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:44.059Z",
      "localScore": 2
    },
    {
      "title": "Synthesizing Standalone World-Models, Part 2: Shifting Structures",
      "url": "https://www.alignmentforum.org/posts/kNyMwXQxctWtaRZhs/synthesizing-standalone-world-models-part-2-shifting",
      "summary": "Published on September 24, 2025 7:02 PM GMT\n\nThis is part of a series covering my current research agenda. Refer to the linked post for additional context.\n\nLet's revisit our initial problem. We're given the lowest-level representation of a well-abstracting universe, and we want to transform it into its minimal representation / the corresponding well-structured world-model. The tools introduced in Part 1 are insufficient for that: there are two more problems left. This part focuses on one of them.\nKey example: Imagine looking at a glider in Conway's Game of Life. At the first time-step, it may occupy the coordinates [0:3]×[0:3].mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n. As time goes on, it would gradually migrate, diagonally moving in the bottom-right direction at the speed of one cell per three time-steps.\nIf we take the individual cells to be the random variables to abstract over, in what sense is the glider an abstraction over them? It's a \"virtual object\", drifting across them.\nBut if it's not an abstraction over the cells, then over... what? There aren't really any other elements in the picture! Maybe it's an abstraction over sets of cells, with cells being \"subvariables\" over which the glider is synergistic? But how exactly do we define those sets?\n(Perhaps it's a synergistic variable over the whole grid/world? I've tried that. That approach was instructive, but it got very clunky very fast.)\nOnce you start looking for it, you start spotting problems of this sort all over the place.\n\n2.1. Wall O' Examples\n\nConsider a human mind in a high-tech civilization. At one moment, it may be implemented on biological neurons; at another, it may jump to some artificial substrate; then the lower-level algorithms on which it functions may be changed without change in high-level behavior; then it may be transferred to another star system encoded in a bunch of photons. Is there any stable set of lower-level random variables over which it is an abstraction?\nNow imagine if we try to model that as a synergistic variable over the whole world. That synergistic variable would have to be defined as drastically different, basically custom-built functions of every specific world-state. It'd have to be able to \"process\"/\"attach to\" any possible representation the upload may have.\nI've tried variants on that approach. It was instructive, but got very clunky very fast. What we need is some general framework for allowing synergistic variables to \"see through\" changes in representation…\n\nThe much-abused dog example fares no better. We say that \"this specific dog\" is an abstraction over some lower-level subsystems \"marked\" by synergistic variables. But the actual positioning of those subsystems isn't stable, nor even their number. How many DNA-containing cells does \"a dog\" have?\nThis is somewhat handled by the thing about Shamir's scheme in 1.5, but it gets very clunky very fast. Especially if we try to apply it to \"virtual objects\" in general, see the upload case above. It's a very \"low-tech\" solution.\n\nIf we consider \"the concept of an animal\", it gets even worse. Some animals don't have eyes, some have echolocators; their digestive, circulatory, and nervous systems may function in completely different ways. What are the features/subvariables in the \"default representation\" of \"an animal\" which, if we condition their values on a higher-level variable, would transform into any possible animal?\nWe can model it using some sort of sufficiently high-dimensional space, of course. But then it more or less becomes an m-dimensional space where m is the number of animal types, and where the animal definitions are one-hot vectors. Again, what's the actual form of the low-level variables the abstraction is defined over, here? What form could it be?\n\nAs outlined in a previous section, the function F a program implements can be considered an abstraction over all possible implementations of this function Pi, with each Pi being a construction {p1i,…,pmi} made up of some combinations of basic functions. Except, uh, both the number of the functions and their dictionary changes between the implementations. Again, what's the implementation-agnostic default program template that we're implicitly using here, the subvariables of the variable over which we abstract (and which doesn't reduce to just one-hot encodings for each possible program)?\nI suppose we can project to e. g. the parameter space of neural networks. But the mapping has many free parameters, and even if we use a fixed-size fixed-architecture representation, neuron#42312 doesn't necessarily implement the same higher-level operation in every sample, so we can't use some fixed way to abstract up.\n\nOr consider your eyes. We can model them, or their constituent \"pixels\"/cone cells, as some random variables. How are you supposed to use them to find the world's abstractions? The abstract structures mapped to them constantly change: they \"drift\" like the Conway glider, they jump representations like the upload (looking at an event vs. seeing its video vs. reading a newspaper article about it...), they get stochastically resampled (switching TV channels, losing consciousness, boarding a random train and ending up in an unfamiliar place)…\nLLMs deal with the same issue: they always get fed a vector of a pre-defined size, mapped to the same set of input-variables, and they somehow know to connect that to different in-world structures depending on what's in it. How, in information-theoretic terms?\nSimilar happens for various in-the-world systems. A newspaper's text, for example: much like observation-variables, it \"connects\" to different structures in the world, depending on the newspaper issue. How do we process that data, infer what it's connected to?\n(I'd tried modeling those switches as, well, literal \"switch-variables\", which control at what part of the world we look, and which get resampled as well. That was instructive, but got very clunky very fast.)\n\nSimilar issue occurs if we're looking at an n-vector representing a low-level universe-state from a god's-eye perspective and watch it get resampled (either randomly, or by a state transition to the next time-step). It's full of such virtual objects and changing structures. We can't start \"unraveling\" it in any white-box way without figuring out how to deal with this.\n(We can just say \"we have a hypercomputer so we just try all possible representations until finding the minimal one\", but that's not helpful. Indeed, that's basically just another one-hot encoding / lookup table mapping the whole n-vector to different values. We're not doing any \"abstracting\" at all here, information-theoretically.)\n\n\n2.2. Grasping the Problem\nThe program example actually hints at what the issue is. The function F is very, very agnostic regarding its lower-level implementation. There's an infinite number of programs that implement it: a two-bit adder can be implemented as a bunch of NAND gates, or XOR gates, or Lisp functions, or as transistors implementing NAND gates, or as an analog computer made up of water streams, or as a set of star systems exchanging asteroids, or as the simulation of a vast civilization tasked with summing the bits...\nSame with the abstractions in general. The higher level of abstraction is largely agnostic regarding the nature of the lower level implementing it. As long as the lower level passes some minimal threshold of expressivity, it can implement a dynamic with ~any emergent behavior. Meaning, in a vacuum, there's ~zero mutual information between the higher level and the laws of the lower level.\nAn \"animal\" could be represented using a wide variety of \"programs\" of different compositions; same with \"a human mind\"; same with \"a market\". Once we lock down a specific \"abstraction operator\" – the map from the lower to the higher level – the lower level is fixed, and the higher level is a valid natural latent over it. But if we go top-down, holding the higher-level abstract structure fixed but not receiving any information about the lower level, the lower-level's structure (not just values) isn't fixed; it's only constrained to the infinite number of structures over which the higher level would be a valid natural latent.\nSymmetrically, if we go bottom-up, there's not any sense in which a specific set of labeled lower-level variables necessarily has the same relationship with any given higher-level variable; or that any given higher-level variable survives a resampling. Depending on the nature of the resampling (random like in \"god's-eye view\", or deterministic like in Conway's, or stochastic-but-not-independent like in head movements), the structures may drift, switch representations, or change outright. So what we need is to... somehow... learn new abstractions from one sample?\nSumming up: Usually, when we're facing a structure-learning problem, we assume that the structure is fixed and we get many samples for it. Here, the structure itself gets resampled. (See also: the bit in 1.3 regarding how we'll need to figure out how to deal with things that \"look like\" probabilistic structures from one angle, and like random variables from a different one.)\n\n2.3. Exploiting the Anthropic Prior\nLet's suppose we do have that hypercomputer after all.\nThe anthropic prior is a very specific entity. It defines a highly opinionated distribution over Tegmark IV/the set of all possible mathematical structures. (This, incidentally, lets us get out of various no-free-lunch theorems. We're not looking at a uniform distribution over all mathematically possible worlds, nor demand perfect performance in all of them. We want good-enough performance on the anthropic prior.)\nSo suppose we compute that prior, and then refactor it into the joint probability distribution over the set of all possible abstractions.\nThat is: Suppose we've gained the ability to learn, by looking at a specific type of variable, what other abstractions are typically present in a universe containing this type of variable. Each corresponding joint sample would be weighed by the anthropic prior, meaning the abstractions' sheer agnosticism regarding lower levels would be ameliorated by us defining a probability distribution over them. Some examples:\n\nIf we see a human, we'd consider it likely that there are other humans around, and perhaps that \"government\" abstractions are active. Depending on the human's clothes, we can update towards or against various types of technology existing. Seeing a human would also make it very unlikely that e. g. any hostile-to-humans superintelligent entities are around.\nIf we see the \"democracy\" abstraction, we would upweight the possibility that there's a set of some sort of agents at the lower level, with non-orthogonal but also not-exactly-the-same values, implementing a civilization. It's possible that a bunch of star systems lobbing asteroids at each other spontaneously assembled into a system for which \"a democracy\" is a good abstraction, but that's pretty unlikely.\nIf we see a sapient mind of a particular form, we'd consider it likely that this universe's history involved some sort of evolutionary process. It's possible that it's a Boltzmann brain, but, conditioning on a well-abstracting universe, that's unlikely.\nIf we see a dog at one moment, we'd consider it likely that the same dog will be present at the next moment, assuming the state-transition function mapping this moment to the next one implements some sort of simple physics.\nSeeing a system implementing a spiral galaxy would presumably nontrivially upweight the probability of a lower level containing stars and planets.\n\nEt cetera. By conditioning on \"this is a sample from the anthropic prior\"/\"we are in a universe that is overall well-abstracting\", we can derive posterior distributions over probabilistic structures, rather than just the values of fixed variables in fixed structures.\nIncidentally, this can be viewed as a generalization of the general abstraction machinery, rather than some new addendum. When we condition on \"we're looking at a dog\", we don't actually deterministically deduce that it has a head, four legs, a heart, and a tail. We merely update our distribution over lower-level structures/features to strongly expect this set of features. We also place a nontrivial amount on \"three legs, one tail\", yet assign epsilon probability to \"no head\" (assuming alive dog) or \"twenty heads\". (This is the promised better way to handle the nitpick in 1.5.)\nBut there's also a bunch of other, softer inferences we make. For example, if we're searching for a specific type of virus that tends to infect dogs, our probability distribution over the locations of this virus' instances would shift towards the volume the dog's body occupies. We'd also infer some distribution over the number of \"dog cell\" abstractions present at the lower level, and the atomic contents of the volume in question, et cetera. Those are all, again, best modeled as inferences about structures, not values (or, well, as about structure-valued variables).\nIn terms of \"upwards\" inferences, we'd expect the \"dog concept\" abstraction (not only this-dog) to be present in that world, and e. g. allocate nontrivial amount of probability mass to \"Earth-like biosphere and evolutionary history\".\nIn terms of \"sideways\" inferences (abstractions at the \"same level\" as the dog), we'd expect more dogs or the dog's owner to be nearby (though, hmm, this might actually route through conditioning on the higher-level \"dog concept\" variable, which both creates new variables and synergistically creates mutual information between them and the dog).\nSo, summarizing: In practical cases, it's impossible to deterministically deduce / uniquely constrain the structures you're trying to learn. However, due to the fact that the \"well-abstractibility prior\" is a very specific entity, it's possible to define posterior probability distributions over those structures.\n\n2.4. The Need for Truesight\nLet's take a look at the current problem from a different angle. Consider the following:\n\nConway's glider vs. the same glider shifted some distance bottom-right.\nA human mind switching computational substrates and lower-level algorithms without change in function.\nThe dog that's the same at the high level, but with slightly different numbers of cells, or slightly different organ placements.\nThe concept of an animal, applicable to systems that function in wildly different ways.\nThe concept of a dog, applicable to different pictures of different dogs.\nThe function F implemented in a variety of different ways on different programming languages.\nThe same real-world structure perceived through…\n... your eyes.\n... your eyes, but after you walked a few meters to the left and slightly rotated your head.\n... your ears.\n... someone's verbal description of it.\n... a news article.\n... a video.\n... a metaphorical poem.\n\nA set of mathematical theorems supported by the same set of axioms.\nA high-level system vs, the corresponding low-level system plus some simplifying assumptions.\nTechnically correct-and-complete descriptions of the same event by two newspapers with different political biases.\nThe plaintext message vs. the ciphertext and the key to it.\n\nEach of those examples involves different representations of what's ultimately the same thing, but transformed in a way such that the similarity is very non-trivial to spot.\nWhat this immediately reminds me of, with all the photo examples, are CNNs.\nCNNs' architecture has translation symmetry built-in: their learned features are hooked up to machinery that moves them all across the image, ensuring that their functionality is invariant under changes in the specific position of the features in the image. What we want is a generalization of this trick: a broad \"suite of symmetries\" which we \"attach\" to the inputs of our learned abstraction-recognition functions, to ensure they don't get confused by the abstract equivalent of shifting a dog in a picture slightly to the left.\nI. e., we want to give our abstraction operators \"truesight\": empower them to zero-shot the recognition of already-known abstractions under changes in representation.\nIn the general case, that's impossible. After all, there's a function for mapping anything to anything else, more or less. No free lunch.\nBut we're not working with the general case: we're working with the samples from the anthropic prior. For any given set of abstractions that we're already seeing, there's a very specific posterior distribution over what abstractions we should expect to discover next. Which corresponds to a probability distribution over what \"lens\" we should try putting onto our feature-detectors to spot the familiar abstractions in new data.\nIn other words: we have a probability distribution over sequences of transformations of the data we should attempt to try, and we keep sampling from it until we spot a familiar abstraction; until we find a way of looking at the data under which it resolves into a known, simple pattern. (Where \"simplicity\" is defined relative to our learned library of abstractions.)\nWhich is to say, we engage in qualitative research. We switch between various representations until finding one in which the compression task looks trivial to us.\nI think this problem/process is, indeed, literally the underlying \"type signature\" of a large fraction of human science and research efforts.\nSome other examples of when it happens:\n\nReading an ambiguous sentence, and trying to pick one interpretation out of several, by trying each of them on \"for size\" and figuring out which would \"make the most sense\" within the context (i. e., simplify your model of that context).\nLooking at a confusing painting, and figuring out what you're looking at by quickly flipping through several explanations (\"maybe it's a face? maybe that's an arm?\") until the picture snaps together.\nAnalyzing a table of numbers in search of a pattern, and eyeballing potential causal connections and trends (\"do these two variables seem to change together? does this variable follow a periodic pattern? is this an exponential?\").\nSelf-psychoanalysis (noticing a weird, illegible emotional response, and reverse-engineering it by iteratively generating verbal explanations and sounding them out/testing them, until one rings true).\nHaving a specific word/concept \"at the tip of your tongue\" that you think perfectly describes a situation, and searching for it by repeatedly sampling concepts/words that come to mind.\nSeeing a number of clues, in e. g. a murder-mystery story, and generating a tree of potential explanations whose branches you eliminate until you're left with a single reality that generated all of those clues. \n\nWhat I'm particularly interested in for the purposes of the bounties:\n\nWhat ways are there of formalizing the machinery described? (There's one obvious way, but I'm wondering whether that framework could be avoided...)\nIs there any extant research covering setups with such \"resampled structures\"?\n\nDiscuss",
      "publishedDate": "2025-09-24T19:02:14.000Z",
      "author": "Thane Ruthenis",
      "source": {
        "name": "AI Alignment Forum",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:46.420Z",
      "localScore": 2
    },
    {
      "title": "A Comprehensive Guide to AI Workflow Automation in 2024 – n8n ...",
      "url": "https://blog.n8n.io/ai-workflow-automation/",
      "summary": "Oct 11, 2024 ... We will highlight 5 AI workflow automation tools that go beyond ... d/1zs963iFkO-3g2rKak8Hcy555h55D8gjF/view?usp=sharing\" }, { \"name ...",
      "publishedDate": "2024-10-11T08:51:49.000Z",
      "author": "Unknown",
      "source": {
        "name": "blog",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI automation platforms\" OR \"AI workflow automation tools\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:18.847Z",
      "localScore": 2
    },
    {
      "title": "Databricks will bake OpenAI models into its products in $100M bet to spur enterprise adoption",
      "url": "https://techcrunch.com/2025/09/25/databricks-will-bake-openai-models-into-its-products-in-100m-bet-to-spur-enterprise-adoption/",
      "summary": "Databricks is on the hook to pay at least $100 million to OpenAI in this deal, even if customer usage falls short. It's a bet, but one that Databricks has already hedged.",
      "publishedDate": "2025-09-25T13:14:16.000Z",
      "author": "Rebecca Bellan",
      "source": {
        "name": "TechCrunch AI",
        "tier": "ai-news",
        "authority": "Medium",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:11.143Z",
      "localScore": 1
    },
    {
      "title": "Building Video Game Recommender Systems with FastAPI, PostgreSQL, and Render: Part 1",
      "url": "https://towardsdatascience.com/building-video-game-recommender-systems-with-fastapi-postgresql-and-render-part-1/",
      "summary": "Designing a video game recommendations service with Steams API\nThe post Building Video Game Recommender Systems with FastAPI, PostgreSQL, and Render: Part 1 appeared first on Towards Data Science.",
      "publishedDate": "2025-09-25T12:30:00.000Z",
      "author": "Lucas See",
      "source": {
        "name": "Towards Data Science",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:20.761Z",
      "localScore": 1
    },
    {
      "title": "Chery Auto Raises US$1.2B in Hong Kong’s Largest Carmaker IPO of 2025",
      "url": "https://technode.com/2025/09/25/chery-auto-raises-us1-2b-in-hong-kongs-largest-carmaker-ipo-of-2025/",
      "summary": "Chery Automobile (9973.HK), China’s biggest passenger car exporter, listed on the Hong Kong Stock Exchange on Sept. 25 after raising HK$9.1 billion (US$1.2 billion) in the city’s largest carmaker IPO this year. The company sold 297 million H-shares at HK$30.75 each, with 13 cornerstone investors including Hillhouse’s HHLR, Greenwoods and Guoxuan Hong Kong. Shares opened […]",
      "publishedDate": "2025-09-25T08:09:24.000Z",
      "author": "TechNode Feed",
      "source": {
        "name": "TechNode",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:30.393Z",
      "localScore": 1
    },
    {
      "title": "Databricks commits to $100 million in OpenAI spending as high-valued startups team up in AI",
      "url": "https://www.cnbc.com/2025/09/25/databricks-commits-to-100-million-in-openai-spending-for-ai.html",
      "summary": "Databricks plans to spend at least $100 million over multiple years on OpenAI models.",
      "publishedDate": "2025-09-25T13:00:01.000Z",
      "author": "Unknown",
      "source": {
        "name": "CNBC Tech",
        "tier": "business",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:07.346Z",
      "localScore": 1
    },
    {
      "title": "British AI firm Nscale raises $1.1 billion in Nvidia-backed funding round",
      "url": "https://www.cnbc.com/2025/09/25/nvidia-backed-uk-ai-firm-nscale-raises-1point1-billion-funding-round.html",
      "summary": "The investment highlights continued demand for high-powered computing infrastructure required to train and run powerful AI models.",
      "publishedDate": "2025-09-25T10:34:23.000Z",
      "author": "Unknown",
      "source": {
        "name": "CNBC Tech",
        "tier": "business",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:07.346Z",
      "localScore": 1
    },
    {
      "title": "Everything you need to know about nonmarket strategy, part 1: Why do you need it?  ",
      "url": "https://www.imd.org/ibyimd/brain-circuits/everything-you-need-to-know-about-nonmarket-strategy-part-1-why-do-you-need-it/",
      "summary": "Forward-thinking leaders proactively shape their external environment, turn uncertainty into certainty, and create substantial value in the process. In the first of a two-part series, Michael Yaziji explains why nonmarket strategy is a key tool in today’s leadership playbook.\nThe post Everything you need to know about nonmarket strategy, part 1: Why do you need it?   first appeared on IMD business school for management and leadership courses.",
      "publishedDate": "2025-09-25T06:58:00.000Z",
      "author": "Michael Yaziji",
      "source": {
        "name": "IMD Business",
        "tier": "business",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:12.644Z",
      "localScore": 1
    },
    {
      "title": "Microsoft adds Anthropic’s AI to Copilot",
      "url": "https://techcrunch.com/2025/09/24/microsoft-adds-anthropics-ai-to-copilot/",
      "summary": "Microsoft is integrating OpenAI rival Anthropic's AI into Copilot, marking another step toward the disentangling of Microsoft and OpenAI.",
      "publishedDate": "2025-09-24T17:46:29.000Z",
      "author": "Rebecca Bellan",
      "source": {
        "name": "TechCrunch AI",
        "tier": "ai-news",
        "authority": "Medium",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:11.143Z",
      "localScore": 0
    },
    {
      "title": "Google's Conversational Photo Editor Is the Rare AI Feature People Will Actually Use",
      "url": "https://www.wired.com/story/google-photos-conversational-photo-editor/",
      "summary": "Google's tool greatly simplifies photo editing; just tell your phone what changes you want in the photo, and it'll execute them. It also hints at the coming leap in how we interact with computers.",
      "publishedDate": "2025-09-25T10:30:00.000Z",
      "author": "Julian Chokkattu",
      "source": {
        "name": "Wired AI",
        "tier": "ai-news",
        "authority": "Medium",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:15.071Z",
      "localScore": 0
    },
    {
      "title": "This AI-Powered Robot Keeps Going Even if You Attack It With a Chainsaw",
      "url": "https://www.wired.com/story/this-ai-powered-robot-keeps-going-even-if-you-attack-it-with-a-chainsaw/",
      "summary": "A single AI model trained to control numerous robotic bodies can operate unfamiliar hardware and adapt eerily well to serious injuries.",
      "publishedDate": "2025-09-24T18:00:00.000Z",
      "author": "Will Knight",
      "source": {
        "name": "Wired AI",
        "tier": "ai-news",
        "authority": "Medium",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:56:15.071Z",
      "localScore": 0
    },
    {
      "title": "Deutsche Bank Notices That a Needle Is Getting Dangerously Close to the AI Bubble",
      "url": "https://gizmodo.com/deutsche-bank-notices-that-a-needle-is-getting-dangerously-close-to-the-ai-bubble-2000663370",
      "summary": "If not for AI spending, the bank says the US would be in a recession.",
      "publishedDate": "2025-09-25T11:00:00.000Z",
      "author": "AJ Dellinger",
      "source": {
        "name": "Gizmodo",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:05.629Z",
      "localScore": 0
    },
    {
      "title": "Dutch lead charge on electric inland vessels",
      "url": "https://techxplore.com/news/2025-09-dutch-electric-inland-vessels.html",
      "summary": "At a windswept container park near the sprawling port of Rotterdam, a crane slots a 30-tonne white battery into a transporter vessel, enough to provide eight hours of zero-emissions freight.",
      "publishedDate": "2025-09-25T13:40:04.000Z",
      "author": "Unknown",
      "source": {
        "name": "Tech Xplore",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:10.173Z",
      "localScore": 0
    },
    {
      "title": "Spotify moves to tackle AI abuse with transparency measures",
      "url": "https://techxplore.com/news/2025-09-spotify-tackle-ai-abuse-transparency.html",
      "summary": "Spotify on Thursday unveiled several measures to encourage artists and publishers to be more transparent about their use of artificial intelligence, as well as to limit certain abuses.",
      "publishedDate": "2025-09-25T13:33:01.000Z",
      "author": "Unknown",
      "source": {
        "name": "Tech Xplore",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:10.173Z",
      "localScore": 0
    },
    {
      "title": "Toyota opens high-tech village in Japan to road test the future",
      "url": "https://techxplore.com/news/2025-09-toyota-high-tech-village-japan.html",
      "summary": "Top-selling carmaker Toyota opened its new high-tech village in Japan on Thursday, an experimental project to test autonomous driving and other futuristic developments.",
      "publishedDate": "2025-09-25T13:26:43.000Z",
      "author": "Unknown",
      "source": {
        "name": "Tech Xplore",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:10.173Z",
      "localScore": 0
    },
    {
      "title": "Canada Goes All In on AI: NVIDIA Joins Nations’ Technology Leaders in Montreal to Shape Sovereign AI Strategy",
      "url": "https://blogs.nvidia.com/blog/canada-all-in/",
      "summary": "Canada’s role as a leader in artificial intelligence was on full display at this week’s All In Canada AI Ecosystem event. NVIDIA Vice President of Generative AI Software Kari Briski today joined Canada’s Minister of Artificial Intelligence and Digital Innovation Evan Solomon and Aiden Gomez, cofounder and CEO of Cohere, in a special address moderated\t\n\t\tRead Article",
      "publishedDate": "2025-09-24T16:20:41.000Z",
      "author": "Erik Pounds",
      "source": {
        "name": "NVIDIA Blog",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:12.684Z",
      "localScore": 0
    },
    {
      "title": "Decoding Nonlinear Signals In Large Observational Datasets",
      "url": "https://towardsdatascience.com/decoding-nonlinear-signals-in-large-observational-datasets/",
      "summary": "Rain, snow, or something In between?\nThe post Decoding Nonlinear Signals In Large Observational Datasets appeared first on Towards Data Science.",
      "publishedDate": "2025-09-24T19:37:07.000Z",
      "author": "Fraser King",
      "source": {
        "name": "Towards Data Science",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:20.761Z",
      "localScore": 0
    },
    {
      "title": "China Launches e-CNY International Operations Center in Shanghai",
      "url": "https://technode.com/2025/09/25/china-launches-e-cny-international-operations-center-in-shanghai/",
      "summary": "The People’s Bank of China said the e-CNY International Operations Center has officially started operations in Shanghai, introducing three business platforms: a cross-border payment platform, a blockchain service platform for standardized on-chain transactions, and a digital assets platform offering financial-grade services. The initiatives aim to tackle inefficiencies in cross-border payments, enable on-chain e-CNY settlement for […]",
      "publishedDate": "2025-09-25T10:44:06.000Z",
      "author": "TechNode Feed",
      "source": {
        "name": "TechNode",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:30.393Z",
      "localScore": 0
    },
    {
      "title": "Drone startup Guardian Agriculture shuts down",
      "url": "https://www.therobotreport.com/drone-startup-guardian-agriculture-shuts-down/",
      "summary": "Founded in 2017, Guardian Agriculture had raised attention in the agtech and robotics sectors with its SC1, a fully autonomous quadcopter designed for crop spraying.\nThe post Drone startup Guardian Agriculture shuts down appeared first on The Robot Report.",
      "publishedDate": "2025-09-24T17:36:37.000Z",
      "author": "Steve Crowe",
      "source": {
        "name": "Robotics Business",
        "tier": "ai-news",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:34.828Z",
      "localScore": 0
    },
    {
      "title": "What’s Driving Nvidia’s $100B Investment in OpenAI?",
      "url": "https://www.aiwire.net/2025/09/24/whats-driving-nvidias-100b-investment-in-openai/",
      "summary": "The race to build massive GPU farms, or AI factories, is in full swing, and by all accounts, Nvidia is sitting in the pole position. Flush with cash from surging GPU sales, the Santa Clara, California GPU company is looking for investments that can generate returns and keep the virtuous cycle moving. What better place to invest, then, than in your own hyperscale customers? That appears to be the logic behind today’s news of a landmark alliance between Nvidia and OpenAI, which could see the GPU giant investing up to $100 billion into the AI firm as part of a plan to build 10 gigawatts of AI data center infrastructure. Nvidia’s investment in OpenAI is tied to the opening of new data centers, which is measured in power capacity. The first phase of what could become 10 gigawatts of data center capacity is targeted to come online in the second half of 2026, and utilize Nvidia’s new Vera Rubin GPU-CPU superchips. The investment in OpenAI comes less than a week after Nvidia announced it was taking a $5 billion stake in Intel as part of a plan that will see Intel adopting Nvidia’s NVLink technology for future data center superchips that combine GPUs and CPUs on the same die. The two companies also announced they would collaborate on using NVLink for a new generation of consumer-grade chips that fuse Nvidia GPU RTX chips onto Intel boards. In an interview on CNBC, Nvidia Founder and CEO Jensen Huang discussed his vision for the future of AI. “It is very soon where every single word, every single interaction, every single image and video that we experience through computers will somehow have been reasoned through or referenced by or generated by AI,” Huang told CNBC. “It’s going to be touched by AI somehow. So all of our computing experiences throughout the day, everywhere, in every industry, will be powered by AI.” There’s never been an engineering project as large or complex as the 10 gigawatts in data center capacity that Nvidia and OpenAI will collaborate to build, Huang said. “This is the first 10 gigawatts, surely it sounds like an enormous undertaking. But there’s no question that AI is transformational for every industry,” he said. “But the important thing is the AI infrastructure will be everywhere and it will power computing experiences for everyone everyday. And it’s going to be just everywhere.” OpenAI unveiled GPT-5 about a month ago, marking the company’s first major new LLM since it released GPT-4 in the spring of 2023. However, the new model, which features a built-in controller that will automatically route user requests to standard GPT or to reasoning sub-models, has faced a lackluster reception. With 700 million weekly customers, OpenAI is looking for ways to monetize its reach and AI investments. The company raised another $8.3 billion last month, which adds to the $40 billion it raised earlier this year in a venture capital round that valued it at $300 billion. OpenAI, which has used Nvidia GPUs and was the first customer for Nvidia’s new DGX system back in 2016, has not publicly disclosed what comes after GPT-5. In the announcement, the two companies say OpenAI is on the path to delivering “superintelligence.” More information about the partnership will be released in the coming weeks, the companies said. Nvidia’s stock rose about 3.5% immediately following the announcement. The market capitalization for the most valuable company in the world increased about $150 billion to nearly $4.5 trillion. This article first appeared on our sister publication, HPCwire.",
      "publishedDate": "2025-09-24T18:34:27.000Z",
      "author": "Alex Woodie",
      "source": {
        "name": "Enterprise AI",
        "tier": "industry",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:57:57.723Z",
      "localScore": 0
    },
    {
      "title": " AI is boosting personal productivity but slowing down teams – here’s why ",
      "url": "https://www.itpro.com/business/business-strategy/ai-is-boosting-personal-productivity-but-slowing-down-teams-heres-why",
      "summary": "An Atlassian survey suggests AI is helping worker productivity, but a failure to collaborate means it isn't delivering ROI",
      "publishedDate": "2025-09-25T09:56:20.000Z",
      "author": " Nicole Kobie ",
      "source": {
        "name": "IT Pro",
        "tier": "industry",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:03.374Z",
      "localScore": 0
    },
    {
      "title": " NCA confirms arrest after airport cyber disruption ",
      "url": "https://www.itpro.com/security/cyber-attacks/nca-confirms-arrest-after-airport-cyber-disruption",
      "summary": "Disruption is easing across Europe following the ransomware incident",
      "publishedDate": "2025-09-25T09:25:43.000Z",
      "author": " Emma Woollacott ",
      "source": {
        "name": "IT Pro",
        "tier": "industry",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:03.374Z",
      "localScore": 0
    },
    {
      "title": "Reimagining Marketing Strategy for the AI Era",
      "url": "https://sloanreview.mit.edu/video/reimagining-marketing-strategy-for-the-ai-era/",
      "summary": "Related Reading A. Tomaselli and O.A. Acar, “How GenAI Changes Creative Work,” MIT Sloan Management Review, Sept. 19, 2024. A. Gvirtz and O.A. Acar, “Why Text-to-Image AI Requires a New Branding Mindset,” MIT Sloan Management Review, Oct. 26, 2023. Many marketing leaders recognize the opportunity of using generative AI for marketing but struggle with a […]",
      "publishedDate": "2025-09-25T11:27:43.000Z",
      "author": "Oguz A. Acar and Kaushik Viswanath. <p>Oguz A. Acar is a professor of marketing and innovation and head of generative AI at King’s Business School at King’s College London and a research affiliate at Harvard University’s Laboratory for Innovation Science. His current research is at the nexus of generative AI, organizations, and education. He advises a wide range of companies on AI and marketing and has published extensively on the topic in top business publications, including <cite>MIT Sloan Management Review</cite> and <cite>Harvard Business Review</cite>. Kaushik Viswanath is features editor at <cite>MIT Sloan Management Review</cite>. He moderated the session.</p>\n",
      "source": {
        "name": "MIT Sloan Review",
        "tier": "business",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:04.826Z",
      "localScore": 0
    },
    {
      "title": "European Commission launches antitrust probe into software giant SAP",
      "url": "https://www.cnbc.com/2025/09/25/european-commission-launches-antitrust-probe-into-software-giant-sap.html",
      "summary": "SAP said it did not expect the investigation to have a material impact on its bottom line.",
      "publishedDate": "2025-09-25T11:50:07.000Z",
      "author": "Unknown",
      "source": {
        "name": "CNBC Tech",
        "tier": "business",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:07.346Z",
      "localScore": 0
    },
    {
      "title": "The next frontier in sustainability: Why businesses should care about voluntary biodiversity credits",
      "url": "https://www.imd.org/ibyimd/industry/financial-services-industry/voluntary-biodiversity-credits/",
      "summary": "The nascent market of voluntary biodiversity credits offers businesses an innovative way to invest in nature, creating new opportunities to support measurable conservation outcomes.\nThe post The next frontier in sustainability: Why businesses should care about voluntary biodiversity credits first appeared on IMD business school for management and leadership courses.",
      "publishedDate": "2025-09-25T08:10:48.000Z",
      "author": "Adrian Dellecker",
      "source": {
        "name": "IMD Business",
        "tier": "business",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:12.644Z",
      "localScore": 0
    },
    {
      "title": "Exclusive: How Crunchyroll’s manga app will turn a new page for anime fans",
      "url": "https://www.fastcompany.com/91410256/exclusive-how-crunchyrolls-manga-app-will-turn-a-new-page-for-anime-fans",
      "summary": "There’s no clearer sign of anime’s cultural ascendance than the box office haul of Demon Slayer: Kimetsu no Yaiba — Infinity Castle. The film, which hit U.S. theaters two weeks ago, has pulled in more than $555 million globally, including more than $104 million in North America, making it a bonafide hit for Sony Pictures, which distributed it outside of Japan through its anime streaming arm, Crunchyroll.\nThe movie’s success reflects audiences’ growing interest in anime. A survey from market research firm Dentsu found that, 31% of people worldwide said they consumed anime at least weekly, with a full 50% of Gen Z reporting they watch it. That’s translated into a boom in Crunchyroll subscriptions. The anime streaming service, which is home to more than 2,000 titles (including Demon Slayer), counted 17 million paid subscribers worldwide in May 2025—more than triple the number it had in 2021. \n[Screenshot: courtesy Crunchyroll]\n\n\n\nCrunchyroll will soon offer those subscribers a way to go even deeper on the source material of some of their favorite shows, with the debut a manga reader app. The company shared a first look exclusively with Fast Company. \nSet to launch October 9 on mobile and October 15 on web in the United States and Canada, Crunchyroll Manga will debut with hundreds of titles, including the manga behind some of Crunchyroll’s top series, including Jujutsu Kaisen, Kaiju No. 8, and Apothecary Diaries. \nFor subscribers to Crunchyroll’s $15.99-per-month Ultimate tier, access to Crunchyroll Manga will be free. It will be available as a $3.50 add-on for the $11.99 Mega Fan tier, and a $4 add-on to the $7.99 Fan tier.\nIt’s a feature that users have been asking for, says chief content officer Asa Suehira. “Crunchyroll has been doing a lot of surveys over the past few years and digital manga has always been the most desired feature on our platform,” he says. “This is compared to shorter content, video games, music, or even discounts or credits toward merchandise.”\n[Screenshot: courtesy Crunchyroll]\n\n\n\nBuilding a bridge between anime and manga\nFrom a user perspective, Crunchyroll Manga is designed to function much like the company’s flagship streaming app, with important connections between the two. \nIf a title in the manga app has a corresponding anime series on Crunchyroll, users can choose to start watching the show straight from the manga app. Their device will simply switch to the streaming app if it’s installed. Similarly, if a Crunchyroll anime series has a corresponding manga, viewers will have the option of clicking over to start reading it. \n“There’s data saying that 40% of manga readers discover manga through anime,” Suehira says. “We want to create a new habit of discovery through manga, and being able to watch the anime as well. \nCrunchyroll has been clever about how it entices anime fans who might discover the genre through other streaming services. Notably, it will license shows like Jujutsu Kaisen to Netflix, but exclusively stream the latest season on its platform. \nCrunchyroll Manga offers an opportunity for it to replicate that approach in reverse. The service will include manga volumes for series that exclusively stream elsewhere, including Delicious in Dungeon and The Summer Hikaru Died—two anime adaptations that Netflix exclusively distributes. Fans of those series will have sign up for Crunchyroll if they they want to read the manga.\nThe manga and anime apps will also be linked by user profiles. Any updates made to a profile’s content restrictions in one will be be mirrored in the other. \nThe main appeal, though, is the amount of manga fans will be able to access. Suehira says that by partnering with Link-u, which has developed digital manga infrastructure in Japan, “we were able to work more closely with different publishers.”\n[Screenshot: courtesy Crunchyroll]\n\n\n\nMaking publishers happy\nCrunchyroll Manga is actually the second time the company has offered manga. A previous offering shut down in 2023. Suehira says part of that platform’s downfall was because Crunchyroll’s licensing agreement with manga publishers limited how much users could read. It also “limited the opportunities for us to work with the publishers,” Suehira says. \nCrunchyroll Manga will launch with a library of titles from publishers like Viz Media, AlphaPolis, and Square Enix. Crunchyroll says additional publishers will be added in the coming months, including Shueisha, which publishes the Demon Slayer manga.\nPart of what has gotten these companies on board, Suehira says, is Crunchyroll Manga’s use of a revenue-sharing model that compensates publishers based on user engagement, similar to how the anime platform pays studios. \nCrunchyroll Manga also offers a legitimate way for burgeoning anime fans to read source material. Suehira says 15 of the top 20 internet piracy sites include anime and manga, and that manga represents 70% of global publishing piracy.\n“We want [Crunchyroll Manga] to be a solution to the privacy market and really contribute to the ecosystem in Japan,” Suehira says, adding that the app includes features the prevent screenshots and screen recording. \nPart of working with publishers means tracking a titles popularity, which can inform payments, but also potentially predict a future hit adaptation. \n“[Publishers] want to understand how the crowd is reacting to certain manga or an IP,” he says. “Data on consumption and fan reactions are things we could work together with our partners in Japan to expand the opportunity—whether that’s turning into an anime or selling merchandise.’",
      "publishedDate": "2025-09-25T11:00:00.000Z",
      "author": "David Salazar",
      "source": {
        "name": "Fast Company",
        "tier": "startup",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:16.375Z",
      "localScore": 0
    },
    {
      "title": "Cyber Attack On JLR Should Be A ‘Wake-Up Call’ For British Industry – Minister",
      "url": "https://www.pmtoday.co.uk/cyber-attack-on-jlr-should-be-a-wake-up-call-for-british-industry-minister/",
      "summary": "Industry minister Chris McDonald says Jaguar Land Rover will recover from its cyberattack but warns that UK businesses must strengthen defences against rising threats.\nThe post Cyber Attack On JLR Should Be A ‘Wake-Up Call’ For British Industry – Minister appeared first on PM Today.",
      "publishedDate": "2025-09-24T17:03:04.000Z",
      "author": "Dan Matthews",
      "source": {
        "name": "PM Today",
        "tier": "pmo",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "RSS",
      "discoveredAt": "2025-09-25T13:58:24.384Z",
      "localScore": 0
    },
    {
      "title": "https://careers.cognizant.com/global-en/jobs/xml/?rss=true",
      "url": "https://careers.cognizant.com/global-en/jobs/xml/?rss=true",
      "summary": "... AI automation platforms (e.g.ServiceNow AIOps, ITSI).<o:p></o:p></li> <li> ... d be helpful to this role.<o:p></o:p></p><p><strong>Salary and Other ...",
      "publishedDate": "2025-09-25T13:59:18.847Z",
      "author": "Unknown",
      "source": {
        "name": "careers",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI automation platforms\" OR \"AI workflow automation tools\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:18.847Z",
      "localScore": 0
    },
    {
      "title": "9 AI Agent Frameworks Battle: Why Developers Prefer n8n – n8n Blog",
      "url": "https://blog.n8n.io/ai-agent-frameworks/",
      "summary": "Apr 24, 2025 ... But if you've actually tried to build an AI agent, you know that the reality is much messier: many AI agent frameworks ... Qdrant, Zep) for ...",
      "publishedDate": "2025-04-24T09:47:55.000Z",
      "author": "Unknown",
      "source": {
        "name": "blog",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI orchestration platforms\" OR \"AI agent frameworks\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:20.281Z",
      "localScore": 0
    },
    {
      "title": "Qdrant's GPU-accelerated vector indexing is here",
      "url": "https://cerebralvalley.beehiiv.com/p/qdrant-s-gpu-accelerated-vector-indexing-is-here",
      "summary": "Jan 23, 2025 ... ... AI Agent frameworks to ensure an easy integration. For example, Qdrant works out of the box with frameworks like CrewAI, LangGraph, Autogen ...",
      "publishedDate": "2025-09-25T13:59:20.281Z",
      "author": "Unknown",
      "source": {
        "name": "cerebralvalley",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI orchestration platforms\" OR \"AI agent frameworks\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:20.281Z",
      "localScore": 0
    },
    {
      "title": "OpenAI ChatGPT Plugins List",
      "url": "https://dang.ai/plugins",
      "summary": "Qdrant. Qdrant is a vector search engine ChatGPT plugin to help make the ... AI Productivity Tools · AI Marketing Tools · AI Text to Speech Tools · AI Search ...",
      "publishedDate": "2025-09-25T13:59:21.634Z",
      "author": "Unknown",
      "source": {
        "name": "dang",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI productivity tools\" OR \"AI workplace efficiency apps\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:21.634Z",
      "localScore": 0
    },
    {
      "title": "N8N WORKFLOW BLUEPRINTS– Automate Everything With Ai ...",
      "url": "https://www.etsy.com/listing/4300474642/n8n-workflow-blueprints-automate",
      "summary": "May 4, 2025 ... ... ai productivity tools, n8n blueprints, automation for developers, ai ... If you'd like to file an allegation of infringement, you'll ...",
      "publishedDate": "2025-09-25T13:59:21.634Z",
      "author": "Unknown",
      "source": {
        "name": "etsy",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI productivity tools\" OR \"AI workplace efficiency apps\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:21.634Z",
      "localScore": 0
    },
    {
      "title": "DICOM Router - Secure. Scalable. Seamless.",
      "url": "https://www.qvera.com/dicom-router/",
      "summary": "Ryan W. September ... PACS, VNA, and 3rd-Party System Integration: Direct connections to existing PACS, cloud archives, AI analytics platforms, and EHRs.",
      "publishedDate": "2025-09-25T13:59:22.962Z",
      "author": "Unknown",
      "source": {
        "name": "qvera",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI business dashboards\" OR \"AI analytics platforms\" qdr:d",
      "searchCategory": "generalAI",
      "discoveredAt": "2025-09-25T13:59:22.962Z",
      "localScore": 0
    },
    {
      "title": "Python work barbados Jobs, Employment | Freelancer",
      "url": "https://www.freelancer.com/job-search/python-work-barbados/3/",
      "summary": "I'd like to give it a fresh, modern, and slightly futuristic look. The task ... ContextOps AI Task Automation. 4 days left. Verified. I'm building a local ...",
      "publishedDate": "2025-09-25T14:00:38.283Z",
      "author": "Unknown",
      "source": {
        "name": "freelancer",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI workflow orchestration enterprise\" OR \"AI task automation\" qdr:d",
      "searchCategory": "pmoInference",
      "discoveredAt": "2025-09-25T14:00:38.283Z",
      "localScore": 0
    },
    {
      "title": "Artificial Intelligence for Business Leaders | DataCamp",
      "url": "https://www.datacamp.com/resources/webinars/artificial-intelligence-for-business-leaders",
      "summary": "50% off unlimited learning. Sale ends in. 6d09h57m51s. Buy Now · Courses · See all Beginner ... Hugo shares insights from Andrew Ng's AI Transformation Playbook ...",
      "publishedDate": "2025-09-25T14:00:41.046Z",
      "author": "Unknown",
      "source": {
        "name": "datacamp",
        "tier": "search",
        "authority": "Standard",
        "focusAreas": [
          "AI",
          "PMO"
        ]
      },
      "discoveryMethod": "Google Search",
      "searchQuery": "\"AI organizational change management\" OR \"AI transformation playbook\" qdr:d",
      "searchCategory": "pmoInference",
      "discoveredAt": "2025-09-25T14:00:41.046Z",
      "localScore": 0
    }
  ]
}